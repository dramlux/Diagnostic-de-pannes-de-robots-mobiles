{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kodzo.apedo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/kodzo.apedo/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import Input\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import os\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras import regularizers\n",
    "import time\n",
    "import time\n",
    "\n",
    "from keras import regularizers\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement des donnees \n",
    "\n",
    "df = pd.read_csv('/home/kodzo.apedo/Bureau/Visu/mesdonnees/mesdonnees_sans_degradation_gaussian.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42 #used to help randomly select the data points\n",
    "TEST_PCT = 0.30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds[:,0:34].astype(float)\n",
    "Y = ds[:,34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encodons la classe \"Classe\"\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoder_Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., 13, 13, 13])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefinissons nos classe\n",
    "\n",
    "dummy_y = np_utils.to_categorical(encoder_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yd = dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Yd_train, Yd_test = train_test_split(X, Yd, test_size = TEST_PCT, random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_class = 14 # Nombre de classe\n",
    "\n",
    "nb_epoch = 500\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "#Couche d'entr√©e\n",
    "\n",
    "input_dim = X_train.shape[1] #numbre de colonne, \n",
    "\n",
    "encoding_dim = 500 # Dimension d'encodage\n",
    "nb_class = 20 # Nombre de classe\n",
    "hidden_dim = encoding_dim - 200 #i.e. 7\n",
    "\n",
    "hidden_dim2 = hidden_dim - 200\n",
    "\n",
    "#hidden_dim3 = hidden_dim + 30\n",
    "\n",
    "learning_rate = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d execution : 0.06812191009521484 secondes ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Debut du decompte du temps\n",
    "start_time = time.time()\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoder = Dense(encoding_dim, activation='tanh', \n",
    "                activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
    "#encoder = Dense(hidden_dim2, activation='tanh')(encoder)\n",
    "encoder = Dense(input_dim, activation='relu')(encoder)\n",
    "\n",
    "\n",
    "print(\"Temps d execution : %s secondes ---\" %(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 34)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               17500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 34)                10234     \n",
      "=================================================================\n",
      "Total params: 178,034\n",
      "Trainable params: 178,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 195990 samples, validate on 83996 samples\n",
      "Epoch 1/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.4093 - acc: 0.8282 - val_loss: 0.2687 - val_acc: 0.9086\n",
      "Epoch 2/500\n",
      "195990/195990 [==============================] - 9s 45us/step - loss: 0.2188 - acc: 0.9138 - val_loss: 0.2012 - val_acc: 0.9127\n",
      "Epoch 3/500\n",
      "195990/195990 [==============================] - 9s 45us/step - loss: 0.1844 - acc: 0.9197 - val_loss: 0.1814 - val_acc: 0.9158\n",
      "Epoch 4/500\n",
      "195990/195990 [==============================] - 9s 47us/step - loss: 0.1730 - acc: 0.9168 - val_loss: 0.1728 - val_acc: 0.9250\n",
      "Epoch 5/500\n",
      "195990/195990 [==============================] - 9s 47us/step - loss: 0.1676 - acc: 0.9252 - val_loss: 0.1674 - val_acc: 0.9282\n",
      "Epoch 6/500\n",
      "195990/195990 [==============================] - 9s 48us/step - loss: 0.1643 - acc: 0.9266 - val_loss: 0.1647 - val_acc: 0.9247\n",
      "Epoch 7/500\n",
      "195990/195990 [==============================] - 8s 43us/step - loss: 0.1617 - acc: 0.9313 - val_loss: 0.1635 - val_acc: 0.9194\n",
      "Epoch 8/500\n",
      "195990/195990 [==============================] - 9s 45us/step - loss: 0.1604 - acc: 0.9293 - val_loss: 0.1614 - val_acc: 0.9360\n",
      "Epoch 9/500\n",
      "195990/195990 [==============================] - 9s 44us/step - loss: 0.1598 - acc: 0.9273 - val_loss: 0.1621 - val_acc: 0.9242\n",
      "Epoch 10/500\n",
      "195990/195990 [==============================] - 9s 45us/step - loss: 0.1583 - acc: 0.9339 - val_loss: 0.1589 - val_acc: 0.9336\n",
      "Epoch 11/500\n",
      "195990/195990 [==============================] - 9s 46us/step - loss: 0.1589 - acc: 0.9285 - val_loss: 0.1583 - val_acc: 0.9352\n",
      "Epoch 12/500\n",
      "195990/195990 [==============================] - 9s 47us/step - loss: 0.1575 - acc: 0.9287 - val_loss: 0.1583 - val_acc: 0.9232\n",
      "Epoch 13/500\n",
      "195990/195990 [==============================] - 9s 44us/step - loss: 0.1569 - acc: 0.9303 - val_loss: 0.1571 - val_acc: 0.9425\n",
      "Epoch 14/500\n",
      "195990/195990 [==============================] - 9s 44us/step - loss: 0.1596 - acc: 0.9151 - val_loss: 0.1566 - val_acc: 0.9338\n",
      "Epoch 15/500\n",
      "195990/195990 [==============================] - 10s 49us/step - loss: 0.1559 - acc: 0.9313 - val_loss: 0.1564 - val_acc: 0.9399\n",
      "Epoch 16/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1559 - acc: 0.9286 - val_loss: 0.1563 - val_acc: 0.8815\n",
      "Epoch 17/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1573 - acc: 0.9122 - val_loss: 0.1559 - val_acc: 0.9370\n",
      "Epoch 18/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1557 - acc: 0.9276 - val_loss: 0.1550 - val_acc: 0.9341\n",
      "Epoch 19/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1549 - acc: 0.9313 - val_loss: 0.1548 - val_acc: 0.9302\n",
      "Epoch 20/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1552 - acc: 0.9256 - val_loss: 0.1552 - val_acc: 0.9333\n",
      "Epoch 21/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1564 - acc: 0.9165 - val_loss: 0.1548 - val_acc: 0.9214\n",
      "Epoch 22/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1552 - acc: 0.9247 - val_loss: 0.1545 - val_acc: 0.9128\n",
      "Epoch 23/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1573 - acc: 0.9114 - val_loss: 0.1549 - val_acc: 0.9320\n",
      "Epoch 24/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1548 - acc: 0.9266 - val_loss: 0.1554 - val_acc: 0.9161\n",
      "Epoch 25/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1548 - acc: 0.9253 - val_loss: 0.1546 - val_acc: 0.9208\n",
      "Epoch 26/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1549 - acc: 0.9210 - val_loss: 0.1542 - val_acc: 0.9373\n",
      "Epoch 27/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1575 - acc: 0.9137 - val_loss: 0.1575 - val_acc: 0.9314\n",
      "Epoch 28/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1545 - acc: 0.9270 - val_loss: 0.1543 - val_acc: 0.9358\n",
      "Epoch 29/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1553 - acc: 0.9179 - val_loss: 0.1557 - val_acc: 0.9107\n",
      "Epoch 30/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1548 - acc: 0.9172 - val_loss: 0.1540 - val_acc: 0.9248\n",
      "Epoch 31/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1558 - acc: 0.9092 - val_loss: 0.1551 - val_acc: 0.9136\n",
      "Epoch 32/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1552 - acc: 0.9225 - val_loss: 0.1672 - val_acc: 0.8634\n",
      "Epoch 33/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1596 - acc: 0.8866 - val_loss: 0.1547 - val_acc: 0.9215\n",
      "Epoch 34/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1553 - acc: 0.9140 - val_loss: 0.1586 - val_acc: 0.8852\n",
      "Epoch 35/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1543 - acc: 0.9225 - val_loss: 0.1541 - val_acc: 0.9382\n",
      "Epoch 36/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1550 - acc: 0.9145 - val_loss: 0.1546 - val_acc: 0.9258\n",
      "Epoch 37/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1556 - acc: 0.9090 - val_loss: 0.1597 - val_acc: 0.8462\n",
      "Epoch 38/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1595 - acc: 0.8968 - val_loss: 0.1544 - val_acc: 0.9278\n",
      "Epoch 39/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1540 - acc: 0.9259 - val_loss: 0.1545 - val_acc: 0.9132\n",
      "Epoch 40/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1546 - acc: 0.9189 - val_loss: 0.1582 - val_acc: 0.9190\n",
      "Epoch 41/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1553 - acc: 0.9150 - val_loss: 0.1557 - val_acc: 0.9057\n",
      "Epoch 42/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1543 - acc: 0.9226 - val_loss: 0.1560 - val_acc: 0.8991\n",
      "Epoch 43/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1582 - acc: 0.9051 - val_loss: 0.1548 - val_acc: 0.9259\n",
      "Epoch 44/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1551 - acc: 0.9240 - val_loss: 0.1582 - val_acc: 0.8637\n",
      "Epoch 45/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1550 - acc: 0.9173 - val_loss: 0.1555 - val_acc: 0.9147\n",
      "Epoch 46/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1538 - acc: 0.9302 - val_loss: 0.1543 - val_acc: 0.9435\n",
      "Epoch 47/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1558 - acc: 0.9053 - val_loss: 0.1550 - val_acc: 0.9148\n",
      "Epoch 48/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1543 - acc: 0.9232 - val_loss: 0.1586 - val_acc: 0.8802\n",
      "Epoch 49/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1564 - acc: 0.8941 - val_loss: 0.1549 - val_acc: 0.8950\n",
      "Epoch 50/500\n",
      "195990/195990 [==============================] - 8s 42us/step - loss: 0.1565 - acc: 0.8824 - val_loss: 0.1546 - val_acc: 0.9097\n",
      "Epoch 51/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1549 - acc: 0.9095 - val_loss: 0.1538 - val_acc: 0.9069\n",
      "Epoch 52/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1537 - acc: 0.9297 - val_loss: 0.1545 - val_acc: 0.8788\n",
      "Epoch 53/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1566 - acc: 0.8927 - val_loss: 0.1545 - val_acc: 0.9258\n",
      "Epoch 54/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1543 - acc: 0.9261 - val_loss: 0.1566 - val_acc: 0.9274\n",
      "Epoch 55/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1562 - acc: 0.9086 - val_loss: 0.1544 - val_acc: 0.9298\n",
      "Epoch 56/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1546 - acc: 0.9231 - val_loss: 0.1536 - val_acc: 0.9339\n",
      "Epoch 57/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1544 - acc: 0.9170 - val_loss: 0.1627 - val_acc: 0.8740\n",
      "Epoch 58/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1562 - acc: 0.9010 - val_loss: 0.1547 - val_acc: 0.8785\n",
      "Epoch 59/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1550 - acc: 0.9142 - val_loss: 0.1563 - val_acc: 0.9173\n",
      "Epoch 60/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1605 - acc: 0.8782 - val_loss: 0.1558 - val_acc: 0.8889\n",
      "Epoch 61/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1546 - acc: 0.9155 - val_loss: 0.1540 - val_acc: 0.9256\n",
      "Epoch 62/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1547 - acc: 0.9206 - val_loss: 0.1544 - val_acc: 0.9130\n",
      "Epoch 63/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1544 - acc: 0.9235 - val_loss: 0.1546 - val_acc: 0.9217\n",
      "Epoch 64/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1567 - acc: 0.9114 - val_loss: 0.1651 - val_acc: 0.8642\n",
      "Epoch 65/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1580 - acc: 0.8871 - val_loss: 0.1564 - val_acc: 0.8950\n",
      "Epoch 66/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1550 - acc: 0.9076 - val_loss: 0.1558 - val_acc: 0.8672\n",
      "Epoch 67/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1559 - acc: 0.8954 - val_loss: 0.1538 - val_acc: 0.9361\n",
      "Epoch 68/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1580 - acc: 0.9040 - val_loss: 0.1541 - val_acc: 0.9082\n",
      "Epoch 69/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1544 - acc: 0.9261 - val_loss: 0.1537 - val_acc: 0.9251\n",
      "Epoch 70/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1562 - acc: 0.9111 - val_loss: 0.1560 - val_acc: 0.9258\n",
      "Epoch 71/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1601 - acc: 0.8733 - val_loss: 0.1759 - val_acc: 0.6824\n",
      "Epoch 72/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1626 - acc: 0.8341 - val_loss: 0.1577 - val_acc: 0.8980\n",
      "Epoch 73/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1576 - acc: 0.9036 - val_loss: 0.1566 - val_acc: 0.9094\n",
      "Epoch 74/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1555 - acc: 0.9055 - val_loss: 0.1551 - val_acc: 0.9125\n",
      "Epoch 75/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1556 - acc: 0.9011 - val_loss: 0.1570 - val_acc: 0.8949\n",
      "Epoch 76/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1565 - acc: 0.8928 - val_loss: 0.1568 - val_acc: 0.8770\n",
      "Epoch 77/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1565 - acc: 0.8899 - val_loss: 0.1583 - val_acc: 0.8915\n",
      "Epoch 78/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1574 - acc: 0.8979 - val_loss: 0.1697 - val_acc: 0.8725\n",
      "Epoch 79/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1562 - acc: 0.8968 - val_loss: 0.1540 - val_acc: 0.9127\n",
      "Epoch 80/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1566 - acc: 0.8997 - val_loss: 0.1549 - val_acc: 0.9236\n",
      "Epoch 81/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1537 - acc: 0.9277 - val_loss: 0.1544 - val_acc: 0.9386\n",
      "Epoch 82/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1539 - acc: 0.9257 - val_loss: 0.1538 - val_acc: 0.9363\n",
      "Epoch 83/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1548 - acc: 0.9120 - val_loss: 0.1594 - val_acc: 0.9005\n",
      "Epoch 84/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1564 - acc: 0.9012 - val_loss: 0.1551 - val_acc: 0.9330\n",
      "Epoch 85/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1546 - acc: 0.9173 - val_loss: 0.1544 - val_acc: 0.9112\n",
      "Epoch 86/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1561 - acc: 0.8894 - val_loss: 0.1705 - val_acc: 0.6654\n",
      "Epoch 87/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1634 - acc: 0.8401 - val_loss: 0.1580 - val_acc: 0.8990\n",
      "Epoch 88/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1577 - acc: 0.9009 - val_loss: 0.1560 - val_acc: 0.9107\n",
      "Epoch 89/500\n",
      "195990/195990 [==============================] - 8s 42us/step - loss: 0.1558 - acc: 0.9056 - val_loss: 0.1559 - val_acc: 0.9106\n",
      "Epoch 90/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1550 - acc: 0.9041 - val_loss: 0.1542 - val_acc: 0.9259\n",
      "Epoch 91/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1540 - acc: 0.9164 - val_loss: 0.1547 - val_acc: 0.8968\n",
      "Epoch 92/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1552 - acc: 0.9022 - val_loss: 0.1549 - val_acc: 0.9177\n",
      "Epoch 93/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1549 - acc: 0.9067 - val_loss: 0.1544 - val_acc: 0.8911\n",
      "Epoch 94/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1551 - acc: 0.9101 - val_loss: 0.1547 - val_acc: 0.9206\n",
      "Epoch 95/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1549 - acc: 0.9150 - val_loss: 0.1563 - val_acc: 0.8744\n",
      "Epoch 96/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1547 - acc: 0.9097 - val_loss: 0.1551 - val_acc: 0.9199\n",
      "Epoch 97/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1556 - acc: 0.9016 - val_loss: 0.1614 - val_acc: 0.8847\n",
      "Epoch 98/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1571 - acc: 0.8812 - val_loss: 0.1555 - val_acc: 0.9161\n",
      "Epoch 99/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1546 - acc: 0.9111 - val_loss: 0.1538 - val_acc: 0.9306\n",
      "Epoch 100/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1543 - acc: 0.9228 - val_loss: 0.1559 - val_acc: 0.9199\n",
      "Epoch 101/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1558 - acc: 0.9059 - val_loss: 0.1545 - val_acc: 0.9114\n",
      "Epoch 102/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1561 - acc: 0.9056 - val_loss: 0.1632 - val_acc: 0.8291\n",
      "Epoch 103/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1595 - acc: 0.8686 - val_loss: 0.1567 - val_acc: 0.9033\n",
      "Epoch 104/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1561 - acc: 0.8963 - val_loss: 0.1547 - val_acc: 0.9125\n",
      "Epoch 105/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1555 - acc: 0.9050 - val_loss: 0.1573 - val_acc: 0.9024\n",
      "Epoch 106/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1551 - acc: 0.8984 - val_loss: 0.1541 - val_acc: 0.9213\n",
      "Epoch 107/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1575 - acc: 0.8848 - val_loss: 0.1539 - val_acc: 0.9275\n",
      "Epoch 108/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1554 - acc: 0.9017 - val_loss: 0.1539 - val_acc: 0.9144\n",
      "Epoch 109/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1551 - acc: 0.9092 - val_loss: 0.1538 - val_acc: 0.9312\n",
      "Epoch 110/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1546 - acc: 0.9059 - val_loss: 0.1563 - val_acc: 0.8831\n",
      "Epoch 111/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1543 - acc: 0.9101 - val_loss: 0.1542 - val_acc: 0.9031\n",
      "Epoch 112/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1552 - acc: 0.9113 - val_loss: 0.1536 - val_acc: 0.9256\n",
      "Epoch 113/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1553 - acc: 0.9044 - val_loss: 0.1586 - val_acc: 0.9025\n",
      "Epoch 114/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1575 - acc: 0.8804 - val_loss: 0.1608 - val_acc: 0.9099\n",
      "Epoch 115/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1559 - acc: 0.8947 - val_loss: 0.1545 - val_acc: 0.9098\n",
      "Epoch 116/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1548 - acc: 0.9053 - val_loss: 0.1549 - val_acc: 0.8952\n",
      "Epoch 117/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1548 - acc: 0.9117 - val_loss: 0.1544 - val_acc: 0.9206\n",
      "Epoch 118/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1548 - acc: 0.9122 - val_loss: 0.1546 - val_acc: 0.9067\n",
      "Epoch 119/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1542 - acc: 0.9166 - val_loss: 0.1537 - val_acc: 0.9298\n",
      "Epoch 120/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1570 - acc: 0.8980 - val_loss: 0.1543 - val_acc: 0.9065\n",
      "Epoch 121/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1596 - acc: 0.8641 - val_loss: 0.1675 - val_acc: 0.7569\n",
      "Epoch 122/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1586 - acc: 0.8718 - val_loss: 0.1580 - val_acc: 0.9055\n",
      "Epoch 123/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1550 - acc: 0.9114 - val_loss: 0.1547 - val_acc: 0.9210\n",
      "Epoch 124/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1546 - acc: 0.9069 - val_loss: 0.1544 - val_acc: 0.9185\n",
      "Epoch 125/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1540 - acc: 0.9188 - val_loss: 0.1585 - val_acc: 0.9043\n",
      "Epoch 126/500\n",
      "195990/195990 [==============================] - 8s 42us/step - loss: 0.1575 - acc: 0.8945 - val_loss: 0.1614 - val_acc: 0.8268\n",
      "Epoch 127/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1551 - acc: 0.9150 - val_loss: 0.1569 - val_acc: 0.9056\n",
      "Epoch 128/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1556 - acc: 0.8968 - val_loss: 0.1542 - val_acc: 0.9237\n",
      "Epoch 129/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1542 - acc: 0.9094 - val_loss: 0.1546 - val_acc: 0.8962\n",
      "Epoch 130/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1543 - acc: 0.9116 - val_loss: 0.1538 - val_acc: 0.9173\n",
      "Epoch 131/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1542 - acc: 0.9123 - val_loss: 0.1535 - val_acc: 0.9251\n",
      "Epoch 132/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1536 - acc: 0.9250 - val_loss: 0.1548 - val_acc: 0.9098\n",
      "Epoch 133/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1539 - acc: 0.9108 - val_loss: 0.1554 - val_acc: 0.9014\n",
      "Epoch 134/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1579 - acc: 0.8789 - val_loss: 0.1547 - val_acc: 0.8984\n",
      "Epoch 135/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1569 - acc: 0.9002 - val_loss: 0.1545 - val_acc: 0.9292\n",
      "Epoch 136/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1542 - acc: 0.9173 - val_loss: 0.1535 - val_acc: 0.9246\n",
      "Epoch 137/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1539 - acc: 0.9203 - val_loss: 0.1541 - val_acc: 0.8989\n",
      "Epoch 138/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1564 - acc: 0.8818 - val_loss: 0.1571 - val_acc: 0.8541\n",
      "Epoch 139/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1554 - acc: 0.8967 - val_loss: 0.1545 - val_acc: 0.8919\n",
      "Epoch 140/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1548 - acc: 0.9061 - val_loss: 0.1648 - val_acc: 0.8819\n",
      "Epoch 141/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1545 - acc: 0.9136 - val_loss: 0.1547 - val_acc: 0.9258\n",
      "Epoch 142/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1625 - acc: 0.7992 - val_loss: 0.1601 - val_acc: 0.7947\n",
      "Epoch 143/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1583 - acc: 0.8859 - val_loss: 0.1599 - val_acc: 0.8990\n",
      "Epoch 144/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1557 - acc: 0.9079 - val_loss: 0.1549 - val_acc: 0.9283\n",
      "Epoch 145/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1588 - acc: 0.8927 - val_loss: 0.1548 - val_acc: 0.9261\n",
      "Epoch 146/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1549 - acc: 0.9096 - val_loss: 0.1543 - val_acc: 0.9266\n",
      "Epoch 147/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1553 - acc: 0.8987 - val_loss: 0.1543 - val_acc: 0.9111\n",
      "Epoch 148/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1551 - acc: 0.9058 - val_loss: 0.1565 - val_acc: 0.9215\n",
      "Epoch 149/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1554 - acc: 0.9107 - val_loss: 0.1541 - val_acc: 0.9181\n",
      "Epoch 150/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1556 - acc: 0.9070 - val_loss: 0.1538 - val_acc: 0.9294\n",
      "Epoch 151/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1556 - acc: 0.9137 - val_loss: 0.1545 - val_acc: 0.9192\n",
      "Epoch 152/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1560 - acc: 0.9190 - val_loss: 0.1541 - val_acc: 0.9287\n",
      "Epoch 153/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1542 - acc: 0.9251 - val_loss: 0.1540 - val_acc: 0.9270\n",
      "Epoch 154/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1539 - acc: 0.9298 - val_loss: 0.1540 - val_acc: 0.9260\n",
      "Epoch 155/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1545 - acc: 0.9121 - val_loss: 0.1543 - val_acc: 0.9152\n",
      "Epoch 156/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1541 - acc: 0.9149 - val_loss: 0.1535 - val_acc: 0.9306\n",
      "Epoch 157/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1549 - acc: 0.9026 - val_loss: 0.1555 - val_acc: 0.9006\n",
      "Epoch 158/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1588 - acc: 0.8814 - val_loss: 0.1577 - val_acc: 0.8791\n",
      "Epoch 159/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1557 - acc: 0.8897 - val_loss: 0.1546 - val_acc: 0.9127\n",
      "Epoch 160/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1558 - acc: 0.8989 - val_loss: 0.1552 - val_acc: 0.8954\n",
      "Epoch 161/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1552 - acc: 0.8990 - val_loss: 0.1540 - val_acc: 0.9193\n",
      "Epoch 162/500\n",
      "195990/195990 [==============================] - 8s 42us/step - loss: 0.1631 - acc: 0.8462 - val_loss: 0.1647 - val_acc: 0.8667\n",
      "Epoch 163/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1594 - acc: 0.8896 - val_loss: 0.1567 - val_acc: 0.9119\n",
      "Epoch 164/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1556 - acc: 0.9116 - val_loss: 0.1548 - val_acc: 0.9072\n",
      "Epoch 165/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1557 - acc: 0.9070 - val_loss: 0.1549 - val_acc: 0.9102\n",
      "Epoch 166/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1543 - acc: 0.9182 - val_loss: 0.1541 - val_acc: 0.9057\n",
      "Epoch 167/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1578 - acc: 0.8878 - val_loss: 0.1564 - val_acc: 0.8543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1551 - acc: 0.8938 - val_loss: 0.1537 - val_acc: 0.9222\n",
      "Epoch 169/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1535 - acc: 0.9254 - val_loss: 0.1557 - val_acc: 0.9044\n",
      "Epoch 170/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1547 - acc: 0.9104 - val_loss: 0.1540 - val_acc: 0.9148\n",
      "Epoch 171/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1560 - acc: 0.8918 - val_loss: 0.1569 - val_acc: 0.8909\n",
      "Epoch 172/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1557 - acc: 0.9043 - val_loss: 0.1542 - val_acc: 0.9142\n",
      "Epoch 173/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1577 - acc: 0.8978 - val_loss: 0.1555 - val_acc: 0.9241\n",
      "Epoch 174/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1554 - acc: 0.9095 - val_loss: 0.1564 - val_acc: 0.9019\n",
      "Epoch 175/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1542 - acc: 0.9208 - val_loss: 0.1544 - val_acc: 0.9160\n",
      "Epoch 176/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1556 - acc: 0.9105 - val_loss: 0.1541 - val_acc: 0.9122\n",
      "Epoch 177/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1542 - acc: 0.9035 - val_loss: 0.1536 - val_acc: 0.9250\n",
      "Epoch 178/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1539 - acc: 0.9165 - val_loss: 0.1536 - val_acc: 0.9284\n",
      "Epoch 179/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1554 - acc: 0.9001 - val_loss: 0.1548 - val_acc: 0.9202\n",
      "Epoch 180/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1564 - acc: 0.8933 - val_loss: 0.1550 - val_acc: 0.9081\n",
      "Epoch 181/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1554 - acc: 0.8991 - val_loss: 0.1553 - val_acc: 0.9223\n",
      "Epoch 182/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1568 - acc: 0.8891 - val_loss: 0.1548 - val_acc: 0.8923\n",
      "Epoch 183/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1542 - acc: 0.9124 - val_loss: 0.1544 - val_acc: 0.9175\n",
      "Epoch 184/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1565 - acc: 0.8882 - val_loss: 0.1538 - val_acc: 0.9139\n",
      "Epoch 185/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1560 - acc: 0.8909 - val_loss: 0.1538 - val_acc: 0.9067\n",
      "Epoch 186/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1552 - acc: 0.9043 - val_loss: 0.1549 - val_acc: 0.8972\n",
      "Epoch 187/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1556 - acc: 0.8988 - val_loss: 0.1538 - val_acc: 0.9066\n",
      "Epoch 188/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1555 - acc: 0.9019 - val_loss: 0.1542 - val_acc: 0.9073\n",
      "Epoch 189/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1558 - acc: 0.8938 - val_loss: 0.1536 - val_acc: 0.9341\n",
      "Epoch 190/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1580 - acc: 0.9012 - val_loss: 0.1544 - val_acc: 0.9278\n",
      "Epoch 191/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1548 - acc: 0.9165 - val_loss: 0.1591 - val_acc: 0.8754\n",
      "Epoch 192/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1554 - acc: 0.9007 - val_loss: 0.1543 - val_acc: 0.9356\n",
      "Epoch 193/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1550 - acc: 0.9064 - val_loss: 0.1553 - val_acc: 0.9083\n",
      "Epoch 194/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1543 - acc: 0.9164 - val_loss: 0.1566 - val_acc: 0.8884\n",
      "Epoch 195/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1542 - acc: 0.9083 - val_loss: 0.1542 - val_acc: 0.9120\n",
      "Epoch 196/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1565 - acc: 0.8765 - val_loss: 0.1558 - val_acc: 0.9071\n",
      "Epoch 197/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1583 - acc: 0.8801 - val_loss: 0.1585 - val_acc: 0.8801\n",
      "Epoch 198/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1569 - acc: 0.8846 - val_loss: 0.1554 - val_acc: 0.8874\n",
      "Epoch 199/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1547 - acc: 0.9025 - val_loss: 0.1552 - val_acc: 0.8742\n",
      "Epoch 200/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1564 - acc: 0.8918 - val_loss: 0.1561 - val_acc: 0.8993\n",
      "Epoch 201/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1545 - acc: 0.9149 - val_loss: 0.1541 - val_acc: 0.9302\n",
      "Epoch 202/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1545 - acc: 0.9076 - val_loss: 0.1536 - val_acc: 0.9276\n",
      "Epoch 203/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1541 - acc: 0.9140 - val_loss: 0.1552 - val_acc: 0.9189\n",
      "Epoch 204/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1578 - acc: 0.8839 - val_loss: 0.1564 - val_acc: 0.8762\n",
      "Epoch 205/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1552 - acc: 0.8997 - val_loss: 0.1541 - val_acc: 0.9011\n",
      "Epoch 206/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1555 - acc: 0.8922 - val_loss: 0.1559 - val_acc: 0.9110\n",
      "Epoch 207/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1586 - acc: 0.8915 - val_loss: 0.1640 - val_acc: 0.8172\n",
      "Epoch 208/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1576 - acc: 0.8801 - val_loss: 0.1546 - val_acc: 0.9224\n",
      "Epoch 209/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1541 - acc: 0.9222 - val_loss: 0.1544 - val_acc: 0.9273\n",
      "Epoch 210/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1545 - acc: 0.9132 - val_loss: 0.1544 - val_acc: 0.8919\n",
      "Epoch 211/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1547 - acc: 0.9097 - val_loss: 0.1542 - val_acc: 0.9247\n",
      "Epoch 212/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1556 - acc: 0.8969 - val_loss: 0.1535 - val_acc: 0.9246\n",
      "Epoch 213/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1542 - acc: 0.9137 - val_loss: 0.1536 - val_acc: 0.9271\n",
      "Epoch 214/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1542 - acc: 0.9138 - val_loss: 0.1546 - val_acc: 0.9334\n",
      "Epoch 215/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1548 - acc: 0.9092 - val_loss: 0.1546 - val_acc: 0.9150\n",
      "Epoch 216/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1546 - acc: 0.9075 - val_loss: 0.1577 - val_acc: 0.8918\n",
      "Epoch 217/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1544 - acc: 0.9090 - val_loss: 0.1561 - val_acc: 0.9114\n",
      "Epoch 218/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1563 - acc: 0.8976 - val_loss: 0.1548 - val_acc: 0.9111\n",
      "Epoch 219/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1563 - acc: 0.8973 - val_loss: 0.1549 - val_acc: 0.8918\n",
      "Epoch 220/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1555 - acc: 0.9058 - val_loss: 0.1540 - val_acc: 0.9270\n",
      "Epoch 221/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1544 - acc: 0.9133 - val_loss: 0.1543 - val_acc: 0.9258\n",
      "Epoch 222/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1549 - acc: 0.9045 - val_loss: 0.1643 - val_acc: 0.9042\n",
      "Epoch 223/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1569 - acc: 0.8822 - val_loss: 0.1584 - val_acc: 0.8468\n",
      "Epoch 224/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1547 - acc: 0.9033 - val_loss: 0.1544 - val_acc: 0.9102\n",
      "Epoch 225/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1540 - acc: 0.9212 - val_loss: 0.1541 - val_acc: 0.9396\n",
      "Epoch 226/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1549 - acc: 0.9157 - val_loss: 0.1554 - val_acc: 0.9154\n",
      "Epoch 227/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1542 - acc: 0.9113 - val_loss: 0.1543 - val_acc: 0.9105\n",
      "Epoch 228/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1581 - acc: 0.8662 - val_loss: 0.1630 - val_acc: 0.8192\n",
      "Epoch 229/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1582 - acc: 0.8730 - val_loss: 0.1564 - val_acc: 0.8984\n",
      "Epoch 230/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1558 - acc: 0.8988 - val_loss: 0.1551 - val_acc: 0.8901\n",
      "Epoch 231/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1546 - acc: 0.9107 - val_loss: 0.1571 - val_acc: 0.9117\n",
      "Epoch 232/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1577 - acc: 0.8697 - val_loss: 0.1553 - val_acc: 0.9137\n",
      "Epoch 233/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1545 - acc: 0.9084 - val_loss: 0.1541 - val_acc: 0.9102\n",
      "Epoch 234/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1554 - acc: 0.9019 - val_loss: 0.1553 - val_acc: 0.9090\n",
      "Epoch 235/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1549 - acc: 0.9064 - val_loss: 0.1554 - val_acc: 0.8931\n",
      "Epoch 236/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1539 - acc: 0.9266 - val_loss: 0.1546 - val_acc: 0.9124\n",
      "Epoch 237/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1589 - acc: 0.8872 - val_loss: 0.1571 - val_acc: 0.9022\n",
      "Epoch 238/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1573 - acc: 0.8955 - val_loss: 0.1582 - val_acc: 0.8402\n",
      "Epoch 239/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1555 - acc: 0.9058 - val_loss: 0.1569 - val_acc: 0.8977\n",
      "Epoch 240/500\n",
      "195990/195990 [==============================] - 8s 42us/step - loss: 0.1546 - acc: 0.9134 - val_loss: 0.1538 - val_acc: 0.9143\n",
      "Epoch 241/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1551 - acc: 0.8982 - val_loss: 0.1541 - val_acc: 0.9259\n",
      "Epoch 242/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1546 - acc: 0.9086 - val_loss: 0.1538 - val_acc: 0.9215\n",
      "Epoch 243/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1546 - acc: 0.9039 - val_loss: 0.1575 - val_acc: 0.9128\n",
      "Epoch 244/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1552 - acc: 0.9017 - val_loss: 0.1539 - val_acc: 0.9299\n",
      "Epoch 245/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1554 - acc: 0.8969 - val_loss: 0.1566 - val_acc: 0.8119\n",
      "Epoch 246/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1549 - acc: 0.8998 - val_loss: 0.1544 - val_acc: 0.8804\n",
      "Epoch 247/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1546 - acc: 0.9125 - val_loss: 0.1568 - val_acc: 0.8495\n",
      "Epoch 248/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1546 - acc: 0.9078 - val_loss: 0.1542 - val_acc: 0.9262\n",
      "Epoch 249/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1560 - acc: 0.9026 - val_loss: 0.1697 - val_acc: 0.8708\n",
      "Epoch 250/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1566 - acc: 0.8988 - val_loss: 0.1551 - val_acc: 0.9129\n",
      "Epoch 251/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1566 - acc: 0.8864 - val_loss: 0.1612 - val_acc: 0.8077\n",
      "Epoch 252/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1590 - acc: 0.8870 - val_loss: 0.1620 - val_acc: 0.8511\n",
      "Epoch 253/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1566 - acc: 0.8880 - val_loss: 0.1545 - val_acc: 0.9135\n",
      "Epoch 254/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1544 - acc: 0.9104 - val_loss: 0.1543 - val_acc: 0.9102\n",
      "Epoch 255/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1541 - acc: 0.9109 - val_loss: 0.1539 - val_acc: 0.9054\n",
      "Epoch 256/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1553 - acc: 0.8960 - val_loss: 0.1542 - val_acc: 0.9206\n",
      "Epoch 257/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1561 - acc: 0.8989 - val_loss: 0.1549 - val_acc: 0.9317\n",
      "Epoch 258/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1548 - acc: 0.8998 - val_loss: 0.1537 - val_acc: 0.9165\n",
      "Epoch 259/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1541 - acc: 0.9268 - val_loss: 0.1561 - val_acc: 0.9013\n",
      "Epoch 260/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1542 - acc: 0.9220 - val_loss: 0.1535 - val_acc: 0.9382\n",
      "Epoch 261/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1553 - acc: 0.9032 - val_loss: 0.1601 - val_acc: 0.8813\n",
      "Epoch 262/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1568 - acc: 0.9053 - val_loss: 0.1572 - val_acc: 0.9131\n",
      "Epoch 263/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1558 - acc: 0.8992 - val_loss: 0.1602 - val_acc: 0.8524\n",
      "Epoch 264/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1552 - acc: 0.9007 - val_loss: 0.1547 - val_acc: 0.9072\n",
      "Epoch 265/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1543 - acc: 0.9141 - val_loss: 0.1540 - val_acc: 0.9193\n",
      "Epoch 266/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1543 - acc: 0.9102 - val_loss: 0.1537 - val_acc: 0.9228\n",
      "Epoch 267/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1541 - acc: 0.9187 - val_loss: 0.1564 - val_acc: 0.8940\n",
      "Epoch 268/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1549 - acc: 0.8992 - val_loss: 0.1546 - val_acc: 0.9186\n",
      "Epoch 269/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1541 - acc: 0.9154 - val_loss: 0.1544 - val_acc: 0.9323\n",
      "Epoch 270/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1550 - acc: 0.8934 - val_loss: 0.1544 - val_acc: 0.9211\n",
      "Epoch 271/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1565 - acc: 0.8898 - val_loss: 0.1565 - val_acc: 0.8639\n",
      "Epoch 272/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1569 - acc: 0.8794 - val_loss: 0.1578 - val_acc: 0.8672\n",
      "Epoch 273/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1567 - acc: 0.8966 - val_loss: 0.1550 - val_acc: 0.9239\n",
      "Epoch 274/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1573 - acc: 0.8866 - val_loss: 0.1566 - val_acc: 0.8817\n",
      "Epoch 275/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1540 - acc: 0.9179 - val_loss: 0.1536 - val_acc: 0.9259\n",
      "Epoch 276/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1539 - acc: 0.9193 - val_loss: 0.1552 - val_acc: 0.9064\n",
      "Epoch 277/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1552 - acc: 0.9021 - val_loss: 0.1554 - val_acc: 0.9181\n",
      "Epoch 278/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1545 - acc: 0.9149 - val_loss: 0.1559 - val_acc: 0.8473\n",
      "Epoch 279/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1558 - acc: 0.8978 - val_loss: 0.1539 - val_acc: 0.9054\n",
      "Epoch 280/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1549 - acc: 0.9040 - val_loss: 0.1608 - val_acc: 0.8591\n",
      "Epoch 281/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1549 - acc: 0.8952 - val_loss: 0.1538 - val_acc: 0.9344\n",
      "Epoch 282/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1553 - acc: 0.8882 - val_loss: 0.1547 - val_acc: 0.9139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1565 - acc: 0.8902 - val_loss: 0.1546 - val_acc: 0.9031\n",
      "Epoch 284/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1547 - acc: 0.9050 - val_loss: 0.1613 - val_acc: 0.8140\n",
      "Epoch 285/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1550 - acc: 0.9012 - val_loss: 0.1542 - val_acc: 0.9102\n",
      "Epoch 286/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1547 - acc: 0.9187 - val_loss: 0.1554 - val_acc: 0.8892\n",
      "Epoch 287/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1577 - acc: 0.8760 - val_loss: 0.1609 - val_acc: 0.8656\n",
      "Epoch 288/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1560 - acc: 0.8929 - val_loss: 0.1539 - val_acc: 0.9261\n",
      "Epoch 289/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1566 - acc: 0.8924 - val_loss: 0.1609 - val_acc: 0.8208\n",
      "Epoch 290/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1552 - acc: 0.9093 - val_loss: 0.1542 - val_acc: 0.9244\n",
      "Epoch 291/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1565 - acc: 0.9200 - val_loss: 0.1713 - val_acc: 0.8703\n",
      "Epoch 292/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1573 - acc: 0.9082 - val_loss: 0.1548 - val_acc: 0.9199\n",
      "Epoch 293/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1571 - acc: 0.8966 - val_loss: 0.1564 - val_acc: 0.9090\n",
      "Epoch 294/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1557 - acc: 0.8967 - val_loss: 0.1544 - val_acc: 0.9306\n",
      "Epoch 295/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1544 - acc: 0.9189 - val_loss: 0.1541 - val_acc: 0.9136\n",
      "Epoch 296/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1547 - acc: 0.9053 - val_loss: 0.1539 - val_acc: 0.9113\n",
      "Epoch 297/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1557 - acc: 0.8981 - val_loss: 0.1571 - val_acc: 0.9088\n",
      "Epoch 298/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1560 - acc: 0.8870 - val_loss: 0.1539 - val_acc: 0.9089\n",
      "Epoch 299/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1543 - acc: 0.9078 - val_loss: 0.1537 - val_acc: 0.9400\n",
      "Epoch 300/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1559 - acc: 0.9070 - val_loss: 0.1663 - val_acc: 0.8536\n",
      "Epoch 301/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1568 - acc: 0.9017 - val_loss: 0.1561 - val_acc: 0.8702\n",
      "Epoch 302/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1549 - acc: 0.9001 - val_loss: 0.1551 - val_acc: 0.8891\n",
      "Epoch 303/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1548 - acc: 0.9016 - val_loss: 0.1539 - val_acc: 0.9124\n",
      "Epoch 304/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1549 - acc: 0.9100 - val_loss: 0.1558 - val_acc: 0.9116\n",
      "Epoch 305/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1540 - acc: 0.9189 - val_loss: 0.1547 - val_acc: 0.9190\n",
      "Epoch 306/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1549 - acc: 0.9035 - val_loss: 0.1549 - val_acc: 0.9110\n",
      "Epoch 307/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1545 - acc: 0.9080 - val_loss: 0.1540 - val_acc: 0.9044\n",
      "Epoch 308/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1540 - acc: 0.9130 - val_loss: 0.1547 - val_acc: 0.8730\n",
      "Epoch 309/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1617 - acc: 0.8084 - val_loss: 0.1591 - val_acc: 0.8196\n",
      "Epoch 310/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1558 - acc: 0.8654 - val_loss: 0.1566 - val_acc: 0.8883\n",
      "Epoch 311/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1563 - acc: 0.8949 - val_loss: 0.1548 - val_acc: 0.9146\n",
      "Epoch 312/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1556 - acc: 0.9034 - val_loss: 0.1555 - val_acc: 0.8829\n",
      "Epoch 313/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1588 - acc: 0.8697 - val_loss: 0.1560 - val_acc: 0.8046\n",
      "Epoch 314/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1560 - acc: 0.8806 - val_loss: 0.1570 - val_acc: 0.8734\n",
      "Epoch 315/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1557 - acc: 0.8936 - val_loss: 0.1559 - val_acc: 0.8457\n",
      "Epoch 316/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1544 - acc: 0.9085 - val_loss: 0.1534 - val_acc: 0.9365\n",
      "Epoch 317/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1545 - acc: 0.9131 - val_loss: 0.1547 - val_acc: 0.8836\n",
      "Epoch 318/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1539 - acc: 0.9220 - val_loss: 0.1535 - val_acc: 0.9325\n",
      "Epoch 319/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1539 - acc: 0.9237 - val_loss: 0.1548 - val_acc: 0.9160\n",
      "Epoch 320/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1582 - acc: 0.8875 - val_loss: 0.1557 - val_acc: 0.9056\n",
      "Epoch 321/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1552 - acc: 0.9024 - val_loss: 0.1550 - val_acc: 0.9274\n",
      "Epoch 322/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1554 - acc: 0.9065 - val_loss: 0.1569 - val_acc: 0.9005\n",
      "Epoch 323/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1551 - acc: 0.9076 - val_loss: 0.1556 - val_acc: 0.8709\n",
      "Epoch 324/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1574 - acc: 0.8627 - val_loss: 0.1578 - val_acc: 0.8973\n",
      "Epoch 325/500\n",
      "195990/195990 [==============================] - 8s 42us/step - loss: 0.1553 - acc: 0.9136 - val_loss: 0.1544 - val_acc: 0.9222\n",
      "Epoch 326/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1539 - acc: 0.9233 - val_loss: 0.1542 - val_acc: 0.9112\n",
      "Epoch 327/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1548 - acc: 0.9108 - val_loss: 0.1555 - val_acc: 0.9177\n",
      "Epoch 328/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1568 - acc: 0.8933 - val_loss: 0.1540 - val_acc: 0.9346\n",
      "Epoch 329/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1541 - acc: 0.9150 - val_loss: 0.1564 - val_acc: 0.9051\n",
      "Epoch 330/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1547 - acc: 0.8981 - val_loss: 0.1590 - val_acc: 0.8762\n",
      "Epoch 331/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1547 - acc: 0.9013 - val_loss: 0.1552 - val_acc: 0.8503\n",
      "Epoch 332/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1549 - acc: 0.9069 - val_loss: 0.1577 - val_acc: 0.9065\n",
      "Epoch 333/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1587 - acc: 0.8636 - val_loss: 0.1547 - val_acc: 0.9210\n",
      "Epoch 334/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1556 - acc: 0.9080 - val_loss: 0.1542 - val_acc: 0.9278\n",
      "Epoch 335/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1559 - acc: 0.9159 - val_loss: 0.1541 - val_acc: 0.9262\n",
      "Epoch 336/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1545 - acc: 0.9193 - val_loss: 0.1550 - val_acc: 0.9230\n",
      "Epoch 337/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1548 - acc: 0.9132 - val_loss: 0.1538 - val_acc: 0.9220\n",
      "Epoch 338/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1545 - acc: 0.9113 - val_loss: 0.1560 - val_acc: 0.9186\n",
      "Epoch 339/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1558 - acc: 0.9023 - val_loss: 0.1541 - val_acc: 0.9241\n",
      "Epoch 340/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1555 - acc: 0.9043 - val_loss: 0.1552 - val_acc: 0.8319\n",
      "Epoch 341/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1544 - acc: 0.9107 - val_loss: 0.1542 - val_acc: 0.8842\n",
      "Epoch 342/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1536 - acc: 0.9217 - val_loss: 0.1601 - val_acc: 0.9248\n",
      "Epoch 343/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1549 - acc: 0.9009 - val_loss: 0.1537 - val_acc: 0.8965\n",
      "Epoch 344/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1546 - acc: 0.9038 - val_loss: 0.1552 - val_acc: 0.8880\n",
      "Epoch 345/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1543 - acc: 0.9104 - val_loss: 0.1542 - val_acc: 0.9152\n",
      "Epoch 346/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1570 - acc: 0.8953 - val_loss: 0.1557 - val_acc: 0.8834\n",
      "Epoch 347/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1562 - acc: 0.8827 - val_loss: 0.1535 - val_acc: 0.9126\n",
      "Epoch 348/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1536 - acc: 0.9161 - val_loss: 0.1536 - val_acc: 0.9377\n",
      "Epoch 349/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1552 - acc: 0.8976 - val_loss: 0.1546 - val_acc: 0.9141\n",
      "Epoch 350/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1542 - acc: 0.9070 - val_loss: 0.1552 - val_acc: 0.9205\n",
      "Epoch 351/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1554 - acc: 0.8929 - val_loss: 0.1643 - val_acc: 0.8711\n",
      "Epoch 352/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1548 - acc: 0.9122 - val_loss: 0.1540 - val_acc: 0.9126\n",
      "Epoch 353/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1558 - acc: 0.9029 - val_loss: 0.1538 - val_acc: 0.9368\n",
      "Epoch 354/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1550 - acc: 0.9078 - val_loss: 0.1564 - val_acc: 0.8475\n",
      "Epoch 355/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1572 - acc: 0.8920 - val_loss: 0.1540 - val_acc: 0.9329\n",
      "Epoch 356/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1544 - acc: 0.9134 - val_loss: 0.1552 - val_acc: 0.8817\n",
      "Epoch 357/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1566 - acc: 0.8882 - val_loss: 0.1573 - val_acc: 0.9143\n",
      "Epoch 358/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1548 - acc: 0.9115 - val_loss: 0.1536 - val_acc: 0.9166\n",
      "Epoch 359/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1545 - acc: 0.9129 - val_loss: 0.1564 - val_acc: 0.8844\n",
      "Epoch 360/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1545 - acc: 0.9076 - val_loss: 0.1539 - val_acc: 0.9208\n",
      "Epoch 361/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1544 - acc: 0.9102 - val_loss: 0.1562 - val_acc: 0.9035\n",
      "Epoch 362/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1556 - acc: 0.9004 - val_loss: 0.1653 - val_acc: 0.9037\n",
      "Epoch 363/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1562 - acc: 0.8968 - val_loss: 0.1611 - val_acc: 0.8556\n",
      "Epoch 364/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1569 - acc: 0.8763 - val_loss: 0.1559 - val_acc: 0.8759\n",
      "Epoch 365/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1554 - acc: 0.9075 - val_loss: 0.1547 - val_acc: 0.9347\n",
      "Epoch 366/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1555 - acc: 0.9113 - val_loss: 0.1540 - val_acc: 0.9221\n",
      "Epoch 367/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1545 - acc: 0.9120 - val_loss: 0.1552 - val_acc: 0.9173\n",
      "Epoch 368/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1542 - acc: 0.9124 - val_loss: 0.1534 - val_acc: 0.8900\n",
      "Epoch 369/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1540 - acc: 0.9124 - val_loss: 0.1539 - val_acc: 0.9080\n",
      "Epoch 370/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1547 - acc: 0.9149 - val_loss: 0.1540 - val_acc: 0.9248\n",
      "Epoch 371/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1551 - acc: 0.9033 - val_loss: 0.1543 - val_acc: 0.9188\n",
      "Epoch 372/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1560 - acc: 0.8928 - val_loss: 0.1598 - val_acc: 0.9093\n",
      "Epoch 373/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1561 - acc: 0.8959 - val_loss: 0.1553 - val_acc: 0.9030\n",
      "Epoch 374/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1541 - acc: 0.9162 - val_loss: 0.1536 - val_acc: 0.9287\n",
      "Epoch 375/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1540 - acc: 0.9150 - val_loss: 0.1543 - val_acc: 0.9176\n",
      "Epoch 376/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1553 - acc: 0.8991 - val_loss: 0.1550 - val_acc: 0.8936\n",
      "Epoch 377/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1538 - acc: 0.9177 - val_loss: 0.1547 - val_acc: 0.9227\n",
      "Epoch 378/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1577 - acc: 0.8958 - val_loss: 0.1545 - val_acc: 0.9182\n",
      "Epoch 379/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1563 - acc: 0.8972 - val_loss: 0.1540 - val_acc: 0.9357\n",
      "Epoch 380/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1543 - acc: 0.9099 - val_loss: 0.1538 - val_acc: 0.9236\n",
      "Epoch 381/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1539 - acc: 0.9198 - val_loss: 0.1540 - val_acc: 0.9201\n",
      "Epoch 382/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1579 - acc: 0.8795 - val_loss: 0.1586 - val_acc: 0.8861\n",
      "Epoch 383/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1555 - acc: 0.8992 - val_loss: 0.1540 - val_acc: 0.9182\n",
      "Epoch 384/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1544 - acc: 0.9149 - val_loss: 0.1538 - val_acc: 0.9182\n",
      "Epoch 385/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1540 - acc: 0.9145 - val_loss: 0.1537 - val_acc: 0.9194\n",
      "Epoch 386/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1553 - acc: 0.9060 - val_loss: 0.1562 - val_acc: 0.9088\n",
      "Epoch 387/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1553 - acc: 0.9018 - val_loss: 0.1568 - val_acc: 0.8977\n",
      "Epoch 388/500\n",
      "195990/195990 [==============================] - 8s 42us/step - loss: 0.1548 - acc: 0.9154 - val_loss: 0.1538 - val_acc: 0.9273\n",
      "Epoch 389/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1548 - acc: 0.9113 - val_loss: 0.1543 - val_acc: 0.8891\n",
      "Epoch 390/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1540 - acc: 0.9155 - val_loss: 0.1540 - val_acc: 0.9327\n",
      "Epoch 391/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1550 - acc: 0.9033 - val_loss: 0.1577 - val_acc: 0.8950\n",
      "Epoch 392/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1560 - acc: 0.8904 - val_loss: 0.1539 - val_acc: 0.9121\n",
      "Epoch 393/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1548 - acc: 0.8936 - val_loss: 0.1553 - val_acc: 0.9130\n",
      "Epoch 394/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1570 - acc: 0.8956 - val_loss: 0.1547 - val_acc: 0.9042\n",
      "Epoch 395/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1611 - acc: 0.8515 - val_loss: 0.1591 - val_acc: 0.8701\n",
      "Epoch 396/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1575 - acc: 0.8961 - val_loss: 0.1566 - val_acc: 0.8974\n",
      "Epoch 397/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1552 - acc: 0.9109 - val_loss: 0.1549 - val_acc: 0.9236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1543 - acc: 0.9235 - val_loss: 0.1540 - val_acc: 0.9321\n",
      "Epoch 399/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1544 - acc: 0.9164 - val_loss: 0.1556 - val_acc: 0.9235\n",
      "Epoch 400/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1540 - acc: 0.9134 - val_loss: 0.1535 - val_acc: 0.9389\n",
      "Epoch 401/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1561 - acc: 0.8865 - val_loss: 0.1541 - val_acc: 0.9084\n",
      "Epoch 402/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1557 - acc: 0.9085 - val_loss: 0.1545 - val_acc: 0.9302\n",
      "Epoch 403/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1543 - acc: 0.9231 - val_loss: 0.1604 - val_acc: 0.9033\n",
      "Epoch 404/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1562 - acc: 0.9001 - val_loss: 0.1548 - val_acc: 0.9319\n",
      "Epoch 405/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1539 - acc: 0.9239 - val_loss: 0.1536 - val_acc: 0.9316\n",
      "Epoch 406/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1543 - acc: 0.9091 - val_loss: 0.1550 - val_acc: 0.8653\n",
      "Epoch 407/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1567 - acc: 0.9012 - val_loss: 0.1542 - val_acc: 0.9330\n",
      "Epoch 408/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1540 - acc: 0.9292 - val_loss: 0.1572 - val_acc: 0.9359\n",
      "Epoch 409/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1586 - acc: 0.9013 - val_loss: 0.1562 - val_acc: 0.8810\n",
      "Epoch 410/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1544 - acc: 0.9210 - val_loss: 0.1544 - val_acc: 0.9131\n",
      "Epoch 411/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1541 - acc: 0.9229 - val_loss: 0.1601 - val_acc: 0.9111\n",
      "Epoch 412/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1555 - acc: 0.8992 - val_loss: 0.1579 - val_acc: 0.8664\n",
      "Epoch 413/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1559 - acc: 0.8992 - val_loss: 0.1541 - val_acc: 0.9204\n",
      "Epoch 414/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1583 - acc: 0.8811 - val_loss: 0.1546 - val_acc: 0.9249\n",
      "Epoch 415/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1541 - acc: 0.9217 - val_loss: 0.1539 - val_acc: 0.9339\n",
      "Epoch 416/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1554 - acc: 0.8901 - val_loss: 0.1562 - val_acc: 0.8336\n",
      "Epoch 417/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1551 - acc: 0.8948 - val_loss: 0.1539 - val_acc: 0.9076\n",
      "Epoch 418/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1535 - acc: 0.9282 - val_loss: 0.1537 - val_acc: 0.9221\n",
      "Epoch 419/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1543 - acc: 0.9171 - val_loss: 0.1557 - val_acc: 0.8767\n",
      "Epoch 420/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1544 - acc: 0.9071 - val_loss: 0.1583 - val_acc: 0.8563\n",
      "Epoch 421/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1551 - acc: 0.8958 - val_loss: 0.1560 - val_acc: 0.8551\n",
      "Epoch 422/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1546 - acc: 0.9118 - val_loss: 0.1536 - val_acc: 0.9339\n",
      "Epoch 423/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1552 - acc: 0.9025 - val_loss: 0.1538 - val_acc: 0.9225\n",
      "Epoch 424/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1563 - acc: 0.9081 - val_loss: 0.1547 - val_acc: 0.9099\n",
      "Epoch 425/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1567 - acc: 0.8843 - val_loss: 0.1535 - val_acc: 0.9335\n",
      "Epoch 426/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1548 - acc: 0.8985 - val_loss: 0.1545 - val_acc: 0.9021\n",
      "Epoch 427/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1538 - acc: 0.9212 - val_loss: 0.1545 - val_acc: 0.9226\n",
      "Epoch 428/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1541 - acc: 0.9176 - val_loss: 0.1537 - val_acc: 0.9260\n",
      "Epoch 429/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1545 - acc: 0.9081 - val_loss: 0.1558 - val_acc: 0.9179\n",
      "Epoch 430/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1546 - acc: 0.9000 - val_loss: 0.1536 - val_acc: 0.9301\n",
      "Epoch 431/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1545 - acc: 0.9055 - val_loss: 0.1551 - val_acc: 0.9273\n",
      "Epoch 432/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1553 - acc: 0.9084 - val_loss: 0.1540 - val_acc: 0.9245\n",
      "Epoch 433/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1537 - acc: 0.9212 - val_loss: 0.1540 - val_acc: 0.9177\n",
      "Epoch 434/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1563 - acc: 0.8994 - val_loss: 0.1606 - val_acc: 0.8194\n",
      "Epoch 435/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1695 - acc: 0.7934 - val_loss: 0.1685 - val_acc: 0.8539\n",
      "Epoch 436/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1614 - acc: 0.8796 - val_loss: 0.1595 - val_acc: 0.8949\n",
      "Epoch 437/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1595 - acc: 0.9001 - val_loss: 0.1596 - val_acc: 0.9073\n",
      "Epoch 438/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1562 - acc: 0.9123 - val_loss: 0.1555 - val_acc: 0.9215\n",
      "Epoch 439/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1564 - acc: 0.9086 - val_loss: 0.1553 - val_acc: 0.9100\n",
      "Epoch 440/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1562 - acc: 0.9083 - val_loss: 0.1562 - val_acc: 0.8945\n",
      "Epoch 441/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1548 - acc: 0.9137 - val_loss: 0.1547 - val_acc: 0.9210\n",
      "Epoch 442/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1559 - acc: 0.9087 - val_loss: 0.1565 - val_acc: 0.9101\n",
      "Epoch 443/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1559 - acc: 0.8980 - val_loss: 0.1565 - val_acc: 0.9081\n",
      "Epoch 444/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1557 - acc: 0.8930 - val_loss: 0.1545 - val_acc: 0.8802\n",
      "Epoch 445/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1546 - acc: 0.9026 - val_loss: 0.1558 - val_acc: 0.8536\n",
      "Epoch 446/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1551 - acc: 0.9075 - val_loss: 0.1570 - val_acc: 0.8985\n",
      "Epoch 447/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1565 - acc: 0.8929 - val_loss: 0.1602 - val_acc: 0.8530\n",
      "Epoch 448/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1560 - acc: 0.9074 - val_loss: 0.1570 - val_acc: 0.8624\n",
      "Epoch 449/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1562 - acc: 0.9020 - val_loss: 0.1540 - val_acc: 0.9366\n",
      "Epoch 450/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1550 - acc: 0.9115 - val_loss: 0.1604 - val_acc: 0.8783\n",
      "Epoch 451/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1552 - acc: 0.8984 - val_loss: 0.1548 - val_acc: 0.8767\n",
      "Epoch 452/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1560 - acc: 0.9047 - val_loss: 0.1556 - val_acc: 0.8921\n",
      "Epoch 453/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1566 - acc: 0.8957 - val_loss: 0.1561 - val_acc: 0.9118\n",
      "Epoch 454/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1557 - acc: 0.9091 - val_loss: 0.1548 - val_acc: 0.9206\n",
      "Epoch 455/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1536 - acc: 0.9274 - val_loss: 0.1535 - val_acc: 0.9238\n",
      "Epoch 456/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1544 - acc: 0.9152 - val_loss: 0.1539 - val_acc: 0.9209\n",
      "Epoch 457/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1565 - acc: 0.8966 - val_loss: 0.1548 - val_acc: 0.9297\n",
      "Epoch 458/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1545 - acc: 0.9082 - val_loss: 0.1555 - val_acc: 0.9047\n",
      "Epoch 459/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1546 - acc: 0.9076 - val_loss: 0.1546 - val_acc: 0.9129\n",
      "Epoch 460/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1545 - acc: 0.9099 - val_loss: 0.1534 - val_acc: 0.9317\n",
      "Epoch 461/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1553 - acc: 0.9184 - val_loss: 0.1590 - val_acc: 0.8685\n",
      "Epoch 462/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1554 - acc: 0.8883 - val_loss: 0.1547 - val_acc: 0.8853\n",
      "Epoch 463/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1539 - acc: 0.9195 - val_loss: 0.1541 - val_acc: 0.9185\n",
      "Epoch 464/500\n",
      "195990/195990 [==============================] - 8s 39us/step - loss: 0.1538 - acc: 0.9202 - val_loss: 0.1537 - val_acc: 0.9358\n",
      "Epoch 465/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1545 - acc: 0.9057 - val_loss: 0.1572 - val_acc: 0.8547\n",
      "Epoch 466/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1564 - acc: 0.8875 - val_loss: 0.1583 - val_acc: 0.8944\n",
      "Epoch 467/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1588 - acc: 0.8800 - val_loss: 0.1546 - val_acc: 0.9088\n",
      "Epoch 468/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1542 - acc: 0.9200 - val_loss: 0.1539 - val_acc: 0.9357\n",
      "Epoch 469/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1556 - acc: 0.9142 - val_loss: 0.1547 - val_acc: 0.8873\n",
      "Epoch 470/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1553 - acc: 0.9039 - val_loss: 0.1541 - val_acc: 0.9254\n",
      "Epoch 471/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1561 - acc: 0.9064 - val_loss: 0.1545 - val_acc: 0.8919\n",
      "Epoch 472/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1557 - acc: 0.9029 - val_loss: 0.1646 - val_acc: 0.8496\n",
      "Epoch 473/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1570 - acc: 0.9033 - val_loss: 0.1535 - val_acc: 0.9329\n",
      "Epoch 474/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1550 - acc: 0.9042 - val_loss: 0.1536 - val_acc: 0.9191\n",
      "Epoch 475/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1540 - acc: 0.9154 - val_loss: 0.1550 - val_acc: 0.9159\n",
      "Epoch 476/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1558 - acc: 0.8842 - val_loss: 0.1586 - val_acc: 0.7772\n",
      "Epoch 477/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1547 - acc: 0.9076 - val_loss: 0.1537 - val_acc: 0.9110\n",
      "Epoch 478/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1546 - acc: 0.9088 - val_loss: 0.1546 - val_acc: 0.9072\n",
      "Epoch 479/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1546 - acc: 0.9129 - val_loss: 0.1541 - val_acc: 0.9145\n",
      "Epoch 480/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1552 - acc: 0.9004 - val_loss: 0.1543 - val_acc: 0.8881\n",
      "Epoch 481/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1552 - acc: 0.9043 - val_loss: 0.1559 - val_acc: 0.8449\n",
      "Epoch 482/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1564 - acc: 0.8893 - val_loss: 0.1612 - val_acc: 0.8467\n",
      "Epoch 483/500\n",
      "195990/195990 [==============================] - 8s 42us/step - loss: 0.1557 - acc: 0.8942 - val_loss: 0.1538 - val_acc: 0.9202\n",
      "Epoch 484/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1565 - acc: 0.9057 - val_loss: 0.1549 - val_acc: 0.8832\n",
      "Epoch 485/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1549 - acc: 0.9086 - val_loss: 0.1544 - val_acc: 0.9081\n",
      "Epoch 486/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1554 - acc: 0.9013 - val_loss: 0.1549 - val_acc: 0.8849\n",
      "Epoch 487/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1540 - acc: 0.9193 - val_loss: 0.1578 - val_acc: 0.8611\n",
      "Epoch 488/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1586 - acc: 0.8697 - val_loss: 0.1559 - val_acc: 0.9038\n",
      "Epoch 489/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1547 - acc: 0.9142 - val_loss: 0.1543 - val_acc: 0.9235\n",
      "Epoch 490/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1557 - acc: 0.9083 - val_loss: 0.1613 - val_acc: 0.8924\n",
      "Epoch 491/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1553 - acc: 0.9101 - val_loss: 0.1539 - val_acc: 0.9159\n",
      "Epoch 492/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1554 - acc: 0.9049 - val_loss: 0.1543 - val_acc: 0.8941\n",
      "Epoch 493/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1552 - acc: 0.8990 - val_loss: 0.1577 - val_acc: 0.8939\n",
      "Epoch 494/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1553 - acc: 0.9040 - val_loss: 0.1543 - val_acc: 0.9124\n",
      "Epoch 495/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1543 - acc: 0.9142 - val_loss: 0.1547 - val_acc: 0.9103\n",
      "Epoch 496/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1553 - acc: 0.9011 - val_loss: 0.1541 - val_acc: 0.9340\n",
      "Epoch 497/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1542 - acc: 0.9193 - val_loss: 0.1550 - val_acc: 0.9038\n",
      "Epoch 498/500\n",
      "195990/195990 [==============================] - 8s 40us/step - loss: 0.1539 - acc: 0.9233 - val_loss: 0.1537 - val_acc: 0.9233\n",
      "Epoch 499/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1563 - acc: 0.8936 - val_loss: 0.1540 - val_acc: 0.9265\n",
      "Epoch 500/500\n",
      "195990/195990 [==============================] - 8s 41us/step - loss: 0.1566 - acc: 0.8954 - val_loss: 0.1557 - val_acc: 0.8622\n"
     ]
    }
   ],
   "source": [
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=encoder)\n",
    "\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mse',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"ENCODER_DEGRA_GAUSS.h5\",\n",
    "                               save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test, X_test), callbacks = [cp]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXeYXFXZwH/vlG3Z1N0UkpBCCpAQIBg6SIlIUAQERUCKCiIqggq2T0RFwUYRAZUWehVQEEGMFAEpJqETCIQQSCO9J1tm5nx/3Htnzr1z28zObEnO73n22Zlbz9xy3vPWI0opDAaDwWAII9HVDTAYDAZD98cIC4PBYDBEYoSFwWAwGCIxwsJgMBgMkRhhYTAYDIZIjLAwGAwGQyRGWBi2eURklIgoEUnF2PZLIvJsZ7TLYOhOGGFh6FGIyAIRaRORZs/yV+wOf1TXtMxg2LoxwsLQE3kfONH5IiKTgPqua073II5mZDCUixEWhp7IbcCp2vfTgFv1DUSkr4jcKiIrROQDEblARBL2uqSIXCoiK0VkPvBpn31vFJGlIrJYRH4pIsk4DRORv4jIRyKyTkSeFpGJ2rp6EbnMbs86EXlWROrtdQeIyHMislZEForIl+zlT4nIGdoxXGYwW5v6poi8C7xrL7vSPsZ6EZktIgdq2ydF5P9E5D0R2WCv315ErhGRyzy/5e8i8u04v9uw9WOEhaEn8gLQR0R2tjvxLwC3e7a5CugL7AAchCVcvmyv+ypwJDAZmAJ8zrPvLUAGGGtv80ngDOLxKDAOGAS8BNyhrbsU+BiwHzAA+D6QE5ER9n5XAQOB3YFXYp4P4Bhgb2CC/X2mfYwBwJ3AX0Skzl73XSyt7FNAH+ArwGb7N5+oCdRmYCpwVwntMGzNKKXMn/nrMX/AAuATwAXAr4BpwAwgBShgFJAEWoEJ2n5fA56yPz8BnKWt+6S9bwoYbO9br60/EXjS/vwl4NmYbe1nH7cv1sBsC7Cbz3Y/Av4acIyngDO0767z28c/NKIda5zzAnOBowO2ews4zP58NvBIV99v89d9/oyN09BTuQ14GhiNxwQFNAM1wAfasg+AYfbnocBCzzqHkUAaWCoizrKEZ3tfbC3nYuDzWBpCTmtPLVAHvOez6/YBy+PiapuInIelCQ3FEiZ97DZEnesW4GQs4XsycGUH2mTYyjBmKEOPRCn1AZaj+1PAA57VK4F2rI7fYQSw2P68FKvT1Nc5LMTSLJqVUv3svz5KqYlEcxJwNJbm0xdLywEQu00twBif/RYGLAfYBDRo34f4bJMvHW37J34AHA/0V0r1A9bZbYg61+3A0SKyG7Az8LeA7QzbIEZYGHoyp2OZYDbpC5VSWeBe4GIR6S0iI7Fs9Y5f417gHBEZLiL9gR9q+y4F/gVcJiJ9RCQhImNE5KAY7emNJWhWYXXwl2jHzQHTgctFZKjtaN5XRGqx/BqfEJHjRSQlIk0isru96yvAsSLSICJj7d8c1YYMsAJIiciFWJqFww3AL0RknFjsKiJNdhsXYfk7bgPuV0ptifGbDdsIRlgYeixKqfeUUrMCVn8La1Q+H3gWy9E73V53PfAY8CqWE9qrmZyKZcaag2Xvvw/YLkaTbsUyaS22933Bs/584HWsDnk18BsgoZT6EEtDOs9e/gqwm73PFUAbsAzLTHQH4TyG5Sx/x25LC24z1eVYwvJfwHrgRtxhx7cAk7AEhsGQR5Qykx8ZDAYLEfk4lgY2ytaGDAbAaBYGg8FGRNLAucANRlAYvBhhYTAYEJGdgbVY5rbfd3FzDN0QY4YyGAwGQyRGszAYDAZDJFtNUl5zc7MaNWpUVzfDYDAYehSzZ89eqZQaGLXdViMsRo0axaxZQVGUBoPBYPBDRD6I3qrKZigRmSYic0Vknoj80Gf9SBF5XERes6trDtfWZe05Cl4RkYeq2U6DwWAwhFM1zcKuk3MNcBiwCJgpIg8ppeZom10K3KqUukVEDsUqDHeKvW6LUmp3DAaDwdDlVFOz2AuYp5Sar5RqA+7GqpujMwF43P78pM96g8FgMHQDqikshuEuM7CIQtVPh1eB4+zPnwV6O3VqgDoRmSUiL4jIMVVsp8FgMBgiqKawEJ9l3qSO84GDRORlrAlqFmMVQQMYoZSaglXJ8/ciUlQpU0TOtAXKrBUrVlSw6QaDwWDQqaawWIS7DPRwYIm+gVJqiVLqWKXUZODH9rJ1zjr7/3ysCWAme0+glLpOKTVFKTVl4MDIyC+DwWAwlEk1hcVMYJyIjBaRGuAEwBXVJCLNzjSOWLOFTbeX97dLNzvTO+6PVcXTYDAYDF1A1YSFUiqDNTXjY1jTNd6rlHpTRC4SkaPszQ4G5orIO1jTWV5sL98ZmCUir2I5vn/tiaLqPCpdDmX2zfDoDyp/XIPBYKgiW01tqClTpqiKJ+UpBbceDckaOPm+yhzzZ32t/197GrbbLXxbg8FgqDIiMtv2D4diakOF0b4F3v8PzJsBq9+v/LENhmqRy8Lyt4wGa6gYRliE0b658PkPu8PahcHblkolX+JcDtYtjt7OUB4v/BmumNSzrvHD34Y/7gMvXtvVLelcFv4P5v+nq1uxVWKERRhtG93fF75YvM2yOcVCZO6jcM3esPzt6rVN5+Vb4YoJ217H0Fn88wew7kN45rLKHXPVe3Dl7vDqPZU7ps5Lt1r//3dddY4fxNLX4PFfdJ3mfONhcOtRRnOvAkZY+LFwpqXCt212L7//dHh3RuF7yzr4077w+12sl9/hrhNgxdvw1zPd+2czhc8qG7897z0JS14JXu90Yo9+P/4xt2aUgvaWyh83l4neJi6P/R+seb/4Gak0iYiKPtkMPHg2vOGdhrxMrj0QnrkUnrsKXrsXfj8JVr5b3rGy7bBhWfztM23a59bC59XzSztOOTzyPfjvleHbtG6AjXY+2IaPqtueKmCEhZeWdXDjJywV/s4vFK+/43OFz5tWFj5ftYf7u3c9QFZ7gPWHOYzNq+G2Y+C6g4K3GaqloGxZE++4WyvZjHWPLh5sXbtKUsmZRuPef51cFj563TI7xiWZDl//1kPw8m1w35f916+eDx/6aNRRrJgLD3wV1n5oCUYv2Qy8fIe1Pohbj4HLxsOKd+Kds3WDdnxbcKxbDH+YDNcfEr/tpbJmgaXBzbgwfLtfDYdLx1qDu8t2hGd71oSERlh42bK28HldwIP8xv3W/3aP5rF+ifu7/vCCu4PwdhbPXwPTj4C2Te7lLWuJRD/W4peit99aee4q64Wc92/r+3tPxN+3bRM8/8fie+iign6mcgTPoz+APx8Az14ef58ozaJ1ffj6P0yG6Z/smL9m4/JiH90rd8CD34CrQoJwPnjW+v+WT9HpXK74mPpvydia5Zu2xrRea/9/fgvXHVIwVb33JFy9J/zvepjxU7eGEodse2nbP36R9f/fP7XbtrR0H+ZHb1ha25zOK8hthIUXrwDw476vwBO/hFk3uZd7TUthwiLrERaP/R98+Fyxcy4RMTL0nuf2Y2He48Hbbs386wLIaLbqUsxGj/0fPPYjuOeU4G0qFZTwwfOwbpH/updvD87DmXm99f+5q+KfK0qzEK0LuP+M4O2C2huI1v6lr8A/PTMUfPS69d/7HvjhvY/ZDFz9Mcs3kT+dcp9j00rLb+Pns3nyYljyUuE9ue0YWPkOPHI+/Pf3MPOG6Da58Kts5LQ9Z2lmLQFC+dW74fKdCoIjLg9+w9LK7g15XiuMERYeHnghplP66d/BrBvdyxxhkG6wF3he+ExL8bbgHs3W9XXvI9qDmA3o/LwPot9ITD/Xs793a1BgPdCXT4B3/lW8T7XCL5e+ZiUpVuv43k5m9fvB1/DNv1r/F4fk6sRtZ7Y9eNulr8FN02D1e/7rH/wmvPhnK6oniCAT1qr34KnfQKsWmBGlWegd3et/cQ889N8QJXS8eH//i392f6/tHf9YWc9If/0iyzz2/tOFZfMeh3f+Wfj+0Dnw0LeKzVx6u+r6+J9v3ULrHoZqmRoSIixevtXSzG71KagtSXj6UutzlL/DSzlmzA5ihIWHB16YW/7Ojlpb0+i/XnvoN23axPqWdqb9/mn++dg/Ctt4zRN6h5cJcNq2rvPsE+I8v+tEaxTzyPc8y0+wVPU7P+9evuIduHQ8zL4l+JhgvZTPXF5sRtNZtxgePBs173G+fP3TljP07+fC/KfCj10uunlg0Wwr/PneU/23bVnnv1wnjumobTP8dge3b0tn8ezoY0C4+TFoNH7DVHjqkoKZA6KFhXi6AD2ow9UhlSjQo65VbcA70t5S7PwtMvP4dM4blrq/L3vd//h6hGO6l/Xf+75KAp68BC7f2R3QUgptm+GGw6znGyxNxksiWZrQ1OmC/BkjLDRyT/2W69Il2IO9OJ25/gA8c1nBIal19ms3bODemQt5+6MNbH7tb4XtvaYsveMPGE3kvJpF2Iu61I6q0u35m1bBlgBn8L9+DJuWw9/PCT4mwL2nweM/dwuhXA7uOskyDwE8dDa8fBty+7Gcu/DcwnZhTk4vy9+Gyyda6ruXZK37uy5onVHn3H8UbNJKWaNH/cXrpRWk9L6QcYTFopmW7dzxm3gJM43pWo93NA3WSDSsHU5wgy6QShUWS14qBAboHWum1boes28umJBCiejMagNG9dcfYjl/9SRY73Ovj/idexQ0kPKycXn+45//8y4/uO81H20+UfAL/f1cSkIplFIsf/ZmWBSiHYJ1b4KEZuR5SoimrBBGWDi0biDx1MU0SLh693JubOC6thZ7VK0Li8cvouXluyHbTnZlwfSQyrXR0p6liXVMS8wsbO/tTLSO4e0FH/h0YApaPL4RR8BsWBYcEZTTRms3TSs+pvdYUTgjp1fvsv5nM7BqntU5P3eVFVm2rFDea/fE/MK+KU8nH8Z9X7HMEH/9WvG6xkHu73rb+wwtfHZe4pk3WKPHF/5YWOcIi6d+A1fsYoVQ5ynuAKc/+z43Pmt3bK0b3R3Z+iXw2l/c7fATAg66g9bp+DeuKIysU3Xu7ZWyfFybVnmWa8IkUlh4Rul3nQCXjrPboz1XmRZLCP39XMvJ3urJQfISNfJN1hQ+62HOy+1nZO4jhWW61rdwpvt5da7txhihsbmca7t/vbmUe2YtJOcVXPp9WL84OvpMv965LPfMXMjtj8fQIBOpYCtEFPo5H/5O9UODMcKiwIJnY222UgWMiIB1M++2Hl7PA3DnwzPgts+SvL8QnpjLtNKeVZyWeswtoHJZq3O9cnero9A6mp3+cggb/vpd90nbN5PAq41krBfwsvHw29H+jdVHsSs9oYm/GWlFW8Rg0/M38tDtfyDTaztrgfMQ/2EyXLNnYcN3/gkbA2LL9Y5D47qn3+Os22aTzWkdz/I3Y7ULcAtEvZN2InseOd/67wrttDvPpy6xhNL1UwurPCP6bE5x0cNz+MXDc6w2Xnsg/O2swgZ/2g8eOANmTS8sCzPT6aanzautkMxLx8INn7CWeYXq3EctJ+8fJntyeLR2luLgdnAGLF7NQs+XeM1OJsxm4PX7ik1HUVqYPjJuWWv9Fj3iSu/89XDw1+91H8e5r3HyFnIZ13ETdhvbU54Oe/bN7u9LX444rvZbchlufm4BfSTkPju0rncLxVLQr++s6ZZjvsoYYeEQ05a8KkRYDFw0A2beWLRc2jfBgmdcy5atXkcml2OYeEaFuaxltlnzPq/dexEbW9yaTs07Hue1X5SFylqmoxCU05H6jQBb1hVHr3h551/w+C/o9dh3OWreT3hli2a+yeWCw4798OuwgEseeZt/vvkRr85+Hv60v9t+7Dci82plLn+Pdh299m0dp4Os72/9b9dees/xt7QXOon29nbL6erawO7kPnyhsGyz5367tteExdJX4MrdCp+hWFi8b0fOta4rbAvujjiRDD4fBF57gHcXah1wpsVtLpz7iGWTv3Sslax6XYl5DHoH+8YDlkZz1ccKyzRzkUtYeIWQLSxUDGHR1t7mEkgJW1NsTUX4DaL8FsotLJpkA2ekHo1sT0ms+cDyGzqDAu97W8mE0QCMsLDJrAvpQDRWUSwsWlVB1Z/z5F0sX+N2lvai2J764rtL+MdrS0l5tIKP1hZGc2vff5nb/uuOmikaBfk5ZnNZd+foo0ZLts0aDXsTB/MbOOaJAHPCnZ+3MnVt2tpjOOKD8DPNbFrFN5N/YyBrGPfsubDsDbfTuG0j/PNH7k7F6wjVXyDdKbxxWbBpwRn5+2k7nqzwzW2F42c2hyVDatcwSFg8fak7ccyJztLxCgu941yvhbbqvy0q9DogkmfV/Nms/vsFhQWZVrewmPdvy5zndOQblrjPG6VZ6Pfmg//a59DCnh1zJljndTpHbydp3/PNa6KFxT4XP8YbLxUsCPsl32T/xOtsSTSE7IVbo/KLpvNoFl/bXGbZnTDT3R/3tfyGs+1wfe/17bt98T4VxggLm/Z1nodt6k/h689xX83RPJLdK794pfI4w3ALkAktLzFovdsB2CDFnWcNGRas2kzSIyxmv1+YHvbjydfZ6YPbXeszqV7uA/k5plXOY3ddZGXLejq7VRtbrZITvoglSHRH+MwbrCxVn452gBTs25nWGLkqOn6O+7+fw/fS9zK95nfUbAnQkl74oxUe6eAVFvqLrSdabVhaHG008gDrvyMsfGz97Z7ftaWtcO+yG0OyxfVOIMiH9MQvgvd38PNZ+J5Pe6YiQ179hUXTrYeyd0ILI8+0wtoPrM9BAkgXyH7mldaN8MTFVna3y48TkdS28aPCcxqgWeRi1ILKZjKklxfezW+nHuCOml/Rlgn3y817503aszl45PuWJvXExVZin4N+vVWOie0lmEp1vDleW9YU7rGj4S55OX8eF53g8DbCAlBKsWjhAvfCDUth8ESuqz+dNaqgpi5X/Yv291umMzVRbPOsxXrI07awaFXWC7ipxT3KPqTFnWCXEc+I12+kmsu4nZM3HGYl8Vw82LVZS0srbAqYu1zEMg3o/OM8+O+VrH79saLNm6QgnO549q2i9aFkWmDZm1Z1V0cQ2XkGkxILSGVChM8y7cX0ajRBmsWGZcWO+7q+gFij21y2EHmksWSlW3vQzVDZzQEaGrhfbD/hHiOef3NbpkizyAZoR5mM9rvtjn39sgWsnO9jew8xQ7kP2po33727/6UB20RolE//1vq7Zm/3vVkS4RMAFr/6uOXLm+sx79jCImnf3xdzOwUeo442xkpxJnq2LTyopU/rUp55dwX871qrA3/6t1Zin1PnSb+/bRvpnwsxNYahWwkW/Bd+Mwoe+hbPzdOeLcesWGSGMsKiU5i7bAO9MtZLvCFhC4bRHwdAEDLaZVqu+hXt/3ouwIlsUy/FZpZasUZTjhmqFeulbtsSHmWS8z4kPsJC5bJuYRHgWG5ZtyzE4SpWGKgPj/2lWM1uoiAsbn+6xEkNs22WM/ifP4A37uf591axuq1wzZO5kAiidQstjUmp4vwD3cGtaxYbPyoemaVqC36Qtk2+NuCcp7DkZk2zUJvC6lBp98zPxxRWJNLm7Qd+5dIsHnxlMXe++IHvtgtXaffe7lz6/Gk3mm89mI1rPFpaWEKZTqYl35l9cUZAhFVUoli+xpNyX98I/xrAsP+cb/nyvM+yfRyxBVWbCo7+6iUtJKVYG8uGaCXtKskgWYv4FaZ0tFNdaK9bTALFJlVChJ+D7ndxkhhfvo2TbtBqcwWFTxth0TksWLGRZqwX4aSaP8BpD8NORwLWu5TTLlM7xQ/j+2q7ks9Zi/WQe4XFycvdo7YM7hFu0WjSR1i8sXBVcHkBjfZ1S4rLsMdg50RxJ5XQXsJdmsI7oHPavsn7OU3LcVUIfY8Tr3+BVa0Rjlmde77oO6p9a9FKWpzRvy5I2lsChIVt4mvb5OtHSXiEkW6GyoUJC13A+9ViCnN62+zx9qUu88+5d7+Sd9B6SaH7LJLk2grXZs0iT4WCuMldmdb8M7WeBm7NHOazTYRm8Y6mFVSqKKN9n5x7431fdGoJMHe1B+Qv1TfxkRoAQK9WH4Hm+Gt0E5Bdg+pdNZwVIcEwvugRmUGBCc65vGYnY4bqHJYuXUKNZFmnGjhj2t4w+kDXiEt/ADM+l6zNR4BE4Ty4jrBoUf7ho+vF7dDOZb3CoriT2rxlc3FdKh9y65YWl2F3CBlxbifh1VxHNgY/uH/c9T4eyu3vFrp6x2zb2Lfgfz18mfdv347qpfc+4qonLOek0keGufbiziqZjhQWqZy7U9E1CwlKarTOXvjod19iVgpudz17CsG/w20UbaSscqxZVhDu+aihTSut0WjMTnv92lWQbSUrSVqo4drMkcUbPfbjWMcCYkfvXJn5bPgGjrCw743fYM4hUFj4PDt/y+7H7Gl/yz+Hym9Q5Qj5XLGwWK760VrKMwyseH2GJbxbN/qaQQGr3tXsW4xm0VWIbW7Z1GcMR+021LVu6s6DyGrCYmBft4P5xLYfF0U0xcHxWaTErVl4Wa/c58t6HxL7gc2qQudeR1ssYcGGj8LNUAEMlvBKuDXZ4Bjz2estM95/Ggoj0zXrdbOJdR1aSnzRWDmvaFGttPOfdyy78qKVhTa3tbYUjcTmr8mwdIv9OrRt9BUWA1hPS1u7dW2fuZzs+kIEXWZjiHaglBUW++ZffTumlnXRZhiAt5cUfkMt7YF3qL9oHVsuy/plC/Jfs6sXopa/Bb8bA7cfF1tYzJhl5d1slkZAyPp1HW8/HOtYVruihcV7ue3YEmXOsTPLU7apsj1Es+gl/uYm8bnXf80eyJsbe+etCspP+3OWuTQLy/+0QvXL+yHjsnjJYrjnZPjVsHDT3N/PYWNLSORflSh9SLwVMmz1cwC0jjgY8Yyoz5k6jgUrtwM7ei6nSfw1qpHNw/anZsltJZ/TcWx7zVBesgpXv53LKcvJt/BFK2LLfmDX0Jtm229QT2t06Wmgz/KZ8Mo//FfGtWX7kM4EC4v5K611/xlwPOMXvsRBydfo/9LV+fVq9XyE0SW/aH6zGI6TRQxss17eNes34gQXtre3UePpJB9/dy2TE8J2CSDTgsq2FXXG9dLGnHffZMKbl8OcB5k06D8cl9gJEcULb33IMUFte/thqwx2u/91qftfvCqyLa0t+eFdI1sCzVAulKLpuV/mv854YTZD5r3PUQDzn4TdT4p1bsdMuxErzDTX0XFmjM6tjXSopgDA9MNhn28gKNpVuOnyjppf+S4XH5/YZlXLu8s3sldeWBRrf1vWLqce3KN6uzrvctWv9AEPqiBw9SKJPve5Med+v3M5X/FdUYxmAYxvscLpNgzdv2hdbSrJjtsVnNqTRzbDZy0H73ntZ/Hzoyby2V0HFu0XRVrcPougB6tGuUcQKpe1opSevQI+fD5vR96g6vPb1NOGeuO+yDaMXKIJil3dEz21tJVYo18j5y0/ovG+LSx2G9nE47nJRetl9k18M/kgLQSPKOfmhhcvXFU8G9tuifnctOFMyGaoTxRe6HrarKk/NdpJ0eIIqOmHIwEj7pXvzoQ5DwIwbPlTXFbzZy5NX0uqxepMnM60iABBUQppCh1ss6wjEWCGcrHuQ/qsfi3/dais5P2VmuYRU7NoFktYrM1Zz5kKK8sdhxhmk1ZSgYMoF3a5llbSJMuYc0R8HPObsYRFzv6dCR9T4ZpVtklP0yzWL7dyUVbQr+RrpJfAaUsXQvQDzWcauUz572tcjLBo28T2mQ/IqASbm3fx30aLuT/z4PGw2wmcOPhBXq3fh523683OO00s+bRDZDUXp25kjFgj36CRdI24H4JhbQsKX3KZfMRPRhuBbZ9YgcQtr2yjPPVx6j4sf9L7tk3uRMHVzdYEN7NzVs2h5sYazj5kXKBN9/z0Xzgs6Z9Rv0XVcE3GZwzvY4YqNOA96qTQ0SZEgUeYtpFiS4iAckgt8S9hPlwss8E1va2Ci7kgm3MHqNHMnY/V/pDPp54O2drGMyIeJqtcGomKab5whMWaXB0JgfHbFUcFlsLmlujEzVZqojULjRZqSMYRoB5qpbijbaGGebqwaPHRLFbbZkgt6GTNSkuArFO96CelB484KK3PqSe6HHk2qPR+BTHCYumrJMgxV22vzUPhQYtMaKizOpQ7vnYQz/9oKrWpJEz6PC0H/qik0w6XlXwx9TiNdsJe0Aiqhoznu6Yya47YsCiQOLyxuoMjRY2anHsUfcvSkUxt/R0ntVkO0M1tWeprkhy401C/3UO5IfspWv06EB/NIs+yN0mEhd8CbSodyyEpAZFLI21h8eYqqyMO0kw6QprSOwTHMetE5gyVlS6NZMOW8OvyvXZrjnDHDLVBNTCwdy3DB0RkPUewZFm0n6ZdJUNDYb20kg50+odRi58Zqo7Vm9rywiLVWiwshix7mmzrZtraC8Kmt1gBI5uppS8d0Ca1sO9DEtGh1UZYdAar5pFDeDU3hmQioMPUs3ntz4mEUJOyL18iSd3UH9LuTZgrgSAzVKgK2rYpn6VcSkSW7gx3+O+iyqmxjZ7yJm2keU8Ny3fGThRRXV190b5RbFG1vKd8hExI1VH10Zu+Tkx3G1NsCYhI00kGmJMcp/IGZXWiUskpWG1qYpgjzm37Br/PHJv/vnad5RT/UA0mq4TBstY1AFmzMXiEv0nV5hNSnfyE9aqBQb3rGNAYLCw2x8gx2Lw+en50hbg0i42qLmRrSzt/gKmh2/jhXI+rNI11s61lOr6ZpHfOGKBXdi0//ePNnH1HIR+pN5YTfQu19A5wqMdBNI3vipo/RW6fM8KiE9jjVE5u/gtXZD5HkKxwxTyHlHxOpkp0ymrU1/u/fGGjyWzLepTdCZbi3vIzt6R6DYi9fxSNnpfEqzX95rhJANTVe0qXxKCdJPPUcFeHGEV2/eJozYIUvXtHT0STtJ3365T//dpA6QIwLiMT0aPxB3P78/vM5/hGm2UOq8laI92Nqp6PsO7xdlrxypb2YAHUQk3RvdtIPXXpBE29gzvuTTHMeSrGZFMJlGsQtCyiUkIraV5r3J8L2r8cup0XRwivVYUwdWfwlhcWLf7CbckKt1kvbUc3xhGYYSRKjG7KZk3obKewiXpW0I9EUASQj2YRuV2JBGlkRSUgAAAgAElEQVQlzsP3Xq448W/BkuX5ujrZEjQLvxyGeesrZ2PvhVtY6C/8H06czPFTrLikuvrSO1ZnpDkj+zHf9X4amsq0xhAWaVK10aaVtN35rvDJ5AfYpOp9NTed/2ZL93HFxzq308n1ssvft1DDEtUEwIhEoXxES2uwsGglXeRLayNFKpGgOUxYqOj7umMmevpir7BwEuSCaCNNU2MtH6jBodt5qbHfMf1cjpB0zFDpNv9w8TrafP0kmwjXgqJI5ErT9FVUfa0KUFVhISLTRGSuiMwTkaKa1yIyUkQeF5HXROQpERmurTtNRN61/06rZjud6RLiCYuQTrUDwqJNwkcifprDmrVrCpqFlGLbLe5QPwopvzSLnWMfGyhSv/XR6YTteufDkxsCtKkwHGHRFuDjafEJFNi8eTOtW8KLG7arFO2J6Be8Nmf9tpUUF5QEa+QdFlZ6VeYYvtP+jcjzdJScJxKnhRpW2UUw+1OIVnt9YWHE/H5uMM9qgqxFFWsWWZKkkkJz7xAzVIyOss7HpObV1kSU6z5/RLhm0Z6opT6dCExwjcJtOrSunxPRVJ/xD0Wvpd1XWGxRtZzY9mMW5EoTXA4Jn7IkYeR6smYhIkngGuAIYAJwoohM8Gx2KXCrUmpX4CLgV/a+A4CfAnsDewE/FZHwJ6UDOJPrBPss4pmhghLZ2tLRaf9tEm7Cyvo4sNetXZP3WeRKEBZ+iU5BI2WAbETbvHhLsuuj06H9CqPOcoTFtCk7WseME1Jp8/qCZUVRZV7aSNEaw3zSyw5I2BBghtpEXVFHrfNCbmffMveVxiuw2qSWYU2WsNCDJOYt16oFk2KRKoSBt1JTJJQzJEgnEwwNcXDHMUP5cXrb+azXrquVO1F4rjMNQ0L3zyZqqU0lmaXG87fsfiWff6OPRpRV1nX05jU41Eq7bwjzZmp5PjeR49p+VnI74nJk6y/zGnauh2sWewHzlFLzlVJtwN3A0Z5tJgBOWdUntfWHAzOUUquVUmuAGYBn7s/K4RTnC9QsJKawCNi/pW6Q73Kd9ohIHL8yI1s2rc9HQ61P+I90/fCaoU5q+z+WaCr+hwzm4eze+e/JRPhjsiHpluONBGsWDTWF61cTYIby0w4A/pndkwOPOp1Jw/qWFCWTzLbmnZhBTtI20rTECFBozDswi7fdrGrJkQiNr8+S9BX8lcarifbp3ZuJIy1B0KCFYuo+MYVbY2slXaxZqCSphLDDwGCBF8cM5ccstRO7tl6f/y4eM9TmuvBRei5ZS20qgSLBt9vP5oHsASWd/101nCvaj+P83NmFY9r3sn9AGGyQZpFNWdegWqlyOSW8oUbzoC0UVQ8v9zEMWKh9X2Qv03kVOM7+/Fmgt4g0xdwXETlTRGaJyKwVKwJKbccgLyyCrkZMn0WQrFnTOC6yDVFmqIyPT0LaNpK1q6ne3utUskN2jzwPuO3683NDeC63i+v4r8nOvJ7bIf89Eej5t3i/126u714Hd5DJqLbO38Ht53d4OjuJs9q/A8k0/RrSgcf066hrpS3vxAwykWSJZ77oZ0+X6efAdOzUYWYoZ6S6W8t1kefqCN7r8LGxQ5Gk1WbdTFjvCRvVhUMLNUU+i4xthgqsXUT5moVFod0JlCsaqqW2OXRPlawtRChSepZ5jgRXZo/j8dRBnHGAVUl6ZHN40MMZyUe4MH2ra1lWCZuyybLaEJcWarjjjH3YYbA1SFQ92QyFv03Ga4g7HzhIRF4GDgIWA5mY+6KUuk4pNUUpNWXgwNKzqB0cn0UyULNI+H8u3tB36fPjzotsQ3uidM0ind2cd3CPHzuO5Knu2dWCHlS9U3S20Y/fnqx3vaQSkWD2whB3yYgGTxKRkwPy9YPHuJbXNvi/iEEmpgG9rHYP798QuI2fpbeW9nwI8oaQUW9LiGnLmxzmF1HmaC1h1mZnpFnXpylkq47jHdE29+uHeGfaA+okWFi0+uSeZEmQSiRCy8GUq1l4SZBztScZFYCQqnWV6zlmsk+mfwjONWuoSfHjT+/M7As+QZ+G8Pdy+8QK+oqndD115Owgh47mPwWRSqfZf2wz9bV2ocMePq3qIsiX4wEYDrjSipVSS5RSxyqlJgM/tpeti7NvJcnZ0sJbFyqPvjzkJQnaf+iwkTDt16FtaI+wwfuZLnrRko+W+sSEoUVte71hr6J9wN0hZPPCQrMNJ+pc6n+UZrG8zyQObr0sH7LYIG5h4ajyP5jmnpimtt5nHm2gLWBketvp1u/ZfkC9S7NwymX/tP00X82iFy2kJEdGJcgE+HYUsPvwYL+NV7Pz034aezVy85f3JJ0K1j6d6z1tYrj9vaMU+U3S9ZAqbnOdV7NQHs2iyMGdsDULCRw4dTQSyEFwC+lkuhYO96/vBEC6HqWVXE9FmE+9OPemd10KEaGpsRaJOzmUxhYKGk61zFA1Kas/SCSt6/PByg1saq2uwKimsJgJjBOR0SJSA5wAPKRvICLNUrgbPwKm258fAz4pIv1tx/Yn7WVVwTFDBTq449b8D+DA8QMjI6UyUQ5uVXyr+tomkQxJ9hs3EK9m80DTWTCwOJJJ1zj8NItsso75+hwdYS/MUVdTk0qwQG3nmlHQez4/OZoOMEO1JYqFRe/6NBOHWir3sH71ruqiN2WnsWfLH7kle7jv8ZzrFFYO4vuH78Reo8Kc/B7NwscM1au+loN3HEQ6FTyazJBkdHMvzpkabJqMKogXxg+m7cQRuwwp1irT9ZD00Sw0YaGQaJ8FSdJOJxzwXGysUK5Jghx7jC74KVLpOtg3JJIsWet5VUuMKLLfn8Za7V6XUbZlk6rlT1/cg599ZgJ3n1Vcb64i2Nd+zRbred7S0srqTeHh4R2lasJCKZUBzsbq5N8C7lVKvSkiF4nIUfZmBwNzReQdYDBwsb3vauAXWAJnJnCRvawqZPMO7o4eyf8AEjIKc4iybe46othska89k6xxTuRan0nVwx6nFO2nj3acz0pbplK1PJebyAXtX+bDY/8erHFN+w3scQrppCNw/F8shfjLW++c0k67fYSF3oY+9Wn0a50lYefJ+DfTKbtgFZrzFxY7DukdWsU165l32i+6KpVO220NvpfHfmwET55/ME2NwXb9jti5v37wGIb0rSPnHVyk6oqmZQXLn6Pj8lmomqLKABlHs4DAZ3pzRKZ1XCZOmMQ5hxUCKFM1xce9M3NI/nMuWVs8k2QJONdd93vojsx2leR/O34fgOWDDww8zrBBzUzdeTBf2n80k0eE+1nKZpB1XZTdvtokbN/BEixRVDXPQin1iFJqvFJqjFLKEQQXKqUesj/fp5QaZ29zhlKqVdt3ulJqrP13UzXb6dQBC4yGikvY/hGaxcTh4QlHvRuKX5ThYidXJZ1ju89v+WCK2+QnLNw71gDC7dnDSI/cMzi3xF7uvFxBcwnklPCl/UYVrwi4Xrlk8W/V/Un77tBEc2PBpOKM8v/1nYOorym+zk7MemihOUmGCvScR/PryyYubnf7alJOBn/IcdLpAA1SEvClf7DkpCd8/VOl0LsuTbbIDNVQGFRo1Hs0C6+D+9R9R7m0jSzJ/OAgaNS9sYNmqMwZT8KuJ5D69O9IagIiXec+7oPZ/XhLjcx/zyW8wqK09znrJyy0e5khyYKxp8KPP6L3HsEVBGp082qJprBYHH4JHHkFACftYwWiTB7ub9KtJGY+C2KYoSpBWDIf8PEdh1j6V+D+wWaqhFMi2dP5JhMJaBpbtH3WxwylI8nCufrUpVkV4fivTYVrFnvt0Mw5n4qf2JdL1eGt7TZi3KT857p0kifOP5ivX3QuTbKeFVjmo7GDGiGdJKiEkkrWkc4VV/BsHzqF9A4HW2HIz/0BBu4IC2eypWEo9ctm2fum0Suv9JHNXJ85knE77cbx7/0AgIQzIAgRFrVBwgKBUQewnVJs7GDF2rp0wscM5a9ZhPksWknzkyMnkJ7TAHZtpAxJ6hPV0Sye+f4hJBNCql89DLemAUi2FEqT1NQWm7d0QZZL1eaDVcrBuWa6r0PXEttJUl+ThHQ99QEmVKuh1em416pe9P3Cn5EJR+WXOdFatZ1Qi8OU+6CQlBesWcR9AsvXLJIhTlFr/0IH0uaxaReKjrnPL4kEjDsM9nAnwEdpFkoTTA01ISPuIs3C/zdMHjHAPVqLQGmaxZqP/wL2OpO+n/65a5vetSkeze3N7VnLud233hnVB9+DYQP7FyVQPZudyOaT/2k5f2sb4ZsvwvG3wnlvsXmXLxba5IlWuz3zCQBWtWudfwxhka4Jj64REaQDlQAA6lLJYmGRqo/ULMDd+bZQQyohLiFjObijfBbxhcVHQ2wz0v7fZvsBDa6kTYCatKZZ1LiF3Q6D+7v8O7lkXYfci45fsCalPUPae9dOynofwFfw5qmrTtLlrdnDXIICKDxzZg7uziFf7qOqgcQRo0VPB/FIdq/A9d5wxnxF1SLNwo5a2eurruVZ/QXzEXC6MBIRlxB1RQXZnUWN47MIcMzW+JiGwlCaL6PPmL3hU7+DOnfSoYjwxb1H5L9/Zf/RzprA40qqjqTnpcqRIJ3y3yddowmCZOE3PJudyExlRXatbdGEj9OxhAisutoAYaHv01FhkU4WDwJqevlrFhGhsyLi8i1lVJK047MIeGHCJq7y8v7Eb8A37FkffUhpmlidI2g/ey0MmsikU37HwRMK4bEqWeuKhioV511wnmegyAxVn3aERYhArI0uSFkO7X6JqE6/0sNDZ3sMkRnccW2foT6L+MLi9sxUfpf5QuD64NfBff6E8zInisMfHfzMUK05T1u1TiGrCz1xaxZBZqiaQNOLPzV1BUddMhnccV782Uk8ft5B/PKYXfjWocXmtntGXOhekK4v0iwUEhhiqYfAijYq1+tC7T9ey86PoVnsOyY6m7+jwmKXYX2KBwE1vQKioQpmuabGWuq0Eiz58GCvZuEXDbXnGfmPpZTLT6XSMGinQMGTF0xQ6Kh3OwG+8Rz0HeYKB1apWppDAgeicN6FdICwaCdlmaEgXLOorY5m4ZeYm+9XengGd48h77PoqIO7A2YoXfPYRF2xk9O1f7x25oVFMlhY+IXktno0hITowqW4qKJz2YIc3KkoE5sHXbOIUvfGDGzk5H1G+uaCvNXsqRCTqiOJV7MQV4ekk04XOiLROiX9+h04XsuXyGsWwW3u3xgdVipRA4sIdh3ejws/45n1sbYxMs9iYGMtfzh5n/z3vJahdYz5DG5wa8uH/Dj/MaoUS04TWmmfNumkkwlezO3EgtxgEn195jHRTWupWr43bUcOnziYO8/Yu3jbCJz7mtZMpi6fhUoWytWEahbRwuLTrZfALsdFbqfj+34ZYdG5VM5nEUIJmkU7qeLQx2QMzUK8moVjLnCf+4FsIewvS4Kjdx/K4D6FF9grLCRCs8hklX0s/9+YKDGxKZfSOtRSR9naNaj1+klStdQk3FfPygHxv+8pbX4SXbPQw4xF13xiaBbBv6fQBgnRpuKy9xhPRYOaRn/NQg8Bru+HpAvXPkizSPuFzmoDkqBSLA65moKZJhWhdaaTCb7Q9hMObbuMXnU+o3n9NyXraG6s5dpTprDf2NJDVocNsJzWh+6oa4uFZzoT12cRwwy1nnroXTztQBi+mrvzPhqfReegquGzGLGv+3tUp+d6KJPFD4bLDBXPXJZ0XmbNDHVA65Us10o950jw1QN34IUfTYWBlh3+9aQ7ckkfXSmXsLDnTrAvYJBmISVeWJdmUXJkUOEaFDnVVY66ImERTxt0aRa6IHcVmYz2WUQOGqiMsCi6bjW9ojO4j7rKNVJvdcrC6D4Lkv5mqESauaNO5rnsBObKaHyZeiGcP8/V0abSEYEfCSv8O0eCunTxc5TQJxxLdyxk97av7sc9Z+7D1J0LwkI8Zqi6CvksMipVpPGD5XcJ3MdXs7Cvn/FZdA6RJcqH2RPthISvAuGdRKSDW492SvmM0gvHDhQWXs0iWWyGalWpfN0asEaKdWl7dH3Ws/D991mRczuTE1pnn/PpHLO2GyDIZ9EhYdEBk4zLUQmQaUGU+6UKqxCrC4t6LcbflcPgV2QyVLOI/j1JbycydHLkPkW42iB2noXPDImOWW7ab6BpjKsT9DND5XTNwlO6f9ypV/PhZ+5hxnmFRDkXu3wOGge6QrMD8058SHnvp6dtHRUW/Rpq2XuHJrem6QmdzWsWYeeKISzaSfn2J0X1u4YVJvnyjTY0ZqjOJdLBPXBHOOu/cP47EUeKOaIcfZD1f5SWBeoxQxX5LDQ1M66DO19aXDv2D4+cxLWnFSKtciSodcpTJNPQMID/s3MifnSEpWmIJkRd82aIIywsaeHrgAMSJWoHSjdDlapZiFuzWKbP05FpK3qpQrOltXumaxauffzmOgkTFvrvOedl33YnNB+P+saL0FhGHSm9XTWN1vF9TCf5+bid7bVtCmYoj2aR77TdIaaJhHDCXiMY2eSTg/DF+6G/lUCnC4tUhM9Cp1dN8bOg3xe8yZz667CnOyLQF79nTRvoxI6GihE6207SV7MoCm+uL1gBfKMNnftmzFCdQ3Q0FDBkF2iImKc6zO+sv7yfmw7feROO+I31vWmcJzQ2XaxZ5HRhEU+zyDvstWMfN2UUk7Rs8SyJItv+AeOaefsX0/jaQVaVWJeD20ezOMiOCBo7xL+2UsJvROhw/G3QezueGVmo+SMV0izWbG7nU61a4bnMFryi9uCdQjpiXVgkg4SFX/n6mIEOA3bw3cTlK2looiyfmf4s1Nidt0+eRcoRFs72EZqFFQ3lHFtrV1RwSK9CuRpdWIRFuzn88phdOO+w8QzqU9xBJ7S2Jbyjff2yffrSyPP4PWt6xeV2UgU/YAcd3A+ec4i/sPAK9JqC4PXVLKTzNAuTwY3u4K7iSfROIlkDvZqh73A45xXoPQSWzcmvHrXTHtyx//5wq7a/KoR8KoT1fcbRZ/27npN4zVCaxpBfmAYttj6LFDQLjbxtFrcZSSWKNYsRTQ3MuuAT9M2thcuLDhXuDJpwFEw4iuX331VYltYd3OX7LDa0tLNKn/40U5y9XReWAxLks9CFhfj4L8oyQ+mmDx8/SKnox6i1M4p9NIukM32n02btd+ZL2WvmKyvPwt5WBZRO8W2PFhSgXdc4VVlP3mdk4Dr9vki6I/NoEKlZuAZwoUl5wQUpHUYN6gsL/DQLzzItGMA/GsrxWRjNolPIz2dRTWmhP4j6AzFgtLtzBL5y3FHsur1Hi8m5ZzR7Yb8bfM4RFA2lJ5elXR1QjkRkdrVbsyhOygNobqx1hZq694/u8HS/CPpLX6oZaohdFqT3UL728TFMGanN4pdpheNudG8fM3IpEWiG8pmfPa4ZKsZ5y8650NsQolkUtSuGZpF/T0oSFj7mOmB4c/wZHn0Pq7VN0h0spOdz38SVlKcP+HyExfC94MDzLd9PFIm0v2bh9WNomoW/g9sk5XUaOa2YTGB11djEND9EdQANA4q3cT0MQrbXYNh+H/c2gT4Lz4sq+mgphrDQO3LXsby5IP7OykQMB7ee6pDUj1PqyProq2Gfb8KXHmZEUwP3fX0/GLqHtW70x2HS5+B78wvbxxQWuhkqG2WGCjymxAu58x6znKxkr88CwkfDTpuT0T6L/GtSSrsCwmyTtSE1lmKQ1AYW4jUNlfo6+90b3cGtD5T8zGe7fQGm/iTaJOecy68fkIT7PXKZobo2dHabN0NVtIig6yHxHC8R0ME4DNvDSmwaZnds3k7SpVmIpTUMHA8LXwg4vyYsnEgn57NHWET9dr2zVz4O7sIJ/YWFJKM7/JTWBt3BW7Jm0TgIpl3iXnbSvfDWQ7CrnRWvd5pxTUaBPosSHNxx528vOmY5Pgtds7CFRUhYZv6ciQTtkiat2gtFBV2ahda2Ujoo/TfpQiZM24mBrlkkPLWjSrpsAc+ZniAZOXd6qc+q3/siCWt5zs5/qS0UJQzP4K6+ZrHNC4tsxbK3vYQ8qX7nEoGDvh+8Tc4dDZUUgcMusjqTPU71PY0rq3nIJG2FZobyyeAuapou6JI+Zpf89wBhEeMlSrpkaQc0Cz8aB8Kep2sNCvA5eHH5mbTqpuWGzsb9LZXQLPRr7oxOw86vm1ukhrRqD9AsEoXmlGuGymmJgB1875Ka6TNZ04FJlwKujTshNX6uVCz8BKWIR7PQhUWYGaqEe1Em27ywcB78ysiKkIN0cLY9r2aRTIgVVmfXtbdOH6BZeBF9tBQtLHTNQo/UKRpJBZwvGRYN5ezqGlhXWFh4iSssxF+zcK5ZY63bpIeuyfkRan70j+0vKVN0rzO1/fyERZhmUzjPE/0/z4ZlC1iN7VzV/DWuDivsmT7+VnjlLnjnUfv42u/LVG5GNz0aKukNwy3lnQ7SLIJ8FiUcI5AgM5Q+INOEhW8ZlU6sOrvNC4vIhLyy8R6vo8LCHTobNS82hPgKXLWeShMWLid2zDIecZLyXFWhO2KGioPekcadsEoTFpNHNHH8gOGcceAOoGeEl5ClXxoxnp1BE63EOgf9dzlJYjGFxaNNp/Hw4qWFdSk9IVG7l2HCYsLR0Dy+ICz0356tnLBIpdMc1/pTciS4wDsoKckMFaQN6hpXB+9vn2GwfnHhu68ZyqtZFHwWFx69m8/2xgzVacTKsYhL2DE6Wl5qyCSYNyN/qCCzmUIQIgSg9lAftotPcTbv5toLU6PbhWN2fnGioZReAqK7aBYun0WhTYP6NfDbz9kvbtsmbXvndQq42XEFX9tG9/c4WmnzOLcW4muGiicsiggSFlEPtas0jLZftjiEuVzSyQSz1Y725w68w0FmKO03ZCJqXgXe368+CQuegY3L4fmrtXP6HU/cQkTTLHYf6VPvyoTOdh6FKVUrcbQqhd7ucRpM+Ur+a94M5duEwvJA84/24g7sEyPcUHRhEWKGCtw9ert1zZN5MLsfv2j/ossO3dFy3QEN0r8EbxegWWw/oJf/NnmTQIzjFbVJa8fCFz0rK+TgDrsPegKidyCiO7j1LOKoDsovBwUgGzCVYRnogRFFpea9mdSHXmD99/PxBQhLl4M7smRPwPs2bA/Y/9zi5UGahb5cc3D7h9pq0VAdNXVHsM0LC8fBHces0zE6cCMP/K7rQQkVFlrnF1jtNSxqK+qYrlF/vMcnjs8ilUxxbvvZ3Jj9NIlklc1Qrto/cYVF4XfX6xMY+SbQBdzruFqSc99G7GcfLuB4fYYFH8PPZxFau0xLmvOu84TO5olycCcCNLgKmqH0uSeKNIuPfw92ONiqEuB8/8lKGDal+EBBwiIox8h344j76xWuvtGDHjOUK9w5IDDGWV5KwEEZbPPConJzWVAYuXz8+8XrttsdhuwKk0+Of7yT7oVPXw79R1GcQxGwj/Y7fAuvlcGAxgDTU1zNosTQ2ZQr4qoLH9EAM1RghnU+5j3gpY3r4D7xbhh5ABznk3ipM+6TIYfz0SzC0H7TsP6eqCKtwxrYt4FDd3KqskaZoQJCjCupWSRDnveGAXDqg1aVAIdk2l8wBLRJ97dFOrijBgNeJ3RQYdKgZy3IL9FJpijjs8hVULPY5VhrJNMwAKYf4V6XTMHXni4t7Gr84YXP2n5KSaxZ/UqdRyIIcb30+oMc7/hx2qFrSskS5uuuKgFmqEAHufM5SBOIez/GH+6+94HtCwuF9Sn3EYbWtrMPGcv6Le0cu4etuWj5GQ+fezBS65jbIkayPnOfAL5lV8pFNz2l4r7Dfvch0xK5bWTobFS1We/1CshL8q0K4P3s2j5phSPnMkDH8lbCMMLCmcuiUlaosGKDHdJeNGFBWPSW7rOIcb44bXIJi5A8iwDiFItzjRCr4dQuh4CkvOhOP8gMVe7rVobw8Sv3EYa2fa/aFBd/VsvL0Utq6L8hUljoZijtOauoGUq0zzGFsd91ywVpFrrPIuL+9YqYMtc78g96HryaxeGXwMp38vPNFPHdt6xnNd2BPJMYbPPConpJeRVG1yziOrgrZsLRa3GU7uCOY0pKljNCrARhTsEAn0Xk7w46ZqgmEDNHp34AbFlt7xMWyaWtS8cQFmH3yFUFuARhETgq9hQv7AC66SkVNxrKVXqkNjQ6qyQzVOPg8PVeM1SgZuGJBtz3m+HHjaqGXSG6ib7fdThmqI7Xhao2MYWFRsWERWApipiaRYztdAERxyHeKbi0qDjhvBGOxkpoFt9+TTtdTGEdZ8QZGjqr+6zK1Sx8jt/BUh8Aae25SZfzvEdNmOQyQ0Vcb23uCV+8WdZBv98V4NFN3gWMsKhsbahqIh4zVJBw0yfRqYqwSPkvDyFWIUGXg7u7mKECfBZRL3BQJ1qJyC5dS4g7wIklLELaFqRZlHJM/XM/u+T44InxjxWArlnEMrsCLuHbb0T4pq46alEO7qjnIqYZqiOFNKuIERaV9lk4VFFTCc/grsYIPUhYxEzKi9H5678mURc9LWXlCKvhFRANFfkClxM6G9MMlQjwA4QRS1iEHMvl3Pd7pqIHLi4Be/IDVq7D52+JblcEbl9XzOuhX8/P3Wz5GnY9wX9bPSkvymcRxQ6HWP/7j7KPHfB+lmPq7QSq6rMQkWnAlUASuEEp9WvP+hHALUA/e5sfKqUeEZFRwFvAXHvTF5RSZ1WjjdlKRkPpVDpBxuuziKFZVM4MFRAN5df5fe4meOvvzFq0iSnrHrM2izE6cl2tfiOsIolheQSdQVCl4EjNooN5FpWirh+0rI22pUN42GXUcxT4LAaEzjaPhaOuim5TDHTTU2wHt/60NY+F784J9h+45uD2bHPYL2DGT2KeE5j0eauo5Xa7Fx3bRRlBJJ1B1YSFWHny1wCHAYuAmSLykFJqjrbZBcC9Sqk/icgE4BFglL3uPaXU7tVqn0NF8yyqijfPIlqziGfOKTFiKirPYpdjYZdjyV55Sn5RHJ9FUf/ql/HalQRlI/tSQrmP4xaySzUAAB0WSURBVG+DB74Kx98ccrgyBx7nzbVMH0EdoU5Y7kOU6SlOld0q2d51zSK2Kdl7PcOuj6sar+c67H+OJQBevStmqHMCxhyqfQ94jrZBzWIvYJ5Saj6AiNwNHA3owkIBTk5+X2BJFdvjS0VrQ+lU2QwVz8FdoRMGTFwTN7pHYrRVdbh4VpnE7YiDRsmubSLyLPw6pQlHwU5HVif5MMp5qxMWzloXMZtd2GRPkdt0jHQywW+Om1Rc6qNShGkWAH22syoslHXsoLyJ7umzqKawGAYs1L4vAvb2bPMz4F8i8i2gF/AJbd1oEXkZWA9coJR6xnsCETkTOBNgxIgIR1UAVTNDVZqYobPV+RVBPovgF1S0zj/WiK+LZEVsStEsdGGxy3Hwxv3W50CHZjdwHQbkGQCWsDjp3uBM8DhlZao4ePrCnqW++yU8bKVUnS2V3kMsP0bjIHjtnsLyknJ6Oo9qtsTv6fDepROBm5VSw4FPAbeJlS68FBihlJoMfBe4U0Q8VcFAKXWdUmqKUmrKwIEDy2qkqpaDu+K4o6ECNSFXpnecw3YgKS9MWEjh5BXX2rqCoAQz90b2f+3CH/G7wuc45iA/Bk+w/geVh6gEUSU4xh8Oo/b3XxdohqpieztCmdPB+moWHUEETv0bHHude3nYBGNdSDU1i0XA9tr34RSbmU4HpgEopZ4XkTqgWSm1HGi1l88WkfeA8cCsSjeyavNZjD8cPvivVQ+qEmgdVC7GVKhQwcF6WXkWetmR6FMM7x+j+m1X8LEvwer5Vglwh8gaQFrorMtJXmZnc+hPrNH9pOM956mgOuadv7okAm5wqgZO+WtF8ikqS7nCopNymD/Uqg7HqevVSVTz188ExonIaGAxcAJwkmebD4GpwM0isjNQB6wQkYHAaqVUVkR2AMYB86vRSMdnUfGkvH2+aU3+MmKfCh0wZp5FNcoUB9aGCus0C+2Ic21HNDVw5xl7M7hvRzqtKvCZK63/rdocE6WYoVz+njJft7o+hSKV1SDdADt+qvz9w0wlukO3u1CmZlFxM5Tv+QR2OwH+/VPY62vbhmahlMqIyNnAY1hhsdOVUm+KyEXALKXUQ8B5wPUi8h2s3uVLSiklIh8HLhKRDJAFzlJKra5GOwvRUBU+cDIFOx4RvV1cPGXF45i5470TcX54gM8i7EEuQ2btN9ZncpfuQhwHt4OuWQQJ2krTkcHOsdeVL8igW9nVK46uWUgnaEhKwd5nwcj9YPie1T9fCVRVVCqlHsEKh9WXXah9ngMUGUKVUvcD91ezbQ5OUl63z+D2lPuIE/2hKqVlBEVDbRWdRBnRUKUUEgy6dt2Jjk4w1eN8UqVoFvpMeZ1khkrXwfZ7dc65SmBreNs7RLan1IbylPuIo1nU11RIhXUpNaXkG2xFxJnHw0l+CzJDdVeHb0fvY08bNJRrhqq0g9v3fN23H9rmq846hQR7UlJeaAa3xqRhEfHx0LFoqG5kT606rmvg6RxPfgDmPQ6TPmcvqLDPooLkEBLekXVHQ3e7/bvjpUxhUY0pfnsQ2/avR6sN1d0HR95CgjHMZpXTloIyuGPWM+rOxG1mmEY1dqr1lz9mF/gsYl5vhVD0o41mEYz2jHeaGaqb0sPucuXJViuDu4oopHPNZiXZ67dSSrneQcKi2/ostjFhUQoJ3WfRSQ7ubspWfJfjUbVyHxXHbYbq3FO7I7Hi0X0f+qoTGDrb9cLC99nZ1jSLcvMsOiN0thvT0+5yxclVKymv0mgddu+6zu50Sq/xIz1GWJTRzsiBhS4sAsKOuxMdjobqYd2IE5IaxyzoyrPYth3ckXdZRM4WkYgpoHouhfksuu9Nsii0b4eBYVmdVU7K6/bXqTOIuAZBt6AbRI/5ahblmqGa7Kz2bpYPEMl2u8FXn4Tz3o6xceF6Zen6+9eVxBlSDMEqL/4SMB14TFUsgL/ryRcS7O59YFmmoFKP28nn7hZU4/cElSiv8AhcBWgwYbv4LSy3Xaf+DV65C/Y6o7z9u5Jhe8TbTp/dbhsfKEU+JUqpC7DKbdwIfAl4V0QuEZExVW5bp+DIvW5vhnKZgirY1qaxMU5dhmbRY8YTVWhn4BzcXT8yVX6vfLnt6jscDvpe9NzTPZmoAovbELGMlXYJjo+Aj4AM0B+4T0RmKKW+X80GVpseEw1V6dH9Wc9auQG7nxzn5NrHHmaf7gqCBGU3uHb+mkXXC7FuS9gMgtsYkcJCRM4BTgNWAjcA31NKtdulxN8FerSw2G9MM/d/fV/61ne3ypgeKj03wJBJ1l+sc2udnKOJ9N4udJeeoleURdT178aahS/d1fHeHchl8h+7fZWHKhPnKWkGjlVKfaAvVErlROTI6jSr8xjQq4YBvQZ0dTO6N/pLUtMLfrQYUrURO/UQcVEVc1kJ06p2MhV1cG8LaMJiWyeOXvwIkK/4KiK9RWRvAKXUW9VqmKFcqjD68Wo1tY3dImeg2xIkgLpBp+yfZ9H15rFui65ZdGEzugNxnpI/AVoxfzbZywxdRmc/tmX4LHqMg7scyjRDdQPNwpduIMS6LUazyBPnzRc9VFYplcPUlNq2cAmIeIKq54zCOtEMVY1Ouaa39X/YlFibVyWDe2vG5bPojBN23zcnjrCYLyLniEja/juXKs1aZ+imSOmaheopPotyaGgKX9+Z0VDfeB6Ouhr2/lqsze9JfBqAZ7MTCwuNgzuYSk2LHJvu+97EeUrOAv4AXID1Sx4HzqxmowwdwWRwV42TH7Dm4x48IWLDztIsFPTbHvY4JfYe1yWO529bdmMj9TyRPL9K7dqKGH0gX277Hu/khtN/G370IYawUEotx5o/27DNUkZtqO7us5j6U3j6d3Dg+fH3GTsVa8r4CLqxzyIrSV5TYxguKwoLu0G7ujNP5iYDVnLZtkycPIs64HRgIlDnLFdKfaWK7TJ0J8rwWXR7Dvwu7P/tzp3IpBuM4B33Y1aFTOZk8EW2lme/TOI8Jbdh1Yc6HPgPMBzYUM1GGboZZfgsegSd3UlW6toN2MH6PyaGluPBUfiy+qtvNItuRPcVSHF8FmOVUp8XkaOVUreIyJ3AY9VumKE7UaW6VFsrfYbD+kXQd4R7eaU65TP/A6vehaExi+FpOPO35HRhYRzc3Yjua76NM9RxKmmtFZFdgL7AqKq1yND9KGumvO770Fedk++HnY6Ek+9zL6+UJlPXB4Z9rCzB7ZTkzwVNlWsIZFsfJ8UZUlxnz2dxAfAQ0Aj8pKqtMnQvtuoS5VVg0E5wwh3Fy7uBucfRLIwZqrvSfd+v0KGOXSxwvVJqjVLqaaXUDkqpQUqpazupfQY/OnuIU1aJ8uo0pUdT27urW8CZB1r+jhP2HlVYaDSLWHTfbrxzCNUs7GKBZwP3dlJ7DN2d2ILKSIs8R10NC1+EHQ7p6pZw9qFj+eTEIYztm4NX7YXbun3FEIs4ZqgZInI+cA9WXSgAlFKrg3cxbFVsjaGznckep5SUOFdNRIQdh/SGlvVd3ZSexzYuVON43L4CfBN4Gpht/82Kc3ARmSYic0Vknoj80Gf9CBF5UkReFpHXRORT2rof2fvNFZHD4/0cQ1UK+JUROitGs+je1Pa2NJ2dj+rqlhh6CHEyuEeXc2ARSQLXAIcBi7Dm8X5IKTVH2+wC4F6l1J9EZAJWOfRR9ucTsBIBhwL/FpHxSikzbVVXUIbPwoiKbo6INYe2ITbbtl4RL4P7VL/lSqlbI3bdC5inlJpvH+du4GhAFxYK6GN/7gsssT8fDdytlGoF3heRefbxno9q7zZPVVTlrTQpz2AwxCaOz2JP7XMdVnGcl4AoYTEMWKh9XwTs7dnmZ8C/RORbQC/gE9q+L3j2HeY9gYiciV3UcMSIEd7VhkpRhs+iNrmtj8MMWxvbuMsilhnqW/p3EemLVQIkCr9L67VOnAjcrJS6TET2BW6zE//i7ItS6jrgOoApU6YYy0e1KMNnseOQ3rC2Su0xGAydTjl5/puBcTG2WwRsr30fTsHM5HA6MA1AKfW8XbSwOea+hs6iDJ9FTdKYqwxbF9u4YhHLZ/F3CqP6BDCBeHkXM4FxIjIaWIzlsD7Js82HWGatm0VkZywz1wqsTPE7ReRyLAf3OOB/Mc5pqArl+CyMomcwbE3E0Swu1T5ngA+UUouidlJKZeyEvseAJDBdKfWmiFwEzFJKPQScB1wvIt/B6l2+ZE/h+qaI3IvlDM8A3zSRUDpdmMEd99yH/gQWPAsf/35VmmQwdDZ16W070z2OsPgQWKqUagEQkXoRGaWUWhC1o1LqEaxwWH3ZhdrnOcD+AfteDFwco32GalNOifKmMXD+u8YraOjxXHfKx7ji3+9y8WcndXVTupQ4wuIvwH7a96y9bE//zQ1bH2WWKDeCwrAV8MmJQ/jkxCFd3YwuJ84wMaWUanO+2J9rqtckQ4eoSga3/tkIAINhWySOsFghIvmaACJyNLCyek0yGAwGQ3cjjhnqLOAOEbna/r4I8M3qNhgMBsPWSZykvPeAfUSkERCllJl/22AwGKpBNzbzRpqhROQSEemnlNqolNogIv1F5Jed0TiDwWAwdA/i+CyOUErlCzcopdYAnwrZ3mAwGAxbGXGERVJEap0vIlIP1IZsbzAYDIatjDgO7tuBx0XkJvv7l4Fbqtckg8FgMHQ34ji4fysir2GVDxfgn8DIajfMEEI3doIZDIatk7hV4T4CcsBxWIX/3qpaiwwdwwgSg6HnMXQP6//4aV3bjhACNQsRGY9VKfZEYBVwD1bo7CGd1DZDOVQjg9tgMFSXUx6wCm/2RGEBvA08A3xGKTUPwK4OazAYDIZKUt8fdv5MV7cilDAz1HFY5qcnReR6EZmKmf/DYDAYtkkChYVS6q9KqS8AOwFPAd8BBovIn0Tkk53UPoPBYDB0AyId3EqpTUqpO5RSR2JNb/oK8MOqt8xgMBgM3YaSJkpWSq1WSl2rlDq0Wg0yxMFYAw0GQ+dSkrAwGAwGw7aJERYGg8FgiMQIi56ISbwzGAydjBEWBoPBYIjECIutDpPBbTAYKo8RFgaDwWCIxAgLg8FgMERihIUhmkS6q1tgMBi6mDiTHxm2dUYdADt+Cobv2dUtMRgMXYQRFlsdVQirTSThxLsqf1yDwdBjqKoZSkSmichcEZknIkX1pETkChF5xf57R0TWauuy2rqHqtlOg8FgMIRTNc1CRJLANcBhwCJgpog8pJSa42yjlPqOtv23gMnaIbYopXavVvsMBoPBEJ9qahZ7AfOUUvOVUm3A3cDRIdufCBhbh8FgMHRDqikshgELte+L7GVFiMhIYDTwhLa4TkRmicgLInJMwH5n2tvMWrFiRaXabTAYDAYP1RQWfp7WoPTiE4D7lFJZbdkIpdQU4CTg9yIypuhgSl2nlJqilJoycODAjrd4q8BkcBsMhspTTWGxCNhe+z4cWBKw7Ql4TFBKqSX2//lYM/VNLt7NYDAYDJ1BNYXFTGCciIwWkRosgVAU1SQiOwL9gee1Zf1FpNb+3AzsD8zx7mswGAyGzqFq0VBKqYyInA08BiSB6UqpN0XkImCWUsoRHCcCdyuldPvJzsC1IpLDEmi/1qOoDAaDwdC5VDUpTyn1CPCIZ9mFnu8/89nvOWBSNdtmMBgMhviY2lAGg8FgiMQIC4PBYDBEYoSFwWAwGCIxwqInYubgNhgMnYwRFgaDwWCIxAgLg8FgMERihIXBYDAYIjHCwmAwGAyRGGFhMBgMhkiMsDAYDAZDJEZYGAwGgyESIywMBoPBEIkRFgaDwWCIxAiLHonJ4DYYDJ2LERYGg8FgiMQIi60NZebgNhgMlccIC4PBYDBEYoSFwWAwGCIxwsJgMBgMkRhhYTAYDIZIjLAwGAwGQyRGWBgMBoMhEiMsDAaDwRCJERZbG2Z+boPBUAWMsOiJGIFgMBg6GSMstjZMBrfBYKgCqWoeXESmAVcCSeAGpdSvPeuvAA6xvzYAg5RS/ex1pwEX2Ot+qZS6pZptNRgM2xbt7e0sWrSIlpaWrm5Kp1BXV8fw4cNJp9Nl7V81YSEiSeAa4DBgETBTRB5SSs1xtlFKfUfb/lvAZPvzAOCnwBRAAbPtfddUq70Gg2HbYtGiRfTu3ZtRo0YhW7lpVynFqlWrWLRoEaNHjy7rGNU0Q+0FzFNKzVdKtQF3A0eHbH8icJf9+XBghlJqtS0gZgDTqthWg8GwjdHS0kJTU9NWLygARISmpqYOaVHVFBbDgIXa90X2siJEZCQwGniilH1F5EwRmSUis1asWFGRRhsMhm2HbUFQOHT0t1ZTWPi1LMj7egJwn1IqW8q+SqnrlFJTlFJTBg4cWGYzDQaDwRBFNYXFImB77ftwYEnAtidQMEGVuq/BYDD0OFatWsXuu+/O7rvvzpAhQxg2bFj+e1tbW6xjfPnLX2bu3LlVbqlFNaOhZgLjRGQ0sBhLIJzk3UhEdgT6A89rix8DLhGR/vb3TwI/qmJbDQaDoVNpamrilVdeAeBnP/sZjY2NnH/++a5tlFIopUgk/Mf1N910U9Xb6VA1YaGUyojI2VgdfxKYrpR6U0QuAmYppR6yNz0RuFupQoKAUmq1iPwCS+AAXKSUWl2ttvY8th07q8HQGYz64T+qctwFv/50yfvMmzePY445hgMOOIAXX3yRhx9+mJ///Oe89NJLbNmyhS984QtceOGFABxwwAFcffXV7LLLLjQ3N3PWWWfx6KOP0tDQwIMPPsigQYMq9luqmpSnlHpEKTVeKTVGKXWxvexCTVCglPqZUuqHPvtOV0qNtf86T3z2BEIdVSYpz2Do6cyZM4fTTz+dl19+mWHDhvHrX/+aWbNm8eqrrzJjxgzmzJlTtM+6des46KCDePXVV9l3332ZPn16RdtU1aQ8g8Fg6AmUowFUkzFjxrDnnnvmv991113ceOONZDIZlixZwpw5c5gwYYJrn/r6eo444ggAPvax/2/v/mOruss4jr8/KYUyVlb3iy2WjR/bH+A2a9dMBibOpTJE4z9uwWXo0nVpspgME6NuMXEaTAx/6DZW4sTYOJNFnEHiXDIZY9NMMSvgOuiCCDM4yUBaHGMmBAZ9/ON8W++w2y3l9p7bez+v5OSc8z2Hm+e5HHju9/z4nht56aWXShqTi4WZWYWZMWPGyPK+fft49NFH6e3tpampiZUrV476vMTUqVNHluvq6jh9+nRJY/LYUGZmFez48eM0NjYyc+ZMDh06xObNm3OJwz0LM7MK1traysKFC7nuuuuYN28eS5YsySUORZWMUtrW1hY7duzIO4yJ9Z2Lsvn8W+FLm0bfZ/XlcOZk2v/t8sRlNgnt2bOHBQsW5B1GWY2Ws6SdEdFW7M/6NJSZmRXlYjEZTZuZdwRmVmNcLCaTlRth7idh2ffzjsTMaowvcE8m17Rnk5lZmblnUXWq44YFM6ssLhZmZlaUi4WZWQ5KMUQ5QE9PD4cPH57ASDO+ZmFmloOxDFE+Fj09PbS2tnLFFVeUOsT3cLEwMxt+4LXknzu+B2OfeOIJ1q1bx6lTp1i8eDHd3d0MDQ3R0dFBX18fEUFXVxezZs2ir6+PFStWMH36dHp7e98zRlQpuViYmVWQ/v5+Nm3axLZt25gyZQpdXV1s2LCB+fPnMzg4yO7duwE4duwYTU1NPPbYY3R3d9PS0jKhcblYmJlV0NA4zz//PNu3b6etLRuB48SJE8yePZvbbruNvXv3smrVKpYvX87SpUvLGpeLhZlZBYkI7rnnHlavXv1/23bt2sWzzz7L2rVr2bhxI+vXry9bXL4bysysgrS3t/PUU08xODgIZHdNvfHGGwwMDBAR3HHHHSOvWQVobGzknXfemfC43LOoNvUXwJlToLq8IzGzcbj++ut56KGHaG9vZ2hoiPr6eh5//HHq6uro7OwkIpDEmjVrAOjo6ODee++d8AvcHqK82hzcCb+9Hz77A7hqUd7RmFUsD1GeGesQ5e5ZVJvmG+G+P+UdhZlVGV+zMDOzolwszKxmVctp+LE431xdLMysJjU0NHD06NGaKBgRwdGjR2loaBj3Z/iahZnVpObmZg4ePMjAwEDeoZRFQ0MDzc3N4/7zLhZmVpPq6+uZO3du3mFMGj4NZWZmRblYmJlZUS4WZmZWVNU8wS1pAPjHeXzEpcBgicKZLJxzbXDOtWG8OV8dEZcV26lqisX5krRjLI+8VxPnXBucc22Y6Jx9GsrMzIpysTAzs6JcLP6nfG8RqRzOuTY459owoTn7moWZmRXlnoWZmRXlYmFmZkXVfLGQtEzSXkn7JT2QdzylIqlH0hFJ/QVtF0vaImlfmn8otUvS2vQd7JLUml/k4ydptqQXJe2R9JqkVam9avOW1CCpV9KrKefvpva5kl5OOf9S0tTUPi2t70/b5+QZ//mQVCfpFUnPpPWqzlnSAUm7JfVJ2pHaynZs13SxkFQHrAM+AywE7pS0MN+oSuZnwLKz2h4AtkbEtcDWtA5Z/temqQv4UZliLLXTwNciYgGwCPhK+vus5rxPArdGxEeBFmCZpEXAGuDhlPNbQGfavxN4KyKuAR5O+01Wq4A9Beu1kPOnIqKl4HmK8h3bEVGzE3AzsLlg/UHgwbzjKmF+c4D+gvW9wJVp+Upgb1r+MXDnaPtN5gn4DfDpWskbuAD4C/Bxsid5p6T2keMc2AzcnJanpP2Ud+zjyLU5/ed4K/AMoBrI+QBw6VltZTu2a7pnAXwY+GfB+sHUVq1mRcQhgDS/PLVX3feQTjV8DHiZKs87nY7pA44AW4DXgWMRcTrtUpjXSM5p+9vAJeWNuCQeAb4BDKX1S6j+nAN4TtJOSV2prWzHdq2/z0KjtNXivcRV9T1IuhDYCHw1Io5Lo6WX7TpK26TLOyLOAC2SmoBNwILRdkvzSZ+zpM8BRyJip6RbhptH2bVqck6WRMSbki4Htkj66wfsW/Kca71ncRCYXbDeDLyZUyzl8C9JVwKk+ZHUXjXfg6R6skLxZET8OjVXfd4AEXEM+D3Z9ZomScM/BgvzGsk5bb8I+Hd5Iz1vS4DPSzoAbCA7FfUI1Z0zEfFmmh8h+1FwE2U8tmu9WGwHrk13UUwFvgg8nXNME+lp4O60fDfZOf3h9i+nOygWAW8Pd20nE2VdiJ8CeyLihwWbqjZvSZelHgWSpgPtZBd9XwRuT7udnfPwd3E78EKkk9qTRUQ8GBHNETGH7N/sCxFxF1Wcs6QZkhqHl4GlQD/lPLbzvmiT9wQsB/5Gdp73W3nHU8K8fgEcAt4l+5XRSXaediuwL80vTvuK7K6w14HdQFve8Y8z50+QdbV3AX1pWl7NeQM3AK+knPuBb6f2eUAvsB/4FTAttTek9f1p+7y8czjP/G8Bnqn2nFNur6bpteH/q8p5bHu4DzMzK6rWT0OZmdkYuFiYmVlRLhZmZlaUi4WZmRXlYmFmZkW5WJidA0ln0qifw1PJRiqWNEcFowSbVZJaH+7D7FydiIiWvIMwKzf3LMxKIL1rYE16t0SvpGtS+9WStqZ3CmyVdFVqnyVpU3oPxauSFqePqpP0k/RuiufSU9lmuXOxMDs30886DbWiYNvxiLgJ6CYbq4i0/POIuAF4Elib2tcCf4jsPRStZE/lQvb+gXUR8RHgGPCFCc7HbEz8BLfZOZD0n4i4cJT2A2QvIfp7GszwcERcImmQ7D0C76b2QxFxqaQBoDkiThZ8xhxgS2QvskHSN4H6iPjexGdm9sHcszArnXif5ffbZzQnC5bP4OuKViFcLMxKZ0XB/M9peRvZyKgAdwF/TMtbgftg5OVFM8sVpNl4+FeL2bmZnt5KN+x3ETF8++w0SS+T/Qi7M7XdD/RI+jowAHSk9lXAekmdZD2I+8hGCTarSL5mYVYC6ZpFW0QM5h2L2UTwaSgzMyvKPQszMyvKPQszMyvKxcLMzIpysTAzs6JcLMzMrCgXCzMzK+q/h2WIEg210FkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['acc'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_acc'], linewidth=2, label='Test')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Model)              (None, 34)                178034    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               17500     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                2020      \n",
      "=================================================================\n",
      "Total params: 377,954\n",
      "Trainable params: 377,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_7 to have shape (20,) but got array with shape (14,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2f51e0eae437>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m              \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m              verbose=2, callbacks=[checkpointer]).history\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_7 to have shape (20,) but got array with shape (14,)"
     ]
    }
   ],
   "source": [
    "#Debut du decompte du temps\n",
    "start_time = time.time()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(autoencoder)\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(500, activation ='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(300, activation ='tanh'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(100, activation ='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(nb_class, activation ='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(metrics=['accuracy'], loss = 'mse', \n",
    "              optimizer='adam')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='DEGRA_GAUSSIEN.h5', \n",
    "                               verbose=2, save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(X_train, Yd_train,\n",
    "             validation_data=(X_test, Yd_test),\n",
    "             epochs= nb_epoch,\n",
    "             batch_size=batch_size,\n",
    "             shuffle=True,\n",
    "             verbose=2, callbacks=[checkpointer]).history\n",
    "\n",
    "\n",
    "score, acc = model.evaluate(X_test, y = Yd_test, \n",
    "               batch_size = batch_size, \n",
    "               verbose = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Temps d execution : %s secondes ---\" %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['acc'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_acc'], linewidth=2, label='Test')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
