{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kodzo.apedo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/kodzo.apedo/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import Input\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import os\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras import regularizers\n",
    "import time\n",
    "import time\n",
    "\n",
    "from keras import regularizers\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement des donnees \n",
    "\n",
    "df = pd.read_csv('/home/kodzo.apedo/Bureau/Visu/mesdonnees/mesdonnees_sans_degradation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42 #used to help randomly select the data points\n",
    "TEST_PCT = 0.30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds[:,0:34].astype(float)\n",
    "Y = ds[:,34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encodons la classe \"Classe\"\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoder_Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., 15, 15, 15])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefinissons nos classe\n",
    "\n",
    "dummy_y = np_utils.to_categorical(encoder_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yd = dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Yd_train, Yd_test = train_test_split(X, Yd, test_size = TEST_PCT, random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_class = 16 # Nombre de classe\n",
    "\n",
    "nb_epoch = 500\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "#Couche d'entr√©e\n",
    "\n",
    "input_dim = X_train.shape[1] #numbre de colonne, \n",
    "\n",
    "encoding_dim = 500 # Dimension d'encodage\n",
    "nb_class = 20 # Nombre de classe\n",
    "hidden_dim = encoding_dim - 200 #i.e. 7\n",
    "\n",
    "hidden_dim2 = hidden_dim - 200\n",
    "\n",
    "#hidden_dim3 = hidden_dim + 30\n",
    "\n",
    "learning_rate = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d execution : 0.054860591888427734 secondes ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Debut du decompte du temps\n",
    "start_time = time.time()\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoder = Dense(encoding_dim, activation='tanh', \n",
    "                activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
    "#encoder = Dense(hidden_dim2, activation='tanh')(encoder)\n",
    "encoder = Dense(input_dim, activation='relu')(encoder)\n",
    "\n",
    "\n",
    "print(\"Temps d execution : %s secondes ---\" %(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 34)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               17500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 34)                10234     \n",
      "=================================================================\n",
      "Total params: 178,034\n",
      "Trainable params: 178,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 223988 samples, validate on 95996 samples\n",
      "Epoch 1/500\n",
      "223988/223988 [==============================] - 10s 47us/step - loss: 0.5248 - acc: 0.8296 - val_loss: 0.2549 - val_acc: 0.9129\n",
      "Epoch 2/500\n",
      "223988/223988 [==============================] - 10s 44us/step - loss: 0.2185 - acc: 0.9090 - val_loss: 0.2016 - val_acc: 0.9146\n",
      "Epoch 3/500\n",
      "223988/223988 [==============================] - 10s 47us/step - loss: 0.1907 - acc: 0.9160 - val_loss: 0.1907 - val_acc: 0.9093\n",
      "Epoch 4/500\n",
      "223988/223988 [==============================] - 11s 47us/step - loss: 0.1821 - acc: 0.9235 - val_loss: 0.1815 - val_acc: 0.9274\n",
      "Epoch 5/500\n",
      "223988/223988 [==============================] - 10s 46us/step - loss: 0.1781 - acc: 0.9265 - val_loss: 0.1786 - val_acc: 0.9315\n",
      "Epoch 6/500\n",
      "223988/223988 [==============================] - 10s 45us/step - loss: 0.1770 - acc: 0.9238 - val_loss: 0.1767 - val_acc: 0.9313\n",
      "Epoch 7/500\n",
      "223988/223988 [==============================] - 10s 45us/step - loss: 0.1743 - acc: 0.9319 - val_loss: 0.1762 - val_acc: 0.9313\n",
      "Epoch 8/500\n",
      "223988/223988 [==============================] - 10s 43us/step - loss: 0.1764 - acc: 0.9005 - val_loss: 0.1774 - val_acc: 0.8852\n",
      "Epoch 9/500\n",
      "223988/223988 [==============================] - 10s 45us/step - loss: 0.1735 - acc: 0.9280 - val_loss: 0.1733 - val_acc: 0.9251\n",
      "Epoch 10/500\n",
      "223988/223988 [==============================] - 10s 45us/step - loss: 0.1724 - acc: 0.9312 - val_loss: 0.1728 - val_acc: 0.9217\n",
      "Epoch 11/500\n",
      "223988/223988 [==============================] - 10s 45us/step - loss: 0.1713 - acc: 0.9374 - val_loss: 0.1717 - val_acc: 0.9334\n",
      "Epoch 12/500\n",
      "223988/223988 [==============================] - 11s 49us/step - loss: 0.1727 - acc: 0.9128 - val_loss: 0.1723 - val_acc: 0.9257\n",
      "Epoch 13/500\n",
      "223988/223988 [==============================] - 10s 46us/step - loss: 0.1721 - acc: 0.9285 - val_loss: 0.1717 - val_acc: 0.9207\n",
      "Epoch 14/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1703 - acc: 0.9361 - val_loss: 0.1704 - val_acc: 0.9319\n",
      "Epoch 15/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1706 - acc: 0.9318 - val_loss: 0.1712 - val_acc: 0.9248\n",
      "Epoch 16/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1699 - acc: 0.9343 - val_loss: 0.1697 - val_acc: 0.9360\n",
      "Epoch 17/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1720 - acc: 0.9227 - val_loss: 0.1701 - val_acc: 0.9423\n",
      "Epoch 18/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1735 - acc: 0.9111 - val_loss: 0.1746 - val_acc: 0.9147\n",
      "Epoch 19/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1716 - acc: 0.9235 - val_loss: 0.1736 - val_acc: 0.9115\n",
      "Epoch 20/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1714 - acc: 0.9140 - val_loss: 0.1722 - val_acc: 0.9108\n",
      "Epoch 21/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1703 - acc: 0.9255 - val_loss: 0.1697 - val_acc: 0.9431\n",
      "Epoch 22/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1696 - acc: 0.9318 - val_loss: 0.1697 - val_acc: 0.9109\n",
      "Epoch 23/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1713 - acc: 0.9072 - val_loss: 0.1704 - val_acc: 0.9062\n",
      "Epoch 24/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1706 - acc: 0.9122 - val_loss: 0.1723 - val_acc: 0.9081\n",
      "Epoch 25/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1714 - acc: 0.9095 - val_loss: 0.1751 - val_acc: 0.8810\n",
      "Epoch 26/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1707 - acc: 0.9140 - val_loss: 0.1695 - val_acc: 0.9070\n",
      "Epoch 27/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1699 - acc: 0.9218 - val_loss: 0.1723 - val_acc: 0.8833\n",
      "Epoch 28/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1739 - acc: 0.9005 - val_loss: 0.1738 - val_acc: 0.9120\n",
      "Epoch 29/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1703 - acc: 0.9136 - val_loss: 0.1732 - val_acc: 0.9110\n",
      "Epoch 30/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1708 - acc: 0.8939 - val_loss: 0.1714 - val_acc: 0.9110\n",
      "Epoch 31/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1701 - acc: 0.9087 - val_loss: 0.1697 - val_acc: 0.8952\n",
      "Epoch 32/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1724 - acc: 0.8850 - val_loss: 0.1708 - val_acc: 0.9038\n",
      "Epoch 33/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1700 - acc: 0.9120 - val_loss: 0.1688 - val_acc: 0.9278\n",
      "Epoch 34/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1711 - acc: 0.8981 - val_loss: 0.1696 - val_acc: 0.9111\n",
      "Epoch 35/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1694 - acc: 0.9135 - val_loss: 0.1697 - val_acc: 0.8547\n",
      "Epoch 36/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1712 - acc: 0.8842 - val_loss: 0.1751 - val_acc: 0.8537\n",
      "Epoch 37/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1709 - acc: 0.9105 - val_loss: 0.1705 - val_acc: 0.9202\n",
      "Epoch 38/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1708 - acc: 0.9002 - val_loss: 0.1706 - val_acc: 0.9203\n",
      "Epoch 39/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1699 - acc: 0.9167 - val_loss: 0.1722 - val_acc: 0.9091\n",
      "Epoch 40/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1698 - acc: 0.9160 - val_loss: 0.1697 - val_acc: 0.9431\n",
      "Epoch 41/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1718 - acc: 0.9030 - val_loss: 0.1687 - val_acc: 0.9296\n",
      "Epoch 42/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1689 - acc: 0.9263 - val_loss: 0.1689 - val_acc: 0.9360\n",
      "Epoch 43/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1699 - acc: 0.9150 - val_loss: 0.1716 - val_acc: 0.8507\n",
      "Epoch 44/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1718 - acc: 0.9026 - val_loss: 0.1689 - val_acc: 0.9286\n",
      "Epoch 45/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1694 - acc: 0.9238 - val_loss: 0.1724 - val_acc: 0.9228\n",
      "Epoch 46/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1738 - acc: 0.9012 - val_loss: 0.1691 - val_acc: 0.9360\n",
      "Epoch 47/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1693 - acc: 0.9252 - val_loss: 0.1697 - val_acc: 0.9352\n",
      "Epoch 48/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1694 - acc: 0.9189 - val_loss: 0.1687 - val_acc: 0.9268\n",
      "Epoch 49/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1695 - acc: 0.9218 - val_loss: 0.1714 - val_acc: 0.9180\n",
      "Epoch 50/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1718 - acc: 0.8992 - val_loss: 0.1697 - val_acc: 0.8985\n",
      "Epoch 51/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1696 - acc: 0.9120 - val_loss: 0.1728 - val_acc: 0.9063\n",
      "Epoch 52/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1706 - acc: 0.9046 - val_loss: 0.1777 - val_acc: 0.8852\n",
      "Epoch 53/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1720 - acc: 0.9106 - val_loss: 0.1690 - val_acc: 0.9284\n",
      "Epoch 54/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1710 - acc: 0.9018 - val_loss: 0.1697 - val_acc: 0.9253\n",
      "Epoch 55/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1711 - acc: 0.9027 - val_loss: 0.1843 - val_acc: 0.7935\n",
      "Epoch 56/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1731 - acc: 0.8846 - val_loss: 0.1711 - val_acc: 0.8941\n",
      "Epoch 57/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1701 - acc: 0.9121 - val_loss: 0.1698 - val_acc: 0.8829\n",
      "Epoch 58/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1751 - acc: 0.8944 - val_loss: 0.1763 - val_acc: 0.8980\n",
      "Epoch 59/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1714 - acc: 0.9131 - val_loss: 0.1708 - val_acc: 0.9137\n",
      "Epoch 60/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1691 - acc: 0.9254 - val_loss: 0.1688 - val_acc: 0.9114\n",
      "Epoch 61/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1699 - acc: 0.9077 - val_loss: 0.1703 - val_acc: 0.9086\n",
      "Epoch 62/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1695 - acc: 0.9109 - val_loss: 0.1701 - val_acc: 0.9152\n",
      "Epoch 63/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1701 - acc: 0.9116 - val_loss: 0.1689 - val_acc: 0.9014\n",
      "Epoch 64/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1712 - acc: 0.8981 - val_loss: 0.1737 - val_acc: 0.8935\n",
      "Epoch 65/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1705 - acc: 0.9146 - val_loss: 0.1690 - val_acc: 0.9132\n",
      "Epoch 66/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1695 - acc: 0.9201 - val_loss: 0.1775 - val_acc: 0.9179\n",
      "Epoch 67/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1701 - acc: 0.9108 - val_loss: 0.1691 - val_acc: 0.8902\n",
      "Epoch 68/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1704 - acc: 0.9136 - val_loss: 0.1695 - val_acc: 0.9282\n",
      "Epoch 69/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1702 - acc: 0.9153 - val_loss: 0.1691 - val_acc: 0.9181\n",
      "Epoch 70/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1709 - acc: 0.9105 - val_loss: 0.1702 - val_acc: 0.8799\n",
      "Epoch 71/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1741 - acc: 0.8981 - val_loss: 0.1730 - val_acc: 0.9023\n",
      "Epoch 72/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1705 - acc: 0.9200 - val_loss: 0.1694 - val_acc: 0.9369\n",
      "Epoch 73/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1694 - acc: 0.9170 - val_loss: 0.1687 - val_acc: 0.9243\n",
      "Epoch 74/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1722 - acc: 0.8817 - val_loss: 0.1728 - val_acc: 0.9074\n",
      "Epoch 75/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1713 - acc: 0.9097 - val_loss: 0.1706 - val_acc: 0.9155\n",
      "Epoch 76/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1718 - acc: 0.8943 - val_loss: 0.1737 - val_acc: 0.8916\n",
      "Epoch 77/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1708 - acc: 0.9055 - val_loss: 0.1688 - val_acc: 0.9202\n",
      "Epoch 78/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1714 - acc: 0.9079 - val_loss: 0.1699 - val_acc: 0.9201\n",
      "Epoch 79/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1693 - acc: 0.9168 - val_loss: 0.1704 - val_acc: 0.9078\n",
      "Epoch 80/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1709 - acc: 0.9036 - val_loss: 0.1723 - val_acc: 0.7724\n",
      "Epoch 81/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1704 - acc: 0.9064 - val_loss: 0.1690 - val_acc: 0.8971\n",
      "Epoch 82/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1691 - acc: 0.9161 - val_loss: 0.1695 - val_acc: 0.9315\n",
      "Epoch 83/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1690 - acc: 0.9190 - val_loss: 0.1695 - val_acc: 0.9202\n",
      "Epoch 84/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1702 - acc: 0.9141 - val_loss: 0.1709 - val_acc: 0.9229\n",
      "Epoch 85/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1747 - acc: 0.8607 - val_loss: 0.1758 - val_acc: 0.8740\n",
      "Epoch 86/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1707 - acc: 0.9044 - val_loss: 0.1728 - val_acc: 0.8533\n",
      "Epoch 87/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1722 - acc: 0.9012 - val_loss: 0.1693 - val_acc: 0.9134\n",
      "Epoch 88/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1698 - acc: 0.9137 - val_loss: 0.1693 - val_acc: 0.8663\n",
      "Epoch 89/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1704 - acc: 0.9037 - val_loss: 0.1736 - val_acc: 0.8394\n",
      "Epoch 90/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1704 - acc: 0.9078 - val_loss: 0.1702 - val_acc: 0.8905\n",
      "Epoch 91/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1708 - acc: 0.8968 - val_loss: 0.1693 - val_acc: 0.9293\n",
      "Epoch 92/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1712 - acc: 0.8982 - val_loss: 0.1694 - val_acc: 0.9062\n",
      "Epoch 93/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1698 - acc: 0.9144 - val_loss: 0.1691 - val_acc: 0.9222\n",
      "Epoch 94/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1694 - acc: 0.9135 - val_loss: 0.1688 - val_acc: 0.8895\n",
      "Epoch 95/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1689 - acc: 0.9146 - val_loss: 0.1692 - val_acc: 0.9007\n",
      "Epoch 96/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1705 - acc: 0.9032 - val_loss: 0.1699 - val_acc: 0.9138\n",
      "Epoch 97/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1702 - acc: 0.9098 - val_loss: 0.1693 - val_acc: 0.9239\n",
      "Epoch 98/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1726 - acc: 0.8955 - val_loss: 0.1707 - val_acc: 0.9123\n",
      "Epoch 99/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1727 - acc: 0.8964 - val_loss: 0.1690 - val_acc: 0.9231\n",
      "Epoch 100/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1699 - acc: 0.9174 - val_loss: 0.1750 - val_acc: 0.8324\n",
      "Epoch 101/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1712 - acc: 0.9070 - val_loss: 0.1693 - val_acc: 0.9139\n",
      "Epoch 102/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1702 - acc: 0.9066 - val_loss: 0.1687 - val_acc: 0.9172\n",
      "Epoch 103/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1700 - acc: 0.9046 - val_loss: 0.1686 - val_acc: 0.9016\n",
      "Epoch 104/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1729 - acc: 0.8984 - val_loss: 0.1713 - val_acc: 0.8815\n",
      "Epoch 105/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1714 - acc: 0.9046 - val_loss: 0.1705 - val_acc: 0.8940\n",
      "Epoch 106/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1690 - acc: 0.9271 - val_loss: 0.1711 - val_acc: 0.9182\n",
      "Epoch 107/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1701 - acc: 0.9064 - val_loss: 0.1932 - val_acc: 0.6721\n",
      "Epoch 108/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1749 - acc: 0.8395 - val_loss: 0.1712 - val_acc: 0.8762\n",
      "Epoch 109/500\n",
      "223988/223988 [==============================] - 9s 39us/step - loss: 0.1730 - acc: 0.9084 - val_loss: 0.1698 - val_acc: 0.9238\n",
      "Epoch 110/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1711 - acc: 0.9088 - val_loss: 0.1694 - val_acc: 0.9169\n",
      "Epoch 111/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1701 - acc: 0.9184 - val_loss: 0.1708 - val_acc: 0.9114\n",
      "Epoch 112/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1716 - acc: 0.9076 - val_loss: 0.1698 - val_acc: 0.9202\n",
      "Epoch 113/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1716 - acc: 0.9030 - val_loss: 0.1693 - val_acc: 0.9149\n",
      "Epoch 114/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1694 - acc: 0.9174 - val_loss: 0.1691 - val_acc: 0.9049\n",
      "Epoch 115/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1699 - acc: 0.9048 - val_loss: 0.1689 - val_acc: 0.8910\n",
      "Epoch 116/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1687 - acc: 0.9242 - val_loss: 0.1719 - val_acc: 0.9300\n",
      "Epoch 117/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1701 - acc: 0.9070 - val_loss: 0.1700 - val_acc: 0.8926\n",
      "Epoch 118/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1711 - acc: 0.8932 - val_loss: 0.1705 - val_acc: 0.9127\n",
      "Epoch 119/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1698 - acc: 0.9229 - val_loss: 0.1727 - val_acc: 0.8974\n",
      "Epoch 120/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1704 - acc: 0.9135 - val_loss: 0.1729 - val_acc: 0.9205\n",
      "Epoch 121/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1694 - acc: 0.9192 - val_loss: 0.1685 - val_acc: 0.9236\n",
      "Epoch 122/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1693 - acc: 0.9112 - val_loss: 0.1687 - val_acc: 0.9274\n",
      "Epoch 123/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1729 - acc: 0.8913 - val_loss: 0.1711 - val_acc: 0.8995\n",
      "Epoch 124/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1714 - acc: 0.8924 - val_loss: 0.1707 - val_acc: 0.8644\n",
      "Epoch 125/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1695 - acc: 0.9210 - val_loss: 0.1700 - val_acc: 0.8583\n",
      "Epoch 126/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1707 - acc: 0.8979 - val_loss: 0.1694 - val_acc: 0.9098\n",
      "Epoch 127/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1693 - acc: 0.9109 - val_loss: 0.1696 - val_acc: 0.9048\n",
      "Epoch 128/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1713 - acc: 0.8904 - val_loss: 0.1684 - val_acc: 0.9352\n",
      "Epoch 129/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1700 - acc: 0.9003 - val_loss: 0.1687 - val_acc: 0.9209\n",
      "Epoch 130/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1749 - acc: 0.8763 - val_loss: 0.1704 - val_acc: 0.9111\n",
      "Epoch 131/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1717 - acc: 0.9027 - val_loss: 0.1715 - val_acc: 0.9118\n",
      "Epoch 132/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1695 - acc: 0.9167 - val_loss: 0.1686 - val_acc: 0.9344\n",
      "Epoch 133/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1697 - acc: 0.9084 - val_loss: 0.1695 - val_acc: 0.8607\n",
      "Epoch 134/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1707 - acc: 0.8902 - val_loss: 0.1704 - val_acc: 0.9294\n",
      "Epoch 135/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1705 - acc: 0.8992 - val_loss: 0.1691 - val_acc: 0.9208\n",
      "Epoch 136/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1698 - acc: 0.9139 - val_loss: 0.1691 - val_acc: 0.9074\n",
      "Epoch 137/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1700 - acc: 0.9072 - val_loss: 0.1689 - val_acc: 0.8944\n",
      "Epoch 138/500\n",
      "223988/223988 [==============================] - 9s 39us/step - loss: 0.1687 - acc: 0.9240 - val_loss: 0.1689 - val_acc: 0.9034\n",
      "Epoch 139/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1703 - acc: 0.9036 - val_loss: 0.1695 - val_acc: 0.9080\n",
      "Epoch 140/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1696 - acc: 0.9112 - val_loss: 0.1694 - val_acc: 0.9064\n",
      "Epoch 141/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1717 - acc: 0.8858 - val_loss: 0.1702 - val_acc: 0.9015\n",
      "Epoch 142/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1707 - acc: 0.9114 - val_loss: 0.1703 - val_acc: 0.9031\n",
      "Epoch 143/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1711 - acc: 0.8946 - val_loss: 0.1707 - val_acc: 0.8931\n",
      "Epoch 144/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1695 - acc: 0.9213 - val_loss: 0.1698 - val_acc: 0.9263\n",
      "Epoch 145/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1708 - acc: 0.9073 - val_loss: 0.1732 - val_acc: 0.8593\n",
      "Epoch 146/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1702 - acc: 0.9038 - val_loss: 0.1740 - val_acc: 0.8956\n",
      "Epoch 147/500\n",
      "223988/223988 [==============================] - 9s 39us/step - loss: 0.1783 - acc: 0.8394 - val_loss: 0.1733 - val_acc: 0.8888\n",
      "Epoch 148/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1715 - acc: 0.9052 - val_loss: 0.1703 - val_acc: 0.9019\n",
      "Epoch 149/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1720 - acc: 0.9015 - val_loss: 0.1736 - val_acc: 0.8887\n",
      "Epoch 150/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1700 - acc: 0.9185 - val_loss: 0.1701 - val_acc: 0.9290\n",
      "Epoch 151/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1697 - acc: 0.9124 - val_loss: 0.1702 - val_acc: 0.9132\n",
      "Epoch 152/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1697 - acc: 0.9157 - val_loss: 0.1697 - val_acc: 0.9275\n",
      "Epoch 153/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1701 - acc: 0.9072 - val_loss: 0.1685 - val_acc: 0.9067\n",
      "Epoch 154/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1708 - acc: 0.9066 - val_loss: 0.1725 - val_acc: 0.9150\n",
      "Epoch 155/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1701 - acc: 0.9065 - val_loss: 0.1696 - val_acc: 0.9303\n",
      "Epoch 156/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1722 - acc: 0.9025 - val_loss: 0.1720 - val_acc: 0.8880\n",
      "Epoch 157/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1714 - acc: 0.8892 - val_loss: 0.1720 - val_acc: 0.9238\n",
      "Epoch 158/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1722 - acc: 0.8979 - val_loss: 0.1698 - val_acc: 0.9170\n",
      "Epoch 159/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1700 - acc: 0.9090 - val_loss: 0.1701 - val_acc: 0.9108\n",
      "Epoch 160/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1694 - acc: 0.9092 - val_loss: 0.1687 - val_acc: 0.9244\n",
      "Epoch 161/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1699 - acc: 0.9035 - val_loss: 0.1700 - val_acc: 0.9300\n",
      "Epoch 162/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1701 - acc: 0.9102 - val_loss: 0.1712 - val_acc: 0.9236\n",
      "Epoch 163/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1703 - acc: 0.9065 - val_loss: 0.1696 - val_acc: 0.9135\n",
      "Epoch 164/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1697 - acc: 0.9124 - val_loss: 0.1690 - val_acc: 0.9316\n",
      "Epoch 165/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1686 - acc: 0.9306 - val_loss: 0.1710 - val_acc: 0.9061\n",
      "Epoch 166/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1704 - acc: 0.9025 - val_loss: 0.1681 - val_acc: 0.9430\n",
      "Epoch 167/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1711 - acc: 0.8859 - val_loss: 0.1742 - val_acc: 0.8996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1718 - acc: 0.8857 - val_loss: 0.1696 - val_acc: 0.8802\n",
      "Epoch 169/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1737 - acc: 0.8873 - val_loss: 0.1802 - val_acc: 0.8229\n",
      "Epoch 170/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1701 - acc: 0.9112 - val_loss: 0.1706 - val_acc: 0.8612\n",
      "Epoch 171/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1708 - acc: 0.8995 - val_loss: 0.1689 - val_acc: 0.9259\n",
      "Epoch 172/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1700 - acc: 0.9086 - val_loss: 0.1735 - val_acc: 0.8912\n",
      "Epoch 173/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1716 - acc: 0.8813 - val_loss: 0.1691 - val_acc: 0.9005\n",
      "Epoch 174/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1700 - acc: 0.9012 - val_loss: 0.1689 - val_acc: 0.8913\n",
      "Epoch 175/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1716 - acc: 0.9022 - val_loss: 0.1708 - val_acc: 0.9114\n",
      "Epoch 176/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1744 - acc: 0.8730 - val_loss: 0.1702 - val_acc: 0.8977\n",
      "Epoch 177/500\n",
      "223988/223988 [==============================] - 9s 42us/step - loss: 0.1696 - acc: 0.9245 - val_loss: 0.1695 - val_acc: 0.8992\n",
      "Epoch 178/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1692 - acc: 0.9208 - val_loss: 0.1685 - val_acc: 0.9307\n",
      "Epoch 179/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1704 - acc: 0.9080 - val_loss: 0.1684 - val_acc: 0.9288\n",
      "Epoch 180/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1693 - acc: 0.9268 - val_loss: 0.1690 - val_acc: 0.9404\n",
      "Epoch 181/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1696 - acc: 0.9106 - val_loss: 0.1687 - val_acc: 0.9307\n",
      "Epoch 182/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1689 - acc: 0.9211 - val_loss: 0.1691 - val_acc: 0.9176\n",
      "Epoch 183/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1707 - acc: 0.8952 - val_loss: 0.1689 - val_acc: 0.9333\n",
      "Epoch 184/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1692 - acc: 0.9171 - val_loss: 0.1693 - val_acc: 0.9282\n",
      "Epoch 185/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1732 - acc: 0.8857 - val_loss: 0.1700 - val_acc: 0.8858\n",
      "Epoch 186/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1727 - acc: 0.8950 - val_loss: 0.1708 - val_acc: 0.9140\n",
      "Epoch 187/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1708 - acc: 0.9057 - val_loss: 0.1695 - val_acc: 0.9237\n",
      "Epoch 188/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1699 - acc: 0.9164 - val_loss: 0.1715 - val_acc: 0.8938\n",
      "Epoch 189/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1702 - acc: 0.9061 - val_loss: 0.1690 - val_acc: 0.9244\n",
      "Epoch 190/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1807 - acc: 0.8614 - val_loss: 0.1729 - val_acc: 0.8960\n",
      "Epoch 191/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1710 - acc: 0.9156 - val_loss: 0.1692 - val_acc: 0.9332\n",
      "Epoch 192/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1706 - acc: 0.9146 - val_loss: 0.1691 - val_acc: 0.9332\n",
      "Epoch 193/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1705 - acc: 0.9113 - val_loss: 0.1701 - val_acc: 0.9111\n",
      "Epoch 194/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1692 - acc: 0.9139 - val_loss: 0.1692 - val_acc: 0.9393\n",
      "Epoch 195/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1690 - acc: 0.9233 - val_loss: 0.1684 - val_acc: 0.9383\n",
      "Epoch 196/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1701 - acc: 0.9071 - val_loss: 0.1730 - val_acc: 0.8708\n",
      "Epoch 197/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1698 - acc: 0.9066 - val_loss: 0.1689 - val_acc: 0.9232\n",
      "Epoch 198/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1691 - acc: 0.9105 - val_loss: 0.1688 - val_acc: 0.9157\n",
      "Epoch 199/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1753 - acc: 0.8742 - val_loss: 0.1709 - val_acc: 0.9188\n",
      "Epoch 200/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1700 - acc: 0.9126 - val_loss: 0.1687 - val_acc: 0.9256\n",
      "Epoch 201/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1692 - acc: 0.9206 - val_loss: 0.1696 - val_acc: 0.9172\n",
      "Epoch 202/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1732 - acc: 0.9052 - val_loss: 0.1687 - val_acc: 0.9250\n",
      "Epoch 203/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1711 - acc: 0.8959 - val_loss: 0.1703 - val_acc: 0.8966\n",
      "Epoch 204/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1697 - acc: 0.9122 - val_loss: 0.1691 - val_acc: 0.9241\n",
      "Epoch 205/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1709 - acc: 0.9128 - val_loss: 0.1734 - val_acc: 0.8869\n",
      "Epoch 206/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1755 - acc: 0.8423 - val_loss: 0.1705 - val_acc: 0.9066\n",
      "Epoch 207/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1710 - acc: 0.9156 - val_loss: 0.1719 - val_acc: 0.8940\n",
      "Epoch 208/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1717 - acc: 0.9183 - val_loss: 0.1698 - val_acc: 0.9356\n",
      "Epoch 209/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1703 - acc: 0.9253 - val_loss: 0.1691 - val_acc: 0.9270\n",
      "Epoch 210/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1701 - acc: 0.9151 - val_loss: 0.1708 - val_acc: 0.9104\n",
      "Epoch 211/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1696 - acc: 0.9141 - val_loss: 0.1692 - val_acc: 0.9145\n",
      "Epoch 212/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1696 - acc: 0.9142 - val_loss: 0.1707 - val_acc: 0.8764\n",
      "Epoch 213/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1706 - acc: 0.9116 - val_loss: 0.1692 - val_acc: 0.9308\n",
      "Epoch 214/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1705 - acc: 0.9110 - val_loss: 0.1702 - val_acc: 0.8927\n",
      "Epoch 215/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1723 - acc: 0.8946 - val_loss: 0.1701 - val_acc: 0.8783\n",
      "Epoch 216/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1699 - acc: 0.9012 - val_loss: 0.1687 - val_acc: 0.8881\n",
      "Epoch 217/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1692 - acc: 0.9165 - val_loss: 0.1689 - val_acc: 0.9038\n",
      "Epoch 218/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1693 - acc: 0.9077 - val_loss: 0.1690 - val_acc: 0.9089\n",
      "Epoch 219/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1717 - acc: 0.8918 - val_loss: 0.1730 - val_acc: 0.8966\n",
      "Epoch 220/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1718 - acc: 0.8970 - val_loss: 0.1833 - val_acc: 0.8288\n",
      "Epoch 221/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1702 - acc: 0.9011 - val_loss: 0.1705 - val_acc: 0.8847\n",
      "Epoch 222/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1697 - acc: 0.9053 - val_loss: 0.1698 - val_acc: 0.8980\n",
      "Epoch 223/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1736 - acc: 0.8690 - val_loss: 0.1708 - val_acc: 0.9110\n",
      "Epoch 224/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1701 - acc: 0.9162 - val_loss: 0.1688 - val_acc: 0.9182\n",
      "Epoch 225/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1688 - acc: 0.9277 - val_loss: 0.1704 - val_acc: 0.9105\n",
      "Epoch 226/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1699 - acc: 0.9135 - val_loss: 0.1721 - val_acc: 0.9069\n",
      "Epoch 227/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1723 - acc: 0.9030 - val_loss: 0.1695 - val_acc: 0.9216\n",
      "Epoch 228/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1703 - acc: 0.9019 - val_loss: 0.1704 - val_acc: 0.8976\n",
      "Epoch 229/500\n",
      "223988/223988 [==============================] - 9s 39us/step - loss: 0.1695 - acc: 0.9093 - val_loss: 0.1689 - val_acc: 0.9256\n",
      "Epoch 230/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1691 - acc: 0.9131 - val_loss: 0.1688 - val_acc: 0.9174\n",
      "Epoch 231/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1697 - acc: 0.9145 - val_loss: 0.1748 - val_acc: 0.8849\n",
      "Epoch 232/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1716 - acc: 0.8906 - val_loss: 0.1706 - val_acc: 0.9060\n",
      "Epoch 233/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1715 - acc: 0.9084 - val_loss: 0.1689 - val_acc: 0.9297\n",
      "Epoch 234/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1700 - acc: 0.9126 - val_loss: 0.1719 - val_acc: 0.9175\n",
      "Epoch 235/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1702 - acc: 0.9062 - val_loss: 0.1710 - val_acc: 0.9072\n",
      "Epoch 236/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1691 - acc: 0.9134 - val_loss: 0.1690 - val_acc: 0.9197\n",
      "Epoch 237/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1698 - acc: 0.9014 - val_loss: 0.1744 - val_acc: 0.8856\n",
      "Epoch 238/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1706 - acc: 0.9056 - val_loss: 0.1687 - val_acc: 0.9193\n",
      "Epoch 239/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1713 - acc: 0.8980 - val_loss: 0.1694 - val_acc: 0.9337\n",
      "Epoch 240/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1716 - acc: 0.8843 - val_loss: 0.1700 - val_acc: 0.9043\n",
      "Epoch 241/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1703 - acc: 0.8987 - val_loss: 0.1691 - val_acc: 0.8880\n",
      "Epoch 242/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1696 - acc: 0.9149 - val_loss: 0.1733 - val_acc: 0.7770\n",
      "Epoch 243/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1733 - acc: 0.8659 - val_loss: 0.1709 - val_acc: 0.8883\n",
      "Epoch 244/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1710 - acc: 0.9038 - val_loss: 0.1694 - val_acc: 0.9155\n",
      "Epoch 245/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1694 - acc: 0.9170 - val_loss: 0.1689 - val_acc: 0.9082\n",
      "Epoch 246/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1695 - acc: 0.9119 - val_loss: 0.1691 - val_acc: 0.9306\n",
      "Epoch 247/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1696 - acc: 0.9215 - val_loss: 0.1730 - val_acc: 0.8788\n",
      "Epoch 248/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1696 - acc: 0.9184 - val_loss: 0.1695 - val_acc: 0.9178\n",
      "Epoch 249/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1710 - acc: 0.9002 - val_loss: 0.1689 - val_acc: 0.9142\n",
      "Epoch 250/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1691 - acc: 0.9190 - val_loss: 0.1709 - val_acc: 0.9099\n",
      "Epoch 251/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1712 - acc: 0.9029 - val_loss: 0.1717 - val_acc: 0.9069\n",
      "Epoch 252/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1742 - acc: 0.8645 - val_loss: 0.1710 - val_acc: 0.9048\n",
      "Epoch 253/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1745 - acc: 0.8952 - val_loss: 0.1699 - val_acc: 0.9183\n",
      "Epoch 254/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1700 - acc: 0.9203 - val_loss: 0.1693 - val_acc: 0.9209\n",
      "Epoch 255/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1692 - acc: 0.9249 - val_loss: 0.1700 - val_acc: 0.9030\n",
      "Epoch 256/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1718 - acc: 0.8921 - val_loss: 0.1740 - val_acc: 0.8842\n",
      "Epoch 257/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1715 - acc: 0.9022 - val_loss: 0.1690 - val_acc: 0.9354\n",
      "Epoch 258/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1709 - acc: 0.8943 - val_loss: 0.1700 - val_acc: 0.8849\n",
      "Epoch 259/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1698 - acc: 0.9134 - val_loss: 0.1685 - val_acc: 0.9380\n",
      "Epoch 260/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1704 - acc: 0.9095 - val_loss: 0.1690 - val_acc: 0.9254\n",
      "Epoch 261/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1692 - acc: 0.9133 - val_loss: 0.1695 - val_acc: 0.9256\n",
      "Epoch 262/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1693 - acc: 0.9111 - val_loss: 0.1718 - val_acc: 0.8965\n",
      "Epoch 263/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1690 - acc: 0.9103 - val_loss: 0.1691 - val_acc: 0.9122\n",
      "Epoch 264/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1701 - acc: 0.8978 - val_loss: 0.1711 - val_acc: 0.8221\n",
      "Epoch 265/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1712 - acc: 0.9021 - val_loss: 0.1770 - val_acc: 0.8977\n",
      "Epoch 266/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1703 - acc: 0.9018 - val_loss: 0.1687 - val_acc: 0.9268\n",
      "Epoch 267/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1687 - acc: 0.9244 - val_loss: 0.1688 - val_acc: 0.9160\n",
      "Epoch 268/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1701 - acc: 0.9056 - val_loss: 0.1690 - val_acc: 0.9240\n",
      "Epoch 269/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1697 - acc: 0.9083 - val_loss: 0.1707 - val_acc: 0.9194\n",
      "Epoch 270/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1726 - acc: 0.8939 - val_loss: 0.1705 - val_acc: 0.9037\n",
      "Epoch 271/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1705 - acc: 0.9013 - val_loss: 0.1688 - val_acc: 0.9075\n",
      "Epoch 272/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1693 - acc: 0.9104 - val_loss: 0.1682 - val_acc: 0.9367\n",
      "Epoch 273/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1701 - acc: 0.9088 - val_loss: 0.1689 - val_acc: 0.9191\n",
      "Epoch 274/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1724 - acc: 0.9020 - val_loss: 0.1697 - val_acc: 0.8923\n",
      "Epoch 275/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1693 - acc: 0.9098 - val_loss: 0.1693 - val_acc: 0.9060\n",
      "Epoch 276/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1708 - acc: 0.8939 - val_loss: 0.1683 - val_acc: 0.9229\n",
      "Epoch 277/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1704 - acc: 0.9047 - val_loss: 0.1694 - val_acc: 0.9219\n",
      "Epoch 278/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1698 - acc: 0.9158 - val_loss: 0.1686 - val_acc: 0.9257\n",
      "Epoch 279/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1687 - acc: 0.9183 - val_loss: 0.1682 - val_acc: 0.9318\n",
      "Epoch 280/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1700 - acc: 0.8977 - val_loss: 0.1692 - val_acc: 0.9132\n",
      "Epoch 281/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1770 - acc: 0.8394 - val_loss: 0.1725 - val_acc: 0.8852\n",
      "Epoch 282/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1731 - acc: 0.8915 - val_loss: 0.1717 - val_acc: 0.9093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1710 - acc: 0.9113 - val_loss: 0.1703 - val_acc: 0.9196\n",
      "Epoch 284/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1699 - acc: 0.9194 - val_loss: 0.1698 - val_acc: 0.9216\n",
      "Epoch 285/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1702 - acc: 0.9155 - val_loss: 0.1695 - val_acc: 0.9210\n",
      "Epoch 286/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1721 - acc: 0.9079 - val_loss: 0.1697 - val_acc: 0.9212\n",
      "Epoch 287/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1705 - acc: 0.9117 - val_loss: 0.1699 - val_acc: 0.9096\n",
      "Epoch 288/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1697 - acc: 0.9155 - val_loss: 0.1718 - val_acc: 0.8865\n",
      "Epoch 289/500\n",
      "223988/223988 [==============================] - 9s 39us/step - loss: 0.1696 - acc: 0.9103 - val_loss: 0.1720 - val_acc: 0.9085\n",
      "Epoch 290/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1691 - acc: 0.9160 - val_loss: 0.1683 - val_acc: 0.9355\n",
      "Epoch 291/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1698 - acc: 0.9171 - val_loss: 0.1725 - val_acc: 0.8850\n",
      "Epoch 292/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1712 - acc: 0.8908 - val_loss: 0.1690 - val_acc: 0.9325\n",
      "Epoch 293/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1717 - acc: 0.8902 - val_loss: 0.1690 - val_acc: 0.9175\n",
      "Epoch 294/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1712 - acc: 0.8960 - val_loss: 0.1698 - val_acc: 0.8777\n",
      "Epoch 295/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1696 - acc: 0.9044 - val_loss: 0.1696 - val_acc: 0.8626\n",
      "Epoch 296/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1698 - acc: 0.9003 - val_loss: 0.1685 - val_acc: 0.9216\n",
      "Epoch 297/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1706 - acc: 0.8978 - val_loss: 0.1728 - val_acc: 0.8794\n",
      "Epoch 298/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1702 - acc: 0.9058 - val_loss: 0.1713 - val_acc: 0.8845\n",
      "Epoch 299/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1718 - acc: 0.8893 - val_loss: 0.1688 - val_acc: 0.9173\n",
      "Epoch 300/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1717 - acc: 0.9014 - val_loss: 0.1700 - val_acc: 0.8996\n",
      "Epoch 301/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1690 - acc: 0.9163 - val_loss: 0.1683 - val_acc: 0.9198\n",
      "Epoch 302/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1693 - acc: 0.9105 - val_loss: 0.1701 - val_acc: 0.9105\n",
      "Epoch 303/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1702 - acc: 0.8908 - val_loss: 0.1685 - val_acc: 0.9218\n",
      "Epoch 304/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1704 - acc: 0.9164 - val_loss: 0.1693 - val_acc: 0.9250\n",
      "Epoch 305/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1698 - acc: 0.9107 - val_loss: 0.1703 - val_acc: 0.8885\n",
      "Epoch 306/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1698 - acc: 0.9047 - val_loss: 0.1685 - val_acc: 0.9329\n",
      "Epoch 307/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1718 - acc: 0.8878 - val_loss: 0.1714 - val_acc: 0.8864\n",
      "Epoch 308/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1697 - acc: 0.9088 - val_loss: 0.1723 - val_acc: 0.8953\n",
      "Epoch 309/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1701 - acc: 0.9072 - val_loss: 0.1714 - val_acc: 0.8185\n",
      "Epoch 310/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1733 - acc: 0.8861 - val_loss: 0.1692 - val_acc: 0.9190\n",
      "Epoch 311/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1696 - acc: 0.9097 - val_loss: 0.1693 - val_acc: 0.8987\n",
      "Epoch 312/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1698 - acc: 0.9100 - val_loss: 0.1687 - val_acc: 0.9173\n",
      "Epoch 313/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1710 - acc: 0.9055 - val_loss: 0.1696 - val_acc: 0.8596\n",
      "Epoch 314/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1695 - acc: 0.9084 - val_loss: 0.1691 - val_acc: 0.9224\n",
      "Epoch 315/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1699 - acc: 0.9116 - val_loss: 0.1711 - val_acc: 0.9013\n",
      "Epoch 316/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1722 - acc: 0.8990 - val_loss: 0.1699 - val_acc: 0.8931\n",
      "Epoch 317/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1699 - acc: 0.9076 - val_loss: 0.1706 - val_acc: 0.8939\n",
      "Epoch 318/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1699 - acc: 0.9093 - val_loss: 0.1698 - val_acc: 0.9153\n",
      "Epoch 319/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1693 - acc: 0.9166 - val_loss: 0.1683 - val_acc: 0.9401\n",
      "Epoch 320/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1705 - acc: 0.9123 - val_loss: 0.1691 - val_acc: 0.8901\n",
      "Epoch 321/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1694 - acc: 0.9111 - val_loss: 0.1696 - val_acc: 0.9034\n",
      "Epoch 322/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1757 - acc: 0.8353 - val_loss: 0.1788 - val_acc: 0.7899\n",
      "Epoch 323/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1746 - acc: 0.8653 - val_loss: 0.1712 - val_acc: 0.9052\n",
      "Epoch 324/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1717 - acc: 0.9069 - val_loss: 0.1754 - val_acc: 0.8655\n",
      "Epoch 325/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1741 - acc: 0.8817 - val_loss: 0.1708 - val_acc: 0.9204\n",
      "Epoch 326/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1714 - acc: 0.9140 - val_loss: 0.1711 - val_acc: 0.9145\n",
      "Epoch 327/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1718 - acc: 0.9090 - val_loss: 0.1698 - val_acc: 0.9253\n",
      "Epoch 328/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1711 - acc: 0.9165 - val_loss: 0.1695 - val_acc: 0.9204\n",
      "Epoch 329/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1708 - acc: 0.9188 - val_loss: 0.1703 - val_acc: 0.9128\n",
      "Epoch 330/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1706 - acc: 0.9164 - val_loss: 0.1712 - val_acc: 0.9222\n",
      "Epoch 331/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1701 - acc: 0.9200 - val_loss: 0.1716 - val_acc: 0.9180\n",
      "Epoch 332/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1702 - acc: 0.9136 - val_loss: 0.1715 - val_acc: 0.8804\n",
      "Epoch 333/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1704 - acc: 0.9133 - val_loss: 0.1697 - val_acc: 0.9283\n",
      "Epoch 334/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1707 - acc: 0.9082 - val_loss: 0.1699 - val_acc: 0.9187\n",
      "Epoch 335/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1711 - acc: 0.8990 - val_loss: 0.1711 - val_acc: 0.8686\n",
      "Epoch 336/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1719 - acc: 0.8887 - val_loss: 0.1690 - val_acc: 0.9251\n",
      "Epoch 337/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1692 - acc: 0.9220 - val_loss: 0.1703 - val_acc: 0.9060\n",
      "Epoch 338/500\n",
      "223988/223988 [==============================] - 9s 39us/step - loss: 0.1700 - acc: 0.9150 - val_loss: 0.1693 - val_acc: 0.9008\n",
      "Epoch 339/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1687 - acc: 0.9195 - val_loss: 0.1687 - val_acc: 0.9126\n",
      "Epoch 340/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1718 - acc: 0.8967 - val_loss: 0.1691 - val_acc: 0.9248\n",
      "Epoch 341/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1713 - acc: 0.8918 - val_loss: 0.1713 - val_acc: 0.8965\n",
      "Epoch 342/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1783 - acc: 0.8332 - val_loss: 0.1745 - val_acc: 0.8865\n",
      "Epoch 343/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1729 - acc: 0.8982 - val_loss: 0.1717 - val_acc: 0.9041\n",
      "Epoch 344/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1704 - acc: 0.9144 - val_loss: 0.1697 - val_acc: 0.9137\n",
      "Epoch 345/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1701 - acc: 0.9165 - val_loss: 0.1703 - val_acc: 0.9030\n",
      "Epoch 346/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1707 - acc: 0.9045 - val_loss: 0.1692 - val_acc: 0.9233\n",
      "Epoch 347/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1699 - acc: 0.9166 - val_loss: 0.1695 - val_acc: 0.9077\n",
      "Epoch 348/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1700 - acc: 0.9110 - val_loss: 0.1694 - val_acc: 0.9030\n",
      "Epoch 349/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1708 - acc: 0.9071 - val_loss: 0.1694 - val_acc: 0.9095\n",
      "Epoch 350/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1702 - acc: 0.9113 - val_loss: 0.1691 - val_acc: 0.9199\n",
      "Epoch 351/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1697 - acc: 0.9101 - val_loss: 0.1697 - val_acc: 0.9136\n",
      "Epoch 352/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1703 - acc: 0.9009 - val_loss: 0.1691 - val_acc: 0.9134\n",
      "Epoch 353/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1705 - acc: 0.9028 - val_loss: 0.1716 - val_acc: 0.8216\n",
      "Epoch 354/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1700 - acc: 0.9078 - val_loss: 0.1691 - val_acc: 0.9150\n",
      "Epoch 355/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1696 - acc: 0.9114 - val_loss: 0.1684 - val_acc: 0.9338\n",
      "Epoch 356/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1698 - acc: 0.9081 - val_loss: 0.1688 - val_acc: 0.9242\n",
      "Epoch 357/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1695 - acc: 0.9114 - val_loss: 0.1688 - val_acc: 0.9063\n",
      "Epoch 358/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1691 - acc: 0.9158 - val_loss: 0.1692 - val_acc: 0.9017\n",
      "Epoch 359/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1691 - acc: 0.9125 - val_loss: 0.1795 - val_acc: 0.8633\n",
      "Epoch 360/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1727 - acc: 0.8800 - val_loss: 0.1724 - val_acc: 0.9054\n",
      "Epoch 361/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1715 - acc: 0.8776 - val_loss: 0.1710 - val_acc: 0.8986\n",
      "Epoch 362/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1703 - acc: 0.9057 - val_loss: 0.1708 - val_acc: 0.9194\n",
      "Epoch 363/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1704 - acc: 0.9137 - val_loss: 0.1688 - val_acc: 0.9172\n",
      "Epoch 364/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1701 - acc: 0.9074 - val_loss: 0.1688 - val_acc: 0.9235\n",
      "Epoch 365/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1695 - acc: 0.9100 - val_loss: 0.1690 - val_acc: 0.9105\n",
      "Epoch 366/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1705 - acc: 0.9050 - val_loss: 0.1712 - val_acc: 0.8999\n",
      "Epoch 367/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1699 - acc: 0.9056 - val_loss: 0.1715 - val_acc: 0.8750\n",
      "Epoch 368/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1688 - acc: 0.9095 - val_loss: 0.1705 - val_acc: 0.9381\n",
      "Epoch 369/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1705 - acc: 0.8866 - val_loss: 0.1712 - val_acc: 0.8636\n",
      "Epoch 370/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1697 - acc: 0.9037 - val_loss: 0.1692 - val_acc: 0.9327\n",
      "Epoch 371/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1706 - acc: 0.9053 - val_loss: 0.1702 - val_acc: 0.9195\n",
      "Epoch 372/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1709 - acc: 0.9033 - val_loss: 0.1690 - val_acc: 0.9217\n",
      "Epoch 373/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1696 - acc: 0.9212 - val_loss: 0.1699 - val_acc: 0.9321\n",
      "Epoch 374/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1698 - acc: 0.9175 - val_loss: 0.1691 - val_acc: 0.9239\n",
      "Epoch 375/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1699 - acc: 0.9055 - val_loss: 0.1714 - val_acc: 0.8778\n",
      "Epoch 376/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1711 - acc: 0.8890 - val_loss: 0.1717 - val_acc: 0.8963\n",
      "Epoch 377/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1704 - acc: 0.8968 - val_loss: 0.1700 - val_acc: 0.9217\n",
      "Epoch 378/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1687 - acc: 0.9213 - val_loss: 0.1683 - val_acc: 0.9349\n",
      "Epoch 379/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1716 - acc: 0.8904 - val_loss: 0.1699 - val_acc: 0.8783\n",
      "Epoch 380/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1708 - acc: 0.8992 - val_loss: 0.1690 - val_acc: 0.9160\n",
      "Epoch 381/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1689 - acc: 0.9212 - val_loss: 0.1727 - val_acc: 0.9180\n",
      "Epoch 382/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1703 - acc: 0.9009 - val_loss: 0.1702 - val_acc: 0.8894\n",
      "Epoch 383/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1697 - acc: 0.9103 - val_loss: 0.1688 - val_acc: 0.9358\n",
      "Epoch 384/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1695 - acc: 0.9188 - val_loss: 0.1701 - val_acc: 0.8668\n",
      "Epoch 385/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1702 - acc: 0.9022 - val_loss: 0.1687 - val_acc: 0.9160\n",
      "Epoch 386/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1713 - acc: 0.8834 - val_loss: 0.1705 - val_acc: 0.9089\n",
      "Epoch 387/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1702 - acc: 0.8981 - val_loss: 0.1711 - val_acc: 0.8801\n",
      "Epoch 388/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1717 - acc: 0.8923 - val_loss: 0.1723 - val_acc: 0.9279\n",
      "Epoch 389/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1704 - acc: 0.9122 - val_loss: 0.1686 - val_acc: 0.9113\n",
      "Epoch 390/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1688 - acc: 0.9245 - val_loss: 0.1687 - val_acc: 0.9211\n",
      "Epoch 391/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1694 - acc: 0.9154 - val_loss: 0.1708 - val_acc: 0.9062\n",
      "Epoch 392/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1704 - acc: 0.8966 - val_loss: 0.1701 - val_acc: 0.9392\n",
      "Epoch 393/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1712 - acc: 0.8953 - val_loss: 0.1688 - val_acc: 0.9197\n",
      "Epoch 394/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1701 - acc: 0.8999 - val_loss: 0.1685 - val_acc: 0.9347\n",
      "Epoch 395/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1699 - acc: 0.9091 - val_loss: 0.1689 - val_acc: 0.8919\n",
      "Epoch 396/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1693 - acc: 0.9201 - val_loss: 0.1697 - val_acc: 0.9057\n",
      "Epoch 397/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1689 - acc: 0.9150 - val_loss: 0.1701 - val_acc: 0.9032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1703 - acc: 0.9030 - val_loss: 0.1686 - val_acc: 0.9304\n",
      "Epoch 399/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1714 - acc: 0.8929 - val_loss: 0.1708 - val_acc: 0.8891\n",
      "Epoch 400/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1696 - acc: 0.9052 - val_loss: 0.1685 - val_acc: 0.9241\n",
      "Epoch 401/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1693 - acc: 0.9142 - val_loss: 0.1717 - val_acc: 0.8917\n",
      "Epoch 402/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1706 - acc: 0.8937 - val_loss: 0.1691 - val_acc: 0.9090\n",
      "Epoch 403/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1691 - acc: 0.9186 - val_loss: 0.1697 - val_acc: 0.9248\n",
      "Epoch 404/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1711 - acc: 0.8854 - val_loss: 0.1709 - val_acc: 0.8710\n",
      "Epoch 405/500\n",
      "223988/223988 [==============================] - 9s 39us/step - loss: 0.1766 - acc: 0.8418 - val_loss: 0.1725 - val_acc: 0.8927\n",
      "Epoch 406/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1737 - acc: 0.8999 - val_loss: 0.1715 - val_acc: 0.8768\n",
      "Epoch 407/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1703 - acc: 0.9214 - val_loss: 0.1696 - val_acc: 0.9183\n",
      "Epoch 408/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1717 - acc: 0.9152 - val_loss: 0.1692 - val_acc: 0.9077\n",
      "Epoch 409/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1690 - acc: 0.9269 - val_loss: 0.1691 - val_acc: 0.9351\n",
      "Epoch 410/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1710 - acc: 0.9106 - val_loss: 0.1717 - val_acc: 0.8931\n",
      "Epoch 411/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1694 - acc: 0.9195 - val_loss: 0.1706 - val_acc: 0.9239\n",
      "Epoch 412/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1704 - acc: 0.9031 - val_loss: 0.1692 - val_acc: 0.9017\n",
      "Epoch 413/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1698 - acc: 0.9123 - val_loss: 0.1703 - val_acc: 0.9010\n",
      "Epoch 414/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1704 - acc: 0.9102 - val_loss: 0.1696 - val_acc: 0.9199\n",
      "Epoch 415/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1698 - acc: 0.9085 - val_loss: 0.1694 - val_acc: 0.9331\n",
      "Epoch 416/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1691 - acc: 0.9226 - val_loss: 0.1691 - val_acc: 0.9127\n",
      "Epoch 417/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1690 - acc: 0.9181 - val_loss: 0.1692 - val_acc: 0.9191\n",
      "Epoch 418/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1691 - acc: 0.9093 - val_loss: 0.1709 - val_acc: 0.8811\n",
      "Epoch 419/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1696 - acc: 0.9038 - val_loss: 0.1688 - val_acc: 0.8892\n",
      "Epoch 420/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1721 - acc: 0.8852 - val_loss: 0.1692 - val_acc: 0.9153\n",
      "Epoch 421/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1705 - acc: 0.9082 - val_loss: 0.1695 - val_acc: 0.9317\n",
      "Epoch 422/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1703 - acc: 0.9126 - val_loss: 0.1706 - val_acc: 0.8864\n",
      "Epoch 423/500\n",
      "223988/223988 [==============================] - 9s 39us/step - loss: 0.1697 - acc: 0.9110 - val_loss: 0.1709 - val_acc: 0.8784\n",
      "Epoch 424/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1741 - acc: 0.8759 - val_loss: 0.1779 - val_acc: 0.7431\n",
      "Epoch 425/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1773 - acc: 0.8443 - val_loss: 0.1714 - val_acc: 0.8940\n",
      "Epoch 426/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1716 - acc: 0.9010 - val_loss: 0.1705 - val_acc: 0.9007\n",
      "Epoch 427/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1698 - acc: 0.9140 - val_loss: 0.1702 - val_acc: 0.9337\n",
      "Epoch 428/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1690 - acc: 0.9250 - val_loss: 0.1778 - val_acc: 0.9222\n",
      "Epoch 429/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1729 - acc: 0.8944 - val_loss: 0.1698 - val_acc: 0.9175\n",
      "Epoch 430/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1707 - acc: 0.9108 - val_loss: 0.1688 - val_acc: 0.9326\n",
      "Epoch 431/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1702 - acc: 0.9157 - val_loss: 0.1697 - val_acc: 0.9204\n",
      "Epoch 432/500\n",
      "223988/223988 [==============================] - 9s 41us/step - loss: 0.1700 - acc: 0.9088 - val_loss: 0.1698 - val_acc: 0.9039\n",
      "Epoch 433/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1704 - acc: 0.9055 - val_loss: 0.1689 - val_acc: 0.9181\n",
      "Epoch 434/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1695 - acc: 0.9142 - val_loss: 0.1688 - val_acc: 0.9329\n",
      "Epoch 435/500\n",
      "223988/223988 [==============================] - 9s 40us/step - loss: 0.1710 - acc: 0.9001 - val_loss: 0.1690 - val_acc: 0.9292\n",
      "Epoch 436/500\n",
      "223988/223988 [==============================] - 9s 38us/step - loss: 0.1696 - acc: 0.9135 - val_loss: 0.1687 - val_acc: 0.9252\n",
      "Epoch 437/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1726 - acc: 0.8923 - val_loss: 0.1715 - val_acc: 0.8733\n",
      "Epoch 438/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1704 - acc: 0.9040 - val_loss: 0.1687 - val_acc: 0.9140\n",
      "Epoch 439/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1688 - acc: 0.9239 - val_loss: 0.1688 - val_acc: 0.9136\n",
      "Epoch 440/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1700 - acc: 0.9078 - val_loss: 0.1712 - val_acc: 0.9003\n",
      "Epoch 441/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1711 - acc: 0.8820 - val_loss: 0.1691 - val_acc: 0.8948\n",
      "Epoch 442/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1693 - acc: 0.9105 - val_loss: 0.1693 - val_acc: 0.9148\n",
      "Epoch 443/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1710 - acc: 0.8947 - val_loss: 0.1701 - val_acc: 0.9009\n",
      "Epoch 444/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1695 - acc: 0.9105 - val_loss: 0.1687 - val_acc: 0.9165\n",
      "Epoch 445/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1736 - acc: 0.8730 - val_loss: 0.1716 - val_acc: 0.8825\n",
      "Epoch 446/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1701 - acc: 0.9110 - val_loss: 0.1703 - val_acc: 0.9072\n",
      "Epoch 447/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1724 - acc: 0.8955 - val_loss: 0.1691 - val_acc: 0.9260\n",
      "Epoch 448/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1701 - acc: 0.9152 - val_loss: 0.1689 - val_acc: 0.9268\n",
      "Epoch 449/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1696 - acc: 0.9168 - val_loss: 0.1754 - val_acc: 0.8519\n",
      "Epoch 450/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1717 - acc: 0.9018 - val_loss: 0.1706 - val_acc: 0.9335\n",
      "Epoch 451/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1707 - acc: 0.9093 - val_loss: 0.1716 - val_acc: 0.8586\n",
      "Epoch 452/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1697 - acc: 0.9103 - val_loss: 0.1690 - val_acc: 0.9346\n",
      "Epoch 453/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1691 - acc: 0.9207 - val_loss: 0.1687 - val_acc: 0.9260\n",
      "Epoch 454/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1759 - acc: 0.8249 - val_loss: 0.1753 - val_acc: 0.8467\n",
      "Epoch 455/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1749 - acc: 0.8720 - val_loss: 0.1726 - val_acc: 0.8903\n",
      "Epoch 456/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1714 - acc: 0.9096 - val_loss: 0.1707 - val_acc: 0.9173\n",
      "Epoch 457/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1711 - acc: 0.9180 - val_loss: 0.1699 - val_acc: 0.9132\n",
      "Epoch 458/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1697 - acc: 0.9260 - val_loss: 0.1689 - val_acc: 0.9333\n",
      "Epoch 459/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1717 - acc: 0.9174 - val_loss: 0.1694 - val_acc: 0.9248\n",
      "Epoch 460/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1711 - acc: 0.9112 - val_loss: 0.1717 - val_acc: 0.9054\n",
      "Epoch 461/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1694 - acc: 0.9225 - val_loss: 0.1693 - val_acc: 0.9343\n",
      "Epoch 462/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1700 - acc: 0.9260 - val_loss: 0.1694 - val_acc: 0.9157\n",
      "Epoch 463/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1701 - acc: 0.9202 - val_loss: 0.1707 - val_acc: 0.9254\n",
      "Epoch 464/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1692 - acc: 0.9293 - val_loss: 0.1693 - val_acc: 0.9232\n",
      "Epoch 465/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1693 - acc: 0.9234 - val_loss: 0.1681 - val_acc: 0.9350\n",
      "Epoch 466/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1694 - acc: 0.9190 - val_loss: 0.1687 - val_acc: 0.9329\n",
      "Epoch 467/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1734 - acc: 0.8852 - val_loss: 0.1693 - val_acc: 0.9242\n",
      "Epoch 468/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1720 - acc: 0.8836 - val_loss: 0.1707 - val_acc: 0.8880\n",
      "Epoch 469/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1702 - acc: 0.9151 - val_loss: 0.1691 - val_acc: 0.9225\n",
      "Epoch 470/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1704 - acc: 0.9163 - val_loss: 0.1805 - val_acc: 0.8887\n",
      "Epoch 471/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1716 - acc: 0.9099 - val_loss: 0.1696 - val_acc: 0.9098\n",
      "Epoch 472/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1694 - acc: 0.9222 - val_loss: 0.1688 - val_acc: 0.9330\n",
      "Epoch 473/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1694 - acc: 0.9189 - val_loss: 0.1687 - val_acc: 0.9321\n",
      "Epoch 474/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1693 - acc: 0.9208 - val_loss: 0.1686 - val_acc: 0.8974\n",
      "Epoch 475/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1695 - acc: 0.9139 - val_loss: 0.1713 - val_acc: 0.8348\n",
      "Epoch 476/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1698 - acc: 0.9063 - val_loss: 0.1698 - val_acc: 0.8888\n",
      "Epoch 477/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1694 - acc: 0.9163 - val_loss: 0.1690 - val_acc: 0.9168\n",
      "Epoch 478/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1694 - acc: 0.9070 - val_loss: 0.1689 - val_acc: 0.9225\n",
      "Epoch 479/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1709 - acc: 0.8890 - val_loss: 0.1686 - val_acc: 0.9266\n",
      "Epoch 480/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1701 - acc: 0.9114 - val_loss: 0.1798 - val_acc: 0.8607\n",
      "Epoch 481/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1701 - acc: 0.9119 - val_loss: 0.1683 - val_acc: 0.9291\n",
      "Epoch 482/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1687 - acc: 0.9232 - val_loss: 0.1688 - val_acc: 0.9308\n",
      "Epoch 483/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1694 - acc: 0.9122 - val_loss: 0.1712 - val_acc: 0.9263\n",
      "Epoch 484/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1705 - acc: 0.8983 - val_loss: 0.1692 - val_acc: 0.9120\n",
      "Epoch 485/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1702 - acc: 0.8972 - val_loss: 0.1701 - val_acc: 0.8587\n",
      "Epoch 486/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1700 - acc: 0.8998 - val_loss: 0.1685 - val_acc: 0.9041\n",
      "Epoch 487/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1710 - acc: 0.8916 - val_loss: 0.1696 - val_acc: 0.8798\n",
      "Epoch 488/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1707 - acc: 0.9075 - val_loss: 0.1697 - val_acc: 0.8947\n",
      "Epoch 489/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1701 - acc: 0.9127 - val_loss: 0.1687 - val_acc: 0.9280\n",
      "Epoch 490/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1689 - acc: 0.9282 - val_loss: 0.1688 - val_acc: 0.9310\n",
      "Epoch 491/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1699 - acc: 0.9242 - val_loss: 0.1720 - val_acc: 0.8551\n",
      "Epoch 492/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1699 - acc: 0.9076 - val_loss: 0.1689 - val_acc: 0.9060\n",
      "Epoch 493/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1703 - acc: 0.9029 - val_loss: 0.1717 - val_acc: 0.9143\n",
      "Epoch 494/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1713 - acc: 0.8935 - val_loss: 0.1705 - val_acc: 0.9251\n",
      "Epoch 495/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1697 - acc: 0.9143 - val_loss: 0.1693 - val_acc: 0.9351\n",
      "Epoch 496/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1702 - acc: 0.9100 - val_loss: 0.1689 - val_acc: 0.9294\n",
      "Epoch 497/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1725 - acc: 0.8970 - val_loss: 0.1973 - val_acc: 0.7135\n",
      "Epoch 498/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1743 - acc: 0.8636 - val_loss: 0.1702 - val_acc: 0.9007\n",
      "Epoch 499/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1700 - acc: 0.9228 - val_loss: 0.1738 - val_acc: 0.9142\n",
      "Epoch 500/500\n",
      "223988/223988 [==============================] - 5s 22us/step - loss: 0.1697 - acc: 0.9273 - val_loss: 0.1686 - val_acc: 0.9333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=encoder)\n",
    "\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mse',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"ENCODER_DEGRAD.h5\",\n",
    "                               save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test, X_test), callbacks = [cp]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['acc'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_acc'], linewidth=2, label='Test')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Model)              (None, 34)                178034    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               17500     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                2020      \n",
      "=================================================================\n",
      "Total params: 377,954\n",
      "Trainable params: 377,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_7 to have shape (20,) but got array with shape (16,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c8c6430e23fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m              \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m              verbose=2, callbacks=[checkpointer]).history\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_7 to have shape (20,) but got array with shape (16,)"
     ]
    }
   ],
   "source": [
    "#Debut du decompte du temps\n",
    "start_time = time.time()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(autoencoder)\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(500, activation ='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(300, activation ='tanh'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(100, activation ='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(nb_class, activation ='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(metrics=['accuracy'], loss = 'mse', \n",
    "              optimizer='adam')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='DEGRADATION.h5', \n",
    "                               verbose=2, save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(X_train, Yd_train,\n",
    "             validation_data=(X_test, Yd_test),\n",
    "             epochs= nb_epoch,\n",
    "             batch_size=batch_size,\n",
    "             shuffle=True,\n",
    "             verbose=2, callbacks=[checkpointer]).history\n",
    "\n",
    "\n",
    "score, acc = model.evaluate(X_test, y = Yd_test, \n",
    "               batch_size = batch_size, \n",
    "               verbose = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Temps d execution : %s secondes ---\" %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['acc'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_acc'], linewidth=2, label='Test')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
